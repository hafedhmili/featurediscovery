processing compilation unit: Analyzer.java
processing compilation unit: StopFilter.java
processing compilation unit: LowerCaseFilter.java
processing compilation unit: TokenFilter.java
processing compilation unit: TokenStream.java
processing compilation unit: StopAnalyzer.java
processing compilation unit: PorterStemmer.java
processing compilation unit: PorterStemFilter.java
processing compilation unit: WhitespaceTokenizer.java
processing compilation unit: CharTokenizer.java
processing compilation unit: SimpleAnalyzer.java
processing compilation unit: Tokenizer.java
processing compilation unit: LetterTokenizer.java
processing compilation unit: LowerCaseTokenizer.java
processing compilation unit: Token.java
processing compilation unit: WhitespaceAnalyzer.java
processing compilation unit: PerFieldAnalyzerWrapper.java
processing compilation unit: GermanAnalyzer.java
processing compilation unit: GermanStemFilter.java
processing compilation unit: GermanStemmer.java
processing compilation unit: WordlistLoader.java
processing compilation unit: RussianLetterTokenizer.java
processing compilation unit: RussianStemFilter.java
processing compilation unit: RussianLowerCaseFilter.java
processing compilation unit: RussianStemmer.java
processing compilation unit: RussianCharsets.java
processing compilation unit: RussianAnalyzer.java
processing compilation unit: StandardTokenizerConstants.java
processing compilation unit: CharStream.java
processing compilation unit: StandardAnalyzer.java
processing compilation unit: TokenMgrError.java
processing compilation unit: StandardFilter.java
processing compilation unit: FastCharStream.java
processing compilation unit: ParseException.java
processing compilation unit: StandardTokenizerTokenManager.java
processing compilation unit: Token.java
processing compilation unit: StandardTokenizer.java
processing compilation unit: DateField.java
processing compilation unit: Field.java
processing compilation unit: Document.java
processing compilation unit: SegmentMergeInfo.java
processing compilation unit: TermDocs.java
processing compilation unit: TermPositions.java
processing compilation unit: TermFreqVector.java
processing compilation unit: MultiReader.java
processing compilation unit: FieldsReader.java
processing compilation unit: FieldInfo.java
processing compilation unit: CompoundFileWriter.java
processing compilation unit: IndexWriter.java
processing compilation unit: SegmentMerger.java
processing compilation unit: SegmentTermPositions.java
processing compilation unit: Term.java
processing compilation unit: FilterIndexReader.java
processing compilation unit: SegmentTermVector.java
processing compilation unit: SegmentTermEnum.java
processing compilation unit: TermVectorsReader.java
processing compilation unit: TermVectorsWriter.java
processing compilation unit: SegmentMergeQueue.java
processing compilation unit: TermEnum.java
processing compilation unit: TermInfo.java
processing compilation unit: MultipleTermPositions.java
processing compilation unit: TermPositionVector.java
processing compilation unit: IndexReader.java
processing compilation unit: CompoundFileReader.java
processing compilation unit: FieldInfos.java
processing compilation unit: FieldsWriter.java
processing compilation unit: SegmentTermDocs.java
processing compilation unit: DocumentWriter.java
processing compilation unit: SegmentInfo.java
processing compilation unit: SegmentReader.java
processing compilation unit: SegmentInfos.java
processing compilation unit: TermInfosReader.java
processing compilation unit: TermInfosWriter.java
processing compilation unit: FastCharStream.java
processing compilation unit: QueryParserConstants.java
processing compilation unit: Token.java
processing compilation unit: TokenMgrError.java
processing compilation unit: MultiFieldQueryParser.java
processing compilation unit: QueryParser.java
processing compilation unit: QueryParserTokenManager.java
processing compilation unit: CharStream.java
processing compilation unit: ParseException.java
processing compilation unit: PhraseQueue.java
processing compilation unit: WildcardTermEnum.java
processing compilation unit: Explanation.java
processing compilation unit: Hits.java
processing compilation unit: QueryFilter.java
processing compilation unit: MultiSearcher.java
processing compilation unit: Query.java
processing compilation unit: Similarity.java
processing compilation unit: SortComparator.java
processing compilation unit: FieldDoc.java
processing compilation unit: SortComparatorSource.java
processing compilation unit: TopFieldDocs.java
processing compilation unit: HitCollector.java
processing compilation unit: ScoreDocComparator.java
processing compilation unit: FilteredTermEnum.java
processing compilation unit: WildcardQuery.java
processing compilation unit: Searchable.java
processing compilation unit: MultiTermQuery.java
processing compilation unit: DefaultSimilarity.java
processing compilation unit: FieldCache.java
processing compilation unit: HitQueue.java
processing compilation unit: RemoteSearchable.java
processing compilation unit: BooleanClause.java
processing compilation unit: ScoreDoc.java
processing compilation unit: Filter.java
processing compilation unit: QueryTermVector.java
processing compilation unit: CachingWrapperFilter.java
processing compilation unit: PhrasePrefixQuery.java
processing compilation unit: SortField.java
processing compilation unit: ParallelMultiSearcher.java
processing compilation unit: Sort.java
processing compilation unit: SloppyPhraseScorer.java
processing compilation unit: TopDocs.java
processing compilation unit: FuzzyTermEnum.java
processing compilation unit: RangeQuery.java
processing compilation unit: DateFilter.java
processing compilation unit: PhrasePositions.java
processing compilation unit: PhraseScorer.java
processing compilation unit: FieldSortedHitQueue.java
processing compilation unit: PrefixQuery.java
processing compilation unit: IndexSearcher.java
processing compilation unit: Weight.java
processing compilation unit: BooleanQuery.java
processing compilation unit: ExactPhraseScorer.java
processing compilation unit: FieldDocSortedHitQueue.java
processing compilation unit: PhraseQuery.java
processing compilation unit: FilteredQuery.java
processing compilation unit: ConjunctionScorer.java
processing compilation unit: Scorer.java
processing compilation unit: FuzzyQuery.java
processing compilation unit: Searcher.java
processing compilation unit: FieldCacheImpl.java
processing compilation unit: TermScorer.java
processing compilation unit: BooleanScorer.java
processing compilation unit: TermQuery.java
processing compilation unit: SpanFirstQuery.java
processing compilation unit: Spans.java
processing compilation unit: SpanOrQuery.java
processing compilation unit: SpanTermQuery.java
processing compilation unit: SpanWeight.java
processing compilation unit: SpanNearQuery.java
processing compilation unit: SpanNotQuery.java
processing compilation unit: NearSpans.java
processing compilation unit: SpanScorer.java
processing compilation unit: SpanQuery.java
processing compilation unit: FSDirectory.java
processing compilation unit: Lock.java
processing compilation unit: RAMDirectory.java
processing compilation unit: RAMInputStream.java
processing compilation unit: InputStream.java
processing compilation unit: RAMOutputStream.java
processing compilation unit: RAMFile.java
processing compilation unit: Directory.java
processing compilation unit: OutputStream.java
processing compilation unit: StringHelper.java
processing compilation unit: PriorityQueue.java
processing compilation unit: Constants.java
processing compilation unit: BitVector.java
Project Lucene1.4 has : 160 compilation units, and 197 defined types
Printing the relation
org.apache.lucene.analysis.Analyzer =====> [ void StandardAnalyzer(), void addAnalyzer(String fieldName, Analyzer analyzer), void RussianAnalyzer(), void GermanAnalyzer(File stopwords), void setStemExclusionTable(File exclusionlist), void RussianAnalyzer(char[] charset), void setStemExclusionTable(String[] exclusionlist), void GermanAnalyzer(), void StopAnalyzer(String[] stopWords), void RussianAnalyzer(char[] charset, Hashtable stopwords), void StandardAnalyzer(String[] stopWords), void GermanAnalyzer(Hashtable stopwords), void GermanAnalyzer(String[] stopwords), void RussianAnalyzer(char[] charset, String[] stopwords), TokenStream tokenStream(String fieldName, Reader reader), TokenStream tokenStream(Reader reader), String[] makeStopWords(char[] charset), void PerFieldAnalyzerWrapper(Analyzer defaultAnalyzer), void setStemExclusionTable(Hashtable exclusionlist), void StopAnalyzer() ]
org.apache.lucene.analysis.CharTokenizer =====> [ void CharTokenizer(Reader input), void LetterTokenizer(Reader in), void LowerCaseTokenizer(Reader in), char normalize(char c), void RussianLetterTokenizer(Reader in, char[] charset), void WhitespaceTokenizer(Reader in), boolean isTokenChar(char c), Token next() ]
org.apache.lucene.analysis.LetterTokenizer =====> [ void LetterTokenizer(Reader in), void LowerCaseTokenizer(Reader in), char normalize(char c), boolean isTokenChar(char c) ]
org.apache.lucene.analysis.LowerCaseFilter =====> [ void LowerCaseFilter(TokenStream in), Token next() ]
org.apache.lucene.analysis.LowerCaseTokenizer =====> [ void LowerCaseTokenizer(Reader in), char normalize(char c) ]
org.apache.lucene.analysis.PerFieldAnalyzerWrapper =====> [ void addAnalyzer(String fieldName, Analyzer analyzer), TokenStream tokenStream(String fieldName, Reader reader), void PerFieldAnalyzerWrapper(Analyzer defaultAnalyzer) ]
org.apache.lucene.analysis.PorterStemFilter =====> [ void PorterStemFilter(TokenStream in), Token next() ]
org.apache.lucene.analysis.PorterStemmer =====> [ void step2(), boolean stem(char[] word, int wordLen), char[] getResultBuffer(), boolean cons(int i), boolean cvc(int i), void setto(String s), void main(String[] args), void PorterStemmer(), void step6(), boolean vowelinstem(), void step3(), boolean doublec(int j), boolean stem(char[] wordBuffer, int offset, int wordLen), void reset(), int getResultLength(), void step4(), int m(), void step1(), void r(String s), boolean stem(int i0), boolean stem(char[] word), String stem(String s), void add(char ch), void step5(), boolean ends(String s), boolean stem() ]
org.apache.lucene.analysis.SimpleAnalyzer =====> [ TokenStream tokenStream(String fieldName, Reader reader) ]
org.apache.lucene.analysis.StopAnalyzer =====> [ void StopAnalyzer(String[] stopWords), TokenStream tokenStream(String fieldName, Reader reader), void StopAnalyzer() ]
org.apache.lucene.analysis.StopFilter =====> [ void StopFilter(TokenStream in, String[] stopWords), Set makeStopSet(String[] stopWords), void StopFilter(TokenStream in, Hashtable stopTable), void StopFilter(TokenStream in, Set stopWords), Hashtable makeStopTable(String[] stopWords), Token next() ]
org.apache.lucene.analysis.Token =====> [ String type(), int startOffset(), int getPositionIncrement(), String termText(), void Token(String text, int start, int end), void Token(String text, int start, int end, String typ), int endOffset(), void setPositionIncrement(int positionIncrement) ]
org.apache.lucene.analysis.TokenFilter =====> [ void StandardFilter(TokenStream in), void TokenFilter(), void GermanStemFilter(TokenStream in), void setStemmer(RussianStemmer stemmer), org.apache.lucene.analysis.Token next(), Hashtable makeStopTable(String[] stopWords), void RussianStemFilter(TokenStream in, char[] charset), void PorterStemFilter(TokenStream in), void StopFilter(TokenStream in, String[] stopWords), Set makeStopSet(String[] stopWords), void setExclusionSet(Set exclusionSet), void GermanStemFilter(TokenStream in, Hashtable exclusiontable), void LowerCaseFilter(TokenStream in), void RussianLowerCaseFilter(TokenStream in, char[] charset), void StopFilter(TokenStream in, Hashtable stopTable), void close(), void setStemmer(GermanStemmer stemmer), void StopFilter(TokenStream in, Set stopWords), void setExclusionTable(Hashtable exclusiontable), void TokenFilter(TokenStream input), void GermanStemFilter(TokenStream in, Set exclusionSet), Token next() ]
org.apache.lucene.analysis.TokenStream =====> [ void StandardFilter(TokenStream in), void GermanStemFilter(TokenStream in), Token getToken(int index), void jj_la1_0(), int jj_ntk(), Token jj_consume_token(int kind), ParseException generateParseException(), Hashtable makeStopTable(String[] stopWords), void RussianStemFilter(TokenStream in, char[] charset), void PorterStemFilter(TokenStream in), Set makeStopSet(String[] stopWords), void CharTokenizer(Reader input), void LetterTokenizer(Reader in), void GermanStemFilter(TokenStream in, Hashtable exclusiontable), void close(), void setStemmer(GermanStemmer stemmer), void StopFilter(TokenStream in, Set stopWords), void TokenFilter(TokenStream input), void ReInit(CharStream stream), void Tokenizer(), void enable_tracing(), void TokenFilter(), void setStemmer(RussianStemmer stemmer), org.apache.lucene.analysis.Token next(), void disable_tracing(), void Tokenizer(Reader input), void ReInit(StandardTokenizerTokenManager tm), void WhitespaceTokenizer(Reader in), boolean isTokenChar(char c), Token getNextToken(), void StopFilter(TokenStream in, String[] stopWords), void setExclusionSet(Set exclusionSet), void LowerCaseFilter(TokenStream in), void RussianLowerCaseFilter(TokenStream in, char[] charset), void StopFilter(TokenStream in, Hashtable stopTable), void LowerCaseTokenizer(Reader in), void StandardTokenizer(StandardTokenizerTokenManager tm), char normalize(char c), void StandardTokenizer(Reader reader), void setExclusionTable(Hashtable exclusiontable), void GermanStemFilter(TokenStream in, Set exclusionSet), void RussianLetterTokenizer(Reader in, char[] charset), Token next(), void StandardTokenizer(CharStream stream) ]
org.apache.lucene.analysis.Tokenizer =====> [ Token getToken(int index), void jj_la1_0(), int jj_ntk(), Token jj_consume_token(int kind), ParseException generateParseException(), void CharTokenizer(Reader input), void LetterTokenizer(Reader in), void close(), void ReInit(CharStream stream), void Tokenizer(), void enable_tracing(), org.apache.lucene.analysis.Token next(), void disable_tracing(), void Tokenizer(Reader input), void ReInit(StandardTokenizerTokenManager tm), void WhitespaceTokenizer(Reader in), boolean isTokenChar(char c), Token getNextToken(), void LowerCaseTokenizer(Reader in), void StandardTokenizer(StandardTokenizerTokenManager tm), char normalize(char c), void StandardTokenizer(Reader reader), void RussianLetterTokenizer(Reader in, char[] charset), Token next(), void StandardTokenizer(CharStream stream) ]
org.apache.lucene.analysis.WhitespaceAnalyzer =====> [ TokenStream tokenStream(String fieldName, Reader reader) ]
org.apache.lucene.analysis.WhitespaceTokenizer =====> [ void WhitespaceTokenizer(Reader in), boolean isTokenChar(char c) ]
org.apache.lucene.analysis.de.GermanAnalyzer =====> [ void GermanAnalyzer(Hashtable stopwords), void GermanAnalyzer(String[] stopwords), void GermanAnalyzer(File stopwords), TokenStream tokenStream(String fieldName, Reader reader), void setStemExclusionTable(File exclusionlist), void setStemExclusionTable(String[] exclusionlist), void setStemExclusionTable(Hashtable exclusionlist), void GermanAnalyzer() ]
org.apache.lucene.analysis.de.GermanStemFilter =====> [ void setExclusionSet(Set exclusionSet), void GermanStemFilter(TokenStream in, Hashtable exclusiontable), void GermanStemFilter(TokenStream in), void setStemmer(GermanStemmer stemmer), void setExclusionTable(Hashtable exclusiontable), void GermanStemFilter(TokenStream in, Set exclusionSet), Token next() ]
org.apache.lucene.analysis.de.GermanStemmer =====> [ boolean isStemmable(String term), void resubstitute(StringBuffer buffer), void strip(StringBuffer buffer), void optimize(StringBuffer buffer), void substitute(StringBuffer buffer), String stem(String term), void removeParticleDenotion(StringBuffer buffer) ]
org.apache.lucene.analysis.de.WordlistLoader =====> [ Hashtable getWordtable(String path, String wordfile), Hashtable getWordtable(File wordfile), HashSet getWordSet(File wordfile), Hashtable getWordtable(String wordfile), Hashtable makeWordTable(HashSet wordSet) ]
org.apache.lucene.analysis.ru.RussianAnalyzer =====> [ void RussianAnalyzer(char[] charset, Hashtable stopwords), void RussianAnalyzer(), void RussianAnalyzer(char[] charset, String[] stopwords), TokenStream tokenStream(String fieldName, Reader reader), String[] makeStopWords(char[] charset), void RussianAnalyzer(char[] charset) ]
org.apache.lucene.analysis.ru.RussianCharsets =====> [ char toLowerCase(char letter, char[] charset) ]
org.apache.lucene.analysis.ru.RussianLetterTokenizer =====> [ void RussianLetterTokenizer(Reader in, char[] charset), boolean isTokenChar(char c) ]
org.apache.lucene.analysis.ru.RussianLowerCaseFilter =====> [ void RussianLowerCaseFilter(TokenStream in, char[] charset), Token next() ]
org.apache.lucene.analysis.ru.RussianStemFilter =====> [ void setStemmer(RussianStemmer stemmer), void RussianStemFilter(TokenStream in, char[] charset), Token next() ]
org.apache.lucene.analysis.ru.RussianStemmer =====> [ void markPositions(String word), String stem(String input), boolean removeSoft(StringBuffer stemmingZone), boolean noun(StringBuffer stemmingZone), String stem(String theWord, char[] charset), boolean undoubleN(StringBuffer stemmingZone), boolean derivational(StringBuffer stemmingZone), int findEnding(StringBuffer stemmingZone, char[][] theEndingClass), boolean reflexive(StringBuffer stemmingZone), boolean verb(StringBuffer stemmingZone), boolean isVowel(char letter), boolean adjectival(StringBuffer stemmingZone), void RussianStemmer(char[] charset), boolean findAndRemoveEnding(StringBuffer stemmingZone, char[][] theEndingClass, char[][] thePredessors), void RussianStemmer(), void setEndings(), int findEnding(StringBuffer stemmingZone, int startIndex, char[][] theEndingClass), boolean findAndRemoveEnding(StringBuffer stemmingZone, char[][] theEndingClass), boolean removeI(StringBuffer stemmingZone), boolean superlative(StringBuffer stemmingZone), boolean perfectiveGerund(StringBuffer stemmingZone), void setCharset(char[] newCharset) ]
org.apache.lucene.analysis.standard.CharStream =====> [ void refill(), int getEndLine(), int getColumn(), char BeginToken(), String GetImage(), void backup(int amount), char readChar(), int getBeginColumn(), int getEndColumn(), int getLine(), int getBeginLine(), void FastCharStream(Reader r), char[] GetSuffix(int len), void Done() ]
org.apache.lucene.analysis.standard.FastCharStream =====> [ void refill(), int getEndLine(), int getColumn(), char BeginToken(), String GetImage(), void backup(int amount), char readChar(), int getBeginColumn(), int getEndColumn(), int getLine(), int getBeginLine(), void FastCharStream(Reader r), char[] GetSuffix(int len), void Done() ]
org.apache.lucene.analysis.standard.ParseException =====> [ void ParseException(), void ParseException(Token currentTokenVal, int[][] expectedTokenSequencesVal, String[] tokenImageVal), String add_escapes(String str), void ParseException(String message) ]
org.apache.lucene.analysis.standard.StandardAnalyzer =====> [ void StandardAnalyzer(), void StandardAnalyzer(String[] stopWords), TokenStream tokenStream(String fieldName, Reader reader) ]
org.apache.lucene.analysis.standard.StandardFilter =====> [ void StandardFilter(TokenStream in), org.apache.lucene.analysis.Token next() ]
org.apache.lucene.analysis.standard.StandardTokenizer =====> [ void enable_tracing(), org.apache.lucene.analysis.Token next(), Token getToken(int index), void disable_tracing(), void jj_la1_0(), int jj_ntk(), Token jj_consume_token(int kind), void ReInit(StandardTokenizerTokenManager tm), ParseException generateParseException(), Token getNextToken(), void StandardTokenizer(StandardTokenizerTokenManager tm), void StandardTokenizer(Reader reader), void ReInit(CharStream stream), void StandardTokenizer(CharStream stream) ]
org.apache.lucene.analysis.standard.StandardTokenizerConstants =====> [ void StandardFilter(TokenStream in), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), Token getToken(int index), void ReInit(CharStream stream, int lexState), void jj_la1_0(), int jj_ntk(), Token jj_consume_token(int kind), int jjMoveStringLiteralDfa0_0(), ParseException generateParseException(), boolean jjCanMove_1(int hiByte, int i1, int i2, long l1, long l2), void jjAddStates(int start, int end), void jjCheckNAddStates(int start, int end), boolean jjCanMove_2(int hiByte, int i1, int i2, long l1, long l2), void ReInit(CharStream stream), void StandardTokenizerTokenManager(CharStream stream), void jjCheckNAdd(int state), void enable_tracing(), void jjCheckNAddTwoStates(int state1, int state2), void ReInitRounds(), org.apache.lucene.analysis.Token next(), void disable_tracing(), void StandardTokenizerTokenManager(CharStream stream, int lexState), void ReInit(StandardTokenizerTokenManager tm), void jjCheckNAddStates(int start), Token getNextToken(), void SwitchTo(int lexState), void StandardTokenizer(StandardTokenizerTokenManager tm), int jjMoveNfa_0(int startState, int curPos), void StandardTokenizer(Reader reader), Token jjFillToken(), void setDebugStream(java.io.PrintStream ds), void StandardTokenizer(CharStream stream) ]
org.apache.lucene.analysis.standard.StandardTokenizerTokenManager =====> [ void jjCheckNAddTwoStates(int state1, int state2), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), void ReInitRounds(), void ReInit(CharStream stream, int lexState), void StandardTokenizerTokenManager(CharStream stream, int lexState), int jjMoveStringLiteralDfa0_0(), void jjCheckNAddStates(int start), boolean jjCanMove_1(int hiByte, int i1, int i2, long l1, long l2), Token getNextToken(), void jjAddStates(int start, int end), void jjCheckNAddStates(int start, int end), void SwitchTo(int lexState), int jjMoveNfa_0(int startState, int curPos), Token jjFillToken(), void setDebugStream(java.io.PrintStream ds), boolean jjCanMove_2(int hiByte, int i1, int i2, long l1, long l2), void ReInit(CharStream stream), void StandardTokenizerTokenManager(CharStream stream), void jjCheckNAdd(int state) ]
org.apache.lucene.analysis.standard.Token =====> [ Token newToken(int ofKind) ]
org.apache.lucene.analysis.standard.TokenMgrError =====> [ String LexicalError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar), void TokenMgrError(String message, int reason), void TokenMgrError(), void TokenMgrError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar, int reason), String addEscapes(String str) ]
org.apache.lucene.document.DateField =====> [ String MAX_DATE_STRING(), void DateField(), String MIN_DATE_STRING(), String timeToString(long time), Date stringToDate(String s), long stringToTime(String s), String dateToString(Date date) ]
org.apache.lucene.document.Document =====> [ void setBoost(float boost), String[] getValues(String name), Field getField(String name), float getBoost(), void Document(), void removeFields(String name), Field[] getFields(String name), void removeField(String name), String get(String name), void add(Field field), Enumeration fields() ]
org.apache.lucene.document.Field =====> [ void setBoost(float boost), String stringValue(), boolean isStored(), Reader readerValue(), Field UnIndexed(String name, String value), String name(), Field Text(String name, String value, boolean storeTermVector), void Field(String name, String string, boolean store, boolean index, boolean token), boolean isIndexed(), Field Text(String name, Reader value, boolean storeTermVector), Field UnStored(String name, String value), void Field(String name, String string, boolean store, boolean index, boolean token, boolean storeTermVector), boolean isTokenized(), Field Text(String name, String value), Field Keyword(String name, String value), Field UnStored(String name, String value, boolean storeTermVector), void Field(String name, Reader reader), float getBoost(), Field Text(String name, Reader value), Field Keyword(String name, Date value), boolean isTermVectorStored() ]
org.apache.lucene.index.CompoundFileReader =====> [ long fileLength(String name), OutputStream createFile(String name), void CompoundFileReader(Directory dir, String name), void touchFile(String name), Directory getDirectory(), void renameFile(String from, String to), void deleteFile(String name), String getName(), boolean fileExists(String name), String[] list(), void close(), long fileModified(String name), InputStream openFile(String id), Lock makeLock(String name) ]
org.apache.lucene.index.CompoundFileReader.CSInputStream =====> [ void seekInternal(long pos), void close(), void CSInputStream(InputStream base, long fileOffset, long length), void readInternal(byte[] b, int offset, int len) ]
org.apache.lucene.index.CompoundFileWriter =====> [ void CompoundFileWriter(Directory dir, String name), void addFile(String file), void close(), Directory getDirectory(), void copyFile(FileEntry source, OutputStream os, byte[] buffer), String getName() ]
org.apache.lucene.index.DocumentWriter =====> [ void addPosition(String field, String text, int position), Posting[] sortPostingTable(), void DocumentWriter(Directory directory, Analyzer analyzer, Similarity similarity, int maxFieldLength), void addDocument(String segment, Document doc), void invertDocument(Document doc), void writeNorms(Document doc, String segment), void writePostings(Posting[] postings, String segment), void quickSort(Posting[] postings, int lo, int hi) ]
org.apache.lucene.index.FieldInfo =====> [ void FieldInfo(String na, boolean tk, int nu, boolean storeTermVector) ]
org.apache.lucene.index.FieldInfos =====> [ int size(), void write(Directory d, String name), boolean hasVectors(), void add(String name, boolean isIndexed), void add(Document doc), int fieldNumber(String fieldName), void add(Collection names, boolean isIndexed), void addInternal(String name, boolean isIndexed, boolean storeTermVector), void add(String name, boolean isIndexed, boolean storeTermVector), String fieldName(int fieldNumber), void write(OutputStream output), void FieldInfos(), void addIndexed(Collection names, boolean storeTermVectors), void FieldInfos(Directory d, String name), FieldInfo fieldInfo(String fieldName), void read(InputStream input), FieldInfo fieldInfo(int fieldNumber) ]
org.apache.lucene.index.FieldsReader =====> [ int size(), void FieldsReader(Directory d, String segment, FieldInfos fn), void close(), Document doc(int n) ]
org.apache.lucene.index.FieldsWriter =====> [ void close(), void addDocument(Document doc), void FieldsWriter(Directory d, String segment, FieldInfos fn) ]
org.apache.lucene.index.FilterIndexReader =====> [ TermEnum terms(Term t), TermFreqVector[] getTermFreqVectors(int docNumber), Document document(int n), byte[] norms(String f), Collection getFieldNames(boolean indexed), void doSetNorm(int d, String f, byte b), void norms(String f, byte[] bytes, int offset), boolean hasDeletions(), Collection getFieldNames(), int numDocs(), void doUndeleteAll(), void doClose(), void doDelete(int n), int maxDoc(), int docFreq(Term t), TermFreqVector getTermFreqVector(int docNumber, String field), TermPositions termPositions(), void doCommit(), TermEnum terms(), boolean isDeleted(int n), void FilterIndexReader(IndexReader in), TermDocs termDocs(), Collection getIndexedFieldNames(boolean storedTermVector) ]
org.apache.lucene.index.FilterIndexReader.FilterTermDocs =====> [ void FilterTermPositions(TermPositions in), void FilterTermDocs(TermDocs in), int nextPosition(), void seek(Term term), void close(), boolean next(), boolean skipTo(int i), int freq(), void seek(TermEnum termEnum), int read(int[] docs, int[] freqs), int doc() ]
org.apache.lucene.index.FilterIndexReader.FilterTermEnum =====> [ void FilterTermEnum(TermEnum in), void close(), boolean next(), int docFreq(), Term term() ]
org.apache.lucene.index.FilterIndexReader.FilterTermPositions =====> [ void FilterTermPositions(TermPositions in), int nextPosition() ]
org.apache.lucene.index.IndexReader =====> [ TermEnum terms(Term term), TermFreqVector[] getTermFreqVectors(int docNumber), Document document(int n), byte[] norms(String f), void closeNorms(), long getCurrentVersion(Directory directory), TermDocs termDocs(Term term), boolean usesCompoundFile(SegmentInfo si), boolean hasDeletions(), long lastModified(String directory), boolean isLocked(String directory), void doClose(), Directory directory(), int maxDoc(), void aquireWriteLock(), void close(), TermFreqVector getTermFreqVector(int docNumber, String field), boolean indexExists(Directory directory), void setNorm(int doc, String field, byte value), void SegmentReader(SegmentInfos sis, SegmentInfo si, boolean closeDir), void undeleteAll(), void setNorm(int doc, String field, float value), void doSetNorm(int n, String field, byte value), void doSetNorm(int doc, String field, byte value), boolean indexExists(String directory), boolean isLocked(Directory directory), void doSetNorm(int d, String f, byte b), void norms(String f, byte[] bytes, int offset), boolean hasSeparateNorms(SegmentInfo si), void doDelete(int docNum), byte[] norms(String field), void initialize(SegmentInfo si), void MultiReader(Directory directory, SegmentInfos sis, boolean closeDirectory, IndexReader[] subReaders), void MultiReader(IndexReader[] subReaders), void IndexReader(Directory directory), void unlock(Directory directory), TermPositions termPositions(), long getCurrentVersion(File directory), boolean isDeleted(int n), void SegmentReader(SegmentInfo si), Collection getIndexedFieldNames(boolean storedTermVector), void FilterIndexReader(IndexReader in), TermEnum terms(Term t), Collection getFieldNames(boolean indexed), TermFreqVector[] getTermFreqVectors(int n), Collection getFieldNames(), long lastModified(Directory directory), int delete(Term term), TermFreqVector getTermFreqVector(int n, String field), IndexReader open(Directory directory, boolean closeDirectory), TermEnum terms(), TermPositions termPositions(Term term), long lastModified(File directory), boolean indexExists(File directory), void openNorms(Directory cfsDir), IndexReader open(File path), IndexReader open(Directory directory), TermDocs termDocs(), IndexReader open(String path), void delete(int docNum), Vector files(), void commit(), int numDocs(), void doUndeleteAll(), long getCurrentVersion(String directory), void norms(String field, byte[] bytes, int offset), void doDelete(int n), void IndexReader(Directory directory, SegmentInfos segmentInfos, boolean closeDirectory), boolean hasDeletions(SegmentInfo si), int docFreq(Term t), void initialize(IndexReader[] subReaders), int readerIndex(int n), void doCommit(), void norms(String field, byte[] result, int offset) ]
org.apache.lucene.index.IndexWriter =====> [ void mergeSegments(int minSegment), Vector readDeleteableFiles(), void setSimilarity(Similarity similarity), void deleteSegments(Vector segments), void deleteFiles(Vector files, Vector deletable), void flushRamSegments(), void addIndexes(IndexReader[] readers), void IndexWriter(File path, Analyzer a, boolean create), void close(), int getSegmentsCounter(), String newSegmentName(), void deleteFiles(Vector files, Directory directory), boolean getUseCompoundFile(), void setUseCompoundFile(boolean value), void addIndexes(Directory[] dirs), void addDocument(Document doc), Similarity getSimilarity(), void optimize(), void maybeMergeSegments(), void IndexWriter(Directory d, Analyzer a, boolean create), void IndexWriter(String path, Analyzer a, boolean create), Analyzer getAnalyzer(), void writeDeleteableFiles(Vector files), void addDocument(Document doc, Analyzer analyzer), void IndexWriter(Directory d, Analyzer a, boolean create, boolean closeDir), int docCount() ]
org.apache.lucene.index.MultiReader =====> [ TermEnum terms(Term term), TermFreqVector[] getTermFreqVectors(int n), Document document(int n), Collection getFieldNames(boolean indexed), boolean hasDeletions(), Collection getFieldNames(), void doClose(), TermFreqVector getTermFreqVector(int n, String field), int maxDoc(), TermEnum terms(), void doSetNorm(int n, String field, byte value), TermDocs termDocs(), int numDocs(), void doUndeleteAll(), void doDelete(int n), byte[] norms(String field), int docFreq(Term t), void MultiReader(Directory directory, SegmentInfos sis, boolean closeDirectory, IndexReader[] subReaders), void initialize(IndexReader[] subReaders), int readerIndex(int n), void MultiReader(IndexReader[] subReaders), TermPositions termPositions(), void doCommit(), boolean isDeleted(int n), void norms(String field, byte[] result, int offset), Collection getIndexedFieldNames(boolean storedTermVector) ]
org.apache.lucene.index.MultiTermDocs =====> [ void seek(Term term), void MultiTermDocs(IndexReader[] r, int[] s), void MultiTermPositions(IndexReader[] r, int[] s), void seek(TermEnum termEnum), int read(int[] docs, int[] freqs), int nextPosition(), void close(), boolean next(), TermDocs termDocs(IndexReader reader), boolean skipTo(int target), int freq(), TermDocs termDocs(int i), int doc() ]
org.apache.lucene.index.MultiTermEnum =====> [ void close(), boolean next(), int docFreq(), void MultiTermEnum(IndexReader[] readers, int[] starts, Term t), Term term() ]
org.apache.lucene.index.MultiTermPositions =====> [ int nextPosition(), TermDocs termDocs(IndexReader reader), void MultiTermPositions(IndexReader[] r, int[] s) ]
org.apache.lucene.index.MultipleTermPositions =====> [ int nextPosition(), void close(), void MultipleTermPositions(IndexReader indexReader, Term[] terms), boolean next(), int read(int[] arg0, int[] arg1), boolean skipTo(int target), void seek(Term arg0), int freq(), void seek(TermEnum termEnum), int doc() ]
org.apache.lucene.index.MultipleTermPositions.IntQueue =====> [ int next(), int size(), void sort(), void clear(), void add(int i), void growArray() ]
org.apache.lucene.index.MultipleTermPositions.TermPositionsQueue =====> [ TermPositions peek(), boolean lessThan(Object a, Object b), void TermPositionsQueue(List termPositions) ]
org.apache.lucene.index.Posting =====> [ void Posting(Term t, int position) ]
org.apache.lucene.index.SegmentInfo =====> [ void SegmentInfo(String name, int docCount, Directory dir) ]
org.apache.lucene.index.SegmentInfos =====> [ void write(Directory directory), long readCurrentVersion(Directory directory), void read(Directory directory), long getVersion(), SegmentInfo info(int i) ]
org.apache.lucene.index.SegmentMergeInfo =====> [ void close(), boolean next(), void SegmentMergeInfo(int b, TermEnum te, IndexReader r) ]
org.apache.lucene.index.SegmentMergeQueue =====> [ void SegmentMergeQueue(int size), void close(), boolean lessThan(Object a, Object b) ]
org.apache.lucene.index.SegmentMerger =====> [ void SegmentMerger(Directory dir, String name, boolean compoundFile), int merge(), void bufferSkip(int doc), void resetSkip(), void mergeTerms(), void mergeNorms(), int appendPostings(SegmentMergeInfo[] smis, int n), IndexReader segmentReader(int i), int mergeFields(), void mergeTermInfos(), long writeSkip(), void add(IndexReader reader), void mergeTermInfo(SegmentMergeInfo[] smis, int n), void mergeVectors(), void createCompoundFile(), void closeReaders() ]
org.apache.lucene.index.SegmentReader =====> [ TermEnum terms(Term t), Document document(int n), Collection getFieldNames(boolean indexed), TermFreqVector[] getTermFreqVectors(int docNumber), void closeNorms(), boolean usesCompoundFile(SegmentInfo si), boolean hasDeletions(), Collection getFieldNames(), void doClose(), int maxDoc(), TermFreqVector getTermFreqVector(int docNumber, String field), void SegmentReader(SegmentInfos sis, SegmentInfo si, boolean closeDir), TermEnum terms(), void openNorms(Directory cfsDir), void doSetNorm(int doc, String field, byte value), TermDocs termDocs(), Vector files(), int numDocs(), void doUndeleteAll(), boolean hasSeparateNorms(SegmentInfo si), void norms(String field, byte[] bytes, int offset), void doDelete(int docNum), boolean hasDeletions(SegmentInfo si), void initialize(SegmentInfo si), int docFreq(Term t), byte[] norms(String field), void doCommit(), TermPositions termPositions(), void SegmentReader(SegmentInfo si), boolean isDeleted(int n), Collection getIndexedFieldNames(boolean storedTermVector) ]
org.apache.lucene.index.SegmentReader.Norm =====> [ void reWrite(), void Norm(InputStream in, int number) ]
org.apache.lucene.index.SegmentTermDocs =====> [ void seek(Term term), void skippingDoc(), void seek(TermEnum termEnum), void SegmentTermPositions(SegmentReader p), int read(int[] docs, int[] freqs), void seek(TermInfo ti), int nextPosition(), void close(), boolean next(), boolean skipTo(int target), int freq(), void SegmentTermDocs(SegmentReader parent), void skipProx(long proxPointer), int doc() ]
org.apache.lucene.index.SegmentTermEnum =====> [ TermInfo termInfo(), void growBuffer(int length), void SegmentTermEnum(InputStream i, FieldInfos fis, boolean isi), void seek(long pointer, int p, Term t, TermInfo ti), void close(), boolean next(), int docFreq(), long proxPointer(), void termInfo(TermInfo ti), long freqPointer(), Term readTerm(), Term term() ]
org.apache.lucene.index.SegmentTermPositions =====> [ int nextPosition(), void close(), void skippingDoc(), boolean next(), void SegmentTermPositions(SegmentReader p), int read(int[] docs, int[] freqs), void skipProx(long proxPointer), void seek(TermInfo ti) ]
org.apache.lucene.index.SegmentTermVector =====> [ int size(), int[] getTermFrequencies(), int indexOf(String termText), void SegmentTermVector(String field, String[] terms, int[] termFreqs), String[] getTerms(), String getField(), int[] indexesOf(String[] termNumbers, int start, int len) ]
org.apache.lucene.index.Term =====> [ int compareTo(Term other), void Term(String fld, String txt, boolean intern), String text(), void set(String fld, String txt), int compareTo(Object other), void readObject(java.io.ObjectInputStream in), void Term(String fld, String txt), String field() ]
org.apache.lucene.index.TermDocs =====> [ void FilterTermDocs(TermDocs in), void seek(Term term), void MultiTermDocs(IndexReader[] r, int[] s), void skippingDoc(), boolean skipTo(int i), void seek(Term arg0), void MultiTermPositions(IndexReader[] r, int[] s), void seek(TermEnum termEnum), void SegmentTermPositions(SegmentReader p), int read(int[] docs, int[] freqs), void seek(TermInfo ti), void FilterTermPositions(TermPositions in), int nextPosition(), void close(), boolean next(), TermDocs termDocs(IndexReader reader), void MultipleTermPositions(IndexReader indexReader, Term[] terms), int read(int[] arg0, int[] arg1), boolean skipTo(int target), int freq(), TermDocs termDocs(int i), void SegmentTermDocs(SegmentReader parent), void skipProx(long proxPointer), int doc() ]
org.apache.lucene.index.TermEnum =====> [ void SegmentTermEnum(InputStream i, FieldInfos fis, boolean isi), void setEnum(TermEnum actualEnum), boolean wildcardEquals(String pattern, int patternIdx, String string, int stringIdx), int docFreq(), int min(int a, int b, int c), long proxPointer(), long freqPointer(), int editDistance(String s, String t, int n, int m), void seek(long pointer, int p, Term t, TermInfo ti), void close(), void FilterTermEnum(TermEnum in), boolean next(), float difference(), Term term(), boolean skipTo(Term target), TermInfo termInfo(), boolean termCompare(Term term), void FuzzyTermEnum(IndexReader reader, Term term), void termInfo(TermInfo ti), void MultiTermEnum(IndexReader[] readers, int[] starts, Term t), void FilteredTermEnum(), void growBuffer(int length), void WildcardTermEnum(IndexReader reader, Term term), boolean endEnum(), Term readTerm() ]
org.apache.lucene.index.TermFreqVector =====> [ int size(), int[] getTermFrequencies(), int indexOf(String termText), int[] indexesOf(String[] terms, int start, int len), void SegmentTermVector(String field, String[] terms, int[] termFreqs), void processTerms(String[] queryTerms), String getField(), int[] indexesOf(String[] termNumbers, int start, int len), int[] getTermPositions(int index), int indexOf(String term), void QueryTermVector(String[] queryTerms), String[] getTerms(), void QueryTermVector(String queryString, Analyzer analyzer) ]
org.apache.lucene.index.TermInfo =====> [ void TermInfo(TermInfo ti), void TermInfo(int df, long fp, long pp), void set(TermInfo ti), void TermInfo(), void set(int docFreq, long freqPointer, long proxPointer, int skipOffset) ]
org.apache.lucene.index.TermInfosReader =====> [ Term scanEnum(int position), SegmentTermEnum terms(), TermInfo get(Term term), void readIndex(), void seekEnum(int indexOffset), long size(), void TermInfosReader(Directory dir, String seg, FieldInfos fis), int getSkipInterval(), TermInfo scanEnum(Term term), Term get(int position), SegmentTermEnum terms(Term term), void close(), int getIndexOffset(Term term), SegmentTermEnum getEnum(), long getPosition(Term term) ]
org.apache.lucene.index.TermInfosWriter =====> [ void add(Term term, TermInfo ti), void initialize(Directory directory, String segment, FieldInfos fis, boolean isi), void close(), void writeTerm(Term term), void TermInfosWriter(Directory directory, String segment, FieldInfos fis, boolean isIndex), void TermInfosWriter(Directory directory, String segment, FieldInfos fis) ]
org.apache.lucene.index.TermPositionVector =====> [ int[] getTermPositions(int index) ]
org.apache.lucene.index.TermPositions =====> [ void skippingDoc(), void seek(Term arg0), void MultiTermPositions(IndexReader[] r, int[] s), void seek(TermEnum termEnum), void SegmentTermPositions(SegmentReader p), int read(int[] docs, int[] freqs), void seek(TermInfo ti), void FilterTermPositions(TermPositions in), int nextPosition(), void close(), TermDocs termDocs(IndexReader reader), void MultipleTermPositions(IndexReader indexReader, Term[] terms), boolean next(), int read(int[] arg0, int[] arg1), boolean skipTo(int target), int freq(), void skipProx(long proxPointer), int doc() ]
org.apache.lucene.index.TermVectorsReader =====> [ int size(), void checkValidFormat(InputStream in), void TermVectorsReader(Directory d, String segment, FieldInfos fieldInfos), void close(), SegmentTermVector readTermVector(String field, long tvfPointer), TermFreqVector get(int docNum, String field), TermFreqVector[] get(int docNum), SegmentTermVector[] readTermVectors(String[] fields, long[] tvfPointers) ]
org.apache.lucene.index.TermVectorsWriter =====> [ boolean isFieldOpen(), void closeDocument(), void addTermFreqVector(TermFreqVector vector), void writeDoc(), void closeField(), void addTermInternal(String termText, int freq), void TermVectorsWriter(Directory directory, String segment, FieldInfos fieldInfos), void openDocument(), void addTerm(String termText, int freq), void addTermFreqVectorInternal(TermFreqVector vector), void addVectors(TermFreqVector[] vectors), void close(), void openField(String field), boolean isDocumentOpen(), void writeField() ]
org.apache.lucene.index.TermVectorsWriter.TVField =====> [ void TVField(int number) ]
org.apache.lucene.queryParser.CharStream =====> [ void refill(), int getEndLine(), int getColumn(), char BeginToken(), String GetImage(), void backup(int amount), char readChar(), int getBeginColumn(), int getEndColumn(), int getLine(), int getBeginLine(), void FastCharStream(Reader r), char[] GetSuffix(int len), void Done() ]
org.apache.lucene.queryParser.FastCharStream =====> [ void refill(), int getEndLine(), int getColumn(), char BeginToken(), String GetImage(), void backup(int amount), char readChar(), int getBeginColumn(), int getEndColumn(), int getLine(), int getBeginLine(), void FastCharStream(Reader r), char[] GetSuffix(int len), void Done() ]
org.apache.lucene.queryParser.MultiFieldQueryParser =====> [ Query parse(String query, String[] fields, int[] flags, Analyzer analyzer), void MultiFieldQueryParser(QueryParserTokenManager tm), Query parse(String query, String[] fields, Analyzer analyzer), void MultiFieldQueryParser(CharStream stream), void MultiFieldQueryParser(String f, Analyzer a) ]
org.apache.lucene.queryParser.ParseException =====> [ void ParseException(), void ParseException(Token currentTokenVal, int[][] expectedTokenSequencesVal, String[] tokenImageVal), String add_escapes(String str), void ParseException(String message) ]
org.apache.lucene.queryParser.QueryParser =====> [ boolean jj_3_1(), Query parse(String query, String field, Analyzer analyzer), Query getFuzzyQuery(String field, String termStr), Token getToken(int index), Query parse(String query), void jj_la1_0(), int getOperator(), int jj_ntk(), Query getFieldQuery(String field, Analyzer analyzer, String queryText, int slop), void main(String[] args), void setOperator(int operator), boolean jj_scan_token(int kind), Locale getLocale(), void ReInit(CharStream stream), boolean getLowercaseWildcardTerms(), void enable_tracing(), Query parse(String query, String[] fields, Analyzer analyzer), Query Query(String field), void jj_rescan_token(), Query Term(String field), Query getWildcardQuery(String field, String termStr), Query Clause(String field), void ReInit(QueryParserTokenManager tm), Query getRangeQuery(String field, Analyzer analyzer, String part1, String part2, boolean inclusive), boolean jj_2_1(int xla), void jj_add_error_token(int kind, int pos), void setLowercaseWildcardTerms(boolean lowercaseWildcardTerms), void MultiFieldQueryParser(QueryParserTokenManager tm), Query getFieldQuery(String field, Analyzer analyzer, String queryText), Query parse(String query, String[] fields, int[] flags, Analyzer analyzer), Token jj_consume_token(int kind), void QueryParser(QueryParserTokenManager tm), ParseException generateParseException(), void jj_save(int index, int xla), void jj_la1_1(), Query getBooleanQuery(Vector clauses), void addClause(Vector clauses, int conj, int mods, Query q), void MultiFieldQueryParser(CharStream stream), void MultiFieldQueryParser(String f, Analyzer a), Query getPrefixQuery(String field, String termStr), void disable_tracing(), void setLocale(Locale locale), int Modifiers(), void QueryParser(CharStream stream), void setPhraseSlop(int phraseSlop), void QueryParser(String f, Analyzer a), int Conjunction(), String discardEscapeChar(String input), Token getNextToken(), int getPhraseSlop() ]
org.apache.lucene.queryParser.QueryParserConstants =====> [ boolean jj_3_1(), Query parse(String query, String field, Analyzer analyzer), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), Query getFuzzyQuery(String field, String termStr), Token getToken(int index), void ReInit(CharStream stream, int lexState), Query parse(String query), void jj_la1_0(), int getOperator(), int jj_ntk(), Query getFieldQuery(String field, Analyzer analyzer, String queryText, int slop), int jjMoveStringLiteralDfa0_0(), int jjStopAtPos(int pos, int kind), void main(String[] args), void setOperator(int operator), boolean jj_scan_token(int kind), void jjCheckNAddStates(int start, int end), int jjStartNfa_3(int pos, long active0), Locale getLocale(), int jjMoveStringLiteralDfa1_1(long active0), int jjStopStringLiteralDfa_1(int pos, long active0), int jjMoveStringLiteralDfa0_3(), void ReInit(CharStream stream), boolean getLowercaseWildcardTerms(), int jjMoveNfa_1(int startState, int curPos), int jjStartNfaWithStates_3(int pos, int kind, int state), void enable_tracing(), void ReInitRounds(), int jjStopStringLiteralDfa_2(int pos, long active0), Query parse(String query, String[] fields, Analyzer analyzer), Query Query(String field), void jj_rescan_token(), void jjCheckNAddStates(int start), Query Term(String field), int jjStartNfaWithStates_1(int pos, int kind, int state), int jjMoveStringLiteralDfa0_2(), int jjMoveNfa_2(int startState, int curPos), Query getWildcardQuery(String field, String termStr), Query Clause(String field), void ReInit(QueryParserTokenManager tm), int jjStartNfa_1(int pos, long active0), Query getRangeQuery(String field, Analyzer analyzer, String part1, String part2, boolean inclusive), int jjMoveNfa_0(int startState, int curPos), boolean jj_2_1(int xla), void jj_add_error_token(int kind, int pos), Token jjFillToken(), void setLowercaseWildcardTerms(boolean lowercaseWildcardTerms), void MultiFieldQueryParser(QueryParserTokenManager tm), void setDebugStream(java.io.PrintStream ds), Query getFieldQuery(String field, Analyzer analyzer, String queryText), int jjMoveStringLiteralDfa0_1(), int jjStartNfa_2(int pos, long active0), void QueryParserTokenManager(CharStream stream), Query parse(String query, String[] fields, int[] flags, Analyzer analyzer), void QueryParserTokenManager(CharStream stream, int lexState), Token jj_consume_token(int kind), void QueryParser(QueryParserTokenManager tm), ParseException generateParseException(), void jj_save(int index, int xla), void jj_la1_1(), void jjAddStates(int start, int end), Query getBooleanQuery(Vector clauses), void addClause(Vector clauses, int conj, int mods, Query q), void MultiFieldQueryParser(CharStream stream), void MultiFieldQueryParser(String f, Analyzer a), Query getPrefixQuery(String field, String termStr), void jjCheckNAdd(int state), int jjStartNfaWithStates_2(int pos, int kind, int state), void jjCheckNAddTwoStates(int state1, int state2), void disable_tracing(), void setLocale(Locale locale), int Modifiers(), void QueryParser(CharStream stream), void setPhraseSlop(int phraseSlop), void QueryParser(String f, Analyzer a), int Conjunction(), String discardEscapeChar(String input), Token getNextToken(), int getPhraseSlop(), void SwitchTo(int lexState), int jjMoveStringLiteralDfa1_2(long active0), int jjStopStringLiteralDfa_3(int pos, long active0), int jjMoveNfa_3(int startState, int curPos) ]
org.apache.lucene.queryParser.QueryParserTokenManager =====> [ int jjStartNfa_2(int pos, long active0), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), void QueryParserTokenManager(CharStream stream), void ReInit(CharStream stream, int lexState), void QueryParserTokenManager(CharStream stream, int lexState), int jjMoveStringLiteralDfa0_0(), int jjStopAtPos(int pos, int kind), void jjAddStates(int start, int end), void jjCheckNAddStates(int start, int end), int jjStartNfa_3(int pos, long active0), int jjMoveStringLiteralDfa1_1(long active0), int jjStopStringLiteralDfa_1(int pos, long active0), int jjMoveStringLiteralDfa0_3(), void ReInit(CharStream stream), int jjMoveNfa_1(int startState, int curPos), void jjCheckNAdd(int state), int jjStartNfaWithStates_3(int pos, int kind, int state), int jjStartNfaWithStates_2(int pos, int kind, int state), void jjCheckNAddTwoStates(int state1, int state2), void ReInitRounds(), int jjStopStringLiteralDfa_2(int pos, long active0), void jjCheckNAddStates(int start), Token getNextToken(), int jjStartNfaWithStates_1(int pos, int kind, int state), int jjMoveStringLiteralDfa0_2(), int jjMoveNfa_2(int startState, int curPos), int jjStartNfa_1(int pos, long active0), void SwitchTo(int lexState), int jjMoveNfa_0(int startState, int curPos), Token jjFillToken(), int jjMoveStringLiteralDfa1_2(long active0), void setDebugStream(java.io.PrintStream ds), int jjStopStringLiteralDfa_3(int pos, long active0), int jjMoveNfa_3(int startState, int curPos), int jjMoveStringLiteralDfa0_1() ]
org.apache.lucene.queryParser.Token =====> [ Token newToken(int ofKind) ]
org.apache.lucene.queryParser.TokenMgrError =====> [ String LexicalError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar), void TokenMgrError(String message, int reason), void TokenMgrError(), void TokenMgrError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar, int reason), String addEscapes(String str) ]
org.apache.lucene.search.BooleanClause =====> [ void BooleanClause(Query q, boolean r, boolean p) ]
org.apache.lucene.search.BooleanQuery =====> [ void add(Query query, boolean required, boolean prohibited), BooleanClause[] getClauses(), Weight createWeight(Searcher searcher), String toString(String field), int getMaxClauseCount(), void BooleanQuery(), void setMaxClauseCount(int maxClauseCount), void add(BooleanClause clause), Query rewrite(IndexReader reader) ]
org.apache.lucene.search.BooleanQuery.BooleanWeight =====> [ float sumOfSquaredWeights(), void normalize(float norm), void BooleanWeight(Searcher searcher), Scorer scorer(IndexReader reader), float getValue(), Explanation explain(IndexReader reader, int doc), Query getQuery() ]
org.apache.lucene.search.BooleanScorer =====> [ void add(Scorer scorer, boolean required, boolean prohibited), Explanation explain(int doc), void BooleanScorer(Similarity similarity), void computeCoordFactors(), boolean next(), boolean skipTo(int target), float score(), int doc() ]
org.apache.lucene.search.BooleanScorer.BucketTable =====> [ int size(), HitCollector newCollector(int mask), void BucketTable(BooleanScorer scorer) ]
org.apache.lucene.search.BooleanScorer.Collector =====> [ void collect(int doc, float score), void Collector(int mask, BucketTable bucketTable) ]
org.apache.lucene.search.BooleanScorer.SubScorer =====> [ void SubScorer(Scorer scorer, boolean required, boolean prohibited, HitCollector collector, SubScorer next) ]
org.apache.lucene.search.CachingWrapperFilter =====> [ void CachingWrapperFilter(Filter filter), BitSet bits(IndexReader reader) ]
org.apache.lucene.search.ConjunctionScorer =====> [ void add(Scorer scorer), Explanation explain(int doc), boolean next(), Scorer first(), boolean skipTo(int target), void sortScorers(), float score(), Scorer last(), boolean doNext(), void init(), void ConjunctionScorer(Similarity similarity), int doc() ]
org.apache.lucene.search.DateFilter =====> [ DateFilter Before(String field, Date date), DateFilter Before(String field, long time), DateFilter After(String field, long time), BitSet bits(IndexReader reader), void DateFilter(String f, Date from, Date to), void DateFilter(String f, long from, long to), void DateFilter(String f), DateFilter After(String field, Date date) ]
org.apache.lucene.search.DefaultSimilarity =====> [ float queryNorm(float sumOfSquaredWeights), float sloppyFreq(int distance), float idf(int docFreq, int numDocs), float tf(float freq), float lengthNorm(String fieldName, int numTerms), float coord(int overlap, int maxOverlap) ]
org.apache.lucene.search.ExactPhraseScorer =====> [ void ExactPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), float phraseFreq() ]
org.apache.lucene.search.Explanation =====> [ void Explanation(float value, String description), void Explanation(), String getDescription(), void addDetail(Explanation detail), float getValue(), void setValue(float value), String toHtml(), String toString(int depth), void setDescription(String description), Explanation[] getDetails() ]
org.apache.lucene.search.FieldCache =====> [ float[] getFloats(IndexReader reader, String field), String[] getStrings(IndexReader reader, String field), int[] getInts(IndexReader reader, String field), Comparable[] getCustom(IndexReader reader, String field, SortComparator comparator), Object lookup(IndexReader reader, String field, Object comparer), Object store(IndexReader reader, String field, Object comparer, Object value), Object lookup(IndexReader reader, String field, int type), Object store(IndexReader reader, String field, int type, Object value), Object getAuto(IndexReader reader, String field), StringIndex getStringIndex(IndexReader reader, String field) ]
org.apache.lucene.search.FieldCache.StringIndex =====> [ void StringIndex(int[] values, String[] lookup) ]
org.apache.lucene.search.FieldCacheImpl =====> [ float[] getFloats(IndexReader reader, String field), String[] getStrings(IndexReader reader, String field), int[] getInts(IndexReader reader, String field), Comparable[] getCustom(IndexReader reader, String field, SortComparator comparator), Object lookup(IndexReader reader, String field, Object comparer), Object store(IndexReader reader, String field, Object comparer, Object value), Object lookup(IndexReader reader, String field, int type), Object store(IndexReader reader, String field, int type, Object value), Object getAuto(IndexReader reader, String field), StringIndex getStringIndex(IndexReader reader, String field) ]
org.apache.lucene.search.FieldCacheImpl.Entry =====> [ void Entry(IndexReader reader, String field, Object custom), void Entry(IndexReader reader, String field, int type) ]
org.apache.lucene.search.FieldDoc =====> [ void FieldDoc(int doc, float score), void FieldDoc(int doc, float score, Comparable[] fields) ]
org.apache.lucene.search.FieldDocSortedHitQueue =====> [ void setFields(SortField[] fields), void FieldDocSortedHitQueue(SortField[] fields, int size), SortField[] getFields(), boolean lessThan(Object a, Object b), Collator[] hasCollators(SortField[] fields) ]
org.apache.lucene.search.FieldSortedHitQueue =====> [ ScoreDocComparator comparatorFloat(IndexReader reader, String fieldname), FieldDoc fillFields(FieldDoc doc), ScoreDocComparator getCachedComparator(IndexReader reader, String fieldname, int type, Locale locale, SortComparatorSource factory), ScoreDocComparator comparatorStringLocale(IndexReader reader, String fieldname, Locale locale), void FieldSortedHitQueue(IndexReader reader, SortField[] fields, int size), SortField[] getFields(), ScoreDocComparator lookup(IndexReader reader, String field, int type, Object factory), ScoreDocComparator comparatorString(IndexReader reader, String fieldname), boolean lessThan(Object a, Object b), Object store(IndexReader reader, String field, int type, Object factory, Object value), ScoreDocComparator comparatorInt(IndexReader reader, String fieldname), ScoreDocComparator comparatorAuto(IndexReader reader, String fieldname) ]
org.apache.lucene.search.Filter =====> [ void CachingWrapperFilter(Filter filter), DateFilter Before(String field, Date date), DateFilter Before(String field, long time), DateFilter After(String field, long time), void QueryFilter(Query query), BitSet bits(IndexReader reader), void DateFilter(String f, Date from, Date to), void DateFilter(String f, long from, long to), void DateFilter(String f), DateFilter After(String field, Date date) ]
org.apache.lucene.search.FilteredQuery =====> [ void FilteredQuery(Query query, Filter filter), Weight createWeight(Searcher searcher), Query getQuery(), Query rewrite(IndexReader reader), String toString(String s) ]
org.apache.lucene.search.FilteredTermEnum =====> [ void setEnum(TermEnum actualEnum), boolean wildcardEquals(String pattern, int patternIdx, String string, int stringIdx), boolean termCompare(Term term), int docFreq(), void FuzzyTermEnum(IndexReader reader, Term term), int min(int a, int b, int c), int editDistance(String s, String t, int n, int m), void FilteredTermEnum(), void close(), boolean next(), void WildcardTermEnum(IndexReader reader, Term term), float difference(), boolean endEnum(), Term term() ]
org.apache.lucene.search.FuzzyQuery =====> [ FilteredTermEnum getEnum(IndexReader reader), String toString(String field), void FuzzyQuery(Term term) ]
org.apache.lucene.search.FuzzyTermEnum =====> [ void close(), boolean termCompare(Term term), float difference(), void FuzzyTermEnum(IndexReader reader, Term term), int min(int a, int b, int c), boolean endEnum(), int editDistance(String s, String t, int n, int m) ]
org.apache.lucene.search.HitCollector =====> [ void collect(int doc, float score), void Collector(int mask, BucketTable bucketTable) ]
org.apache.lucene.search.HitDoc =====> [ void HitDoc(float s, int i) ]
org.apache.lucene.search.HitQueue =====> [ boolean lessThan(Object a, Object b), void HitQueue(int size) ]
org.apache.lucene.search.Hits =====> [ HitDoc hitDoc(int n), void getMoreDocs(int min), void Hits(Searcher s, Query q, Filter f, Sort o), void Hits(Searcher s, Query q, Filter f), void remove(HitDoc hitDoc), int length(), int id(int n), void addToFront(HitDoc hitDoc), Document doc(int n), float score(int n) ]
org.apache.lucene.search.IndexSearcher =====> [ Explanation explain(Query query, int doc), void IndexSearcher(IndexReader r), void search(Query query, Filter filter, HitCollector results), TopDocs search(Query query, Filter filter, int nDocs), Query rewrite(Query original), void IndexSearcher(String path), Document doc(int i), void IndexSearcher(IndexReader r, boolean closeReader), int docFreq(Term term), int maxDoc(), void close(), void IndexSearcher(Directory directory), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort) ]
org.apache.lucene.search.MultiSearcher =====> [ Explanation explain(Query query, int doc), void search(Query query, Filter filter, HitCollector results), TopDocs search(Query query, Filter filter, int nDocs), Query rewrite(Query original), void ParallelMultiSearcher(Searchable[] searchables), Document doc(int n), int subDoc(int n), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), int[] getStarts(), void MultiSearcher(Searchable[] searchables), int docFreq(Term term), int subSearcher(int n), int maxDoc(), void close(), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int searcherIndex(int n) ]
org.apache.lucene.search.MultiSearcherThread =====> [ IOException getIOException(), void MultiSearcherThread(Searchable searchable, Query query, Filter filter, int nDocs, FieldDocSortedHitQueue hq, Sort sort, int i, int[] starts, String name), int hits(), void MultiSearcherThread(Searchable searchable, Query query, Filter filter, int nDocs, HitQueue hq, int i, int[] starts, String name) ]
org.apache.lucene.search.MultiTermQuery =====> [ void WildcardQuery(Term term), FilteredTermEnum getEnum(IndexReader reader), void MultiTermQuery(Term term), Query combine(Query[] queries), String toString(String field), void FuzzyQuery(Term term), Term getTerm(), Query rewrite(IndexReader reader) ]
org.apache.lucene.search.ParallelMultiSearcher =====> [ int docFreq(Term term), void search(Query query, Filter filter, HitCollector results), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), Query rewrite(Query original), void ParallelMultiSearcher(Searchable[] searchables) ]
org.apache.lucene.search.PhrasePositions =====> [ boolean next(), boolean skipTo(int target), boolean nextPosition(), void firstPosition(), void PhrasePositions(TermPositions t, int o) ]
org.apache.lucene.search.PhrasePrefixQuery =====> [ int getSlop(), void add(Term[] terms), String toString(String f), Weight createWeight(Searcher searcher), void setSlop(int s), void add(Term term) ]
org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight =====> [ float sumOfSquaredWeights(), void PhrasePrefixWeight(Searcher searcher), Scorer scorer(IndexReader reader), float getValue(), Explanation explain(IndexReader reader, int doc), Query getQuery(), void normalize(float queryNorm) ]
org.apache.lucene.search.PhraseQuery =====> [ void PhraseQuery(), int getSlop(), String toString(String f), Weight createWeight(Searcher searcher), Term[] getTerms(), void setSlop(int s), void add(Term term) ]
org.apache.lucene.search.PhraseQuery.PhraseWeight =====> [ float sumOfSquaredWeights(), void PhraseWeight(Searcher searcher), Scorer scorer(IndexReader reader), float getValue(), Explanation explain(IndexReader reader, int doc), Query getQuery(), void normalize(float queryNorm) ]
org.apache.lucene.search.PhraseQueue =====> [ boolean lessThan(Object o1, Object o2), void PhraseQueue(int size) ]
org.apache.lucene.search.PhraseScorer =====> [ Explanation explain(int doc), void PhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), float score(), void ExactPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void init(), float phraseFreq(), void firstToLast(), void sort(), boolean next(), boolean skipTo(int target), boolean doNext(), void pqToList(), int doc(), void SloppyPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, int slop, byte[] norms) ]
org.apache.lucene.search.PrefixQuery =====> [ Term getPrefix(), Query combine(Query[] queries), String toString(String field), void PrefixQuery(Term prefix), Query rewrite(IndexReader reader) ]
org.apache.lucene.search.Query =====> [ void SpanTermQuery(Term term), Query mergeBooleanQueries(Query[] queries), Similarity getSimilarity(Searcher searcher), void FuzzyQuery(Term term), void BooleanQuery(), int getEnd(), Weight createWeight(Searcher searcher), BooleanClause[] getClauses(), float getBoost(), void setBoost(float b), void PhraseQuery(), SpanQuery getMatch(), void PrefixQuery(Term prefix), void add(BooleanClause clause), void FilteredQuery(Query query, Filter filter), String toString(String field), SpanQuery getExclude(), void add(Term term), Term getTerm(), void add(Term[] terms), void WildcardQuery(Term term), FilteredTermEnum getEnum(IndexReader reader), Query combine(Query[] queries), SpanQuery[] getClauses(), boolean isInOrder(), void SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder), Query getQuery(), String getField(), String toString(String s), Term[] getTerms(), Weight weight(Searcher searcher), Spans getSpans(IndexReader reader), int getSlop(), Collection getTerms(), void add(Query query, boolean required, boolean prohibited), void MultiTermQuery(Term term), int getMaxClauseCount(), void SpanNotQuery(SpanQuery include, SpanQuery exclude), void SpanOrQuery(SpanQuery[] clauses), void setMaxClauseCount(int maxClauseCount), boolean isInclusive(), void RangeQuery(Term lowerTerm, Term upperTerm, boolean inclusive), String toString(String f), Term getUpperTerm(), Term getPrefix(), void TermQuery(Term t), SpanQuery getInclude(), Term getLowerTerm(), void setSlop(int s), void SpanFirstQuery(SpanQuery match, int end), Query rewrite(IndexReader reader) ]
org.apache.lucene.search.QueryFilter =====> [ void QueryFilter(Query query), BitSet bits(IndexReader reader) ]
org.apache.lucene.search.QueryTermVector =====> [ int size(), int[] getTermFrequencies(), int[] indexesOf(String[] terms, int start, int len), void QueryTermVector(String[] queryTerms), int indexOf(String term), void processTerms(String[] queryTerms), String[] getTerms(), void QueryTermVector(String queryString, Analyzer analyzer), String getField() ]
org.apache.lucene.search.RangeQuery =====> [ void RangeQuery(Term lowerTerm, Term upperTerm, boolean inclusive), Term getUpperTerm(), Query combine(Query[] queries), Term getLowerTerm(), String toString(String field), String getField(), boolean isInclusive(), Query rewrite(IndexReader reader) ]
org.apache.lucene.search.RemoteSearchable =====> [ Explanation explain(Query query, int doc), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results), void RemoteSearchable(Searchable local), TopDocs search(Query query, Filter filter, int n), Query rewrite(Query original), void main(String[] args), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), Document doc(int i) ]
org.apache.lucene.search.ScoreDoc =====> [ void FieldDoc(int doc, float score), void ScoreDoc(int doc, float score), void FieldDoc(int doc, float score, Comparable[] fields) ]
org.apache.lucene.search.ScoreDocComparator =====> [ Comparable sortValue(ScoreDoc i), int compare(ScoreDoc i, ScoreDoc j), int sortType() ]
org.apache.lucene.search.Scorer =====> [ void add(Scorer scorer), void Scorer(Similarity similarity), void add(Scorer scorer, boolean required, boolean prohibited), void computeCoordFactors(), void sortScorers(), Scorer last(), void init(), void SpanScorer(Spans spans, Weight weight, Similarity similarity, byte[] norms), float phraseFreq(), void TermScorer(Weight weight, TermDocs td, Similarity similarity, byte[] norms), boolean next(), boolean skipTo(int target), Scorer first(), boolean doNext(), void ConjunctionScorer(Similarity similarity), Explanation explain(int doc), void PhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void BooleanScorer(Similarity similarity), Similarity getSimilarity(), float score(), void ExactPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void firstToLast(), void sort(), void score(HitCollector hc), void pqToList(), int doc(), void SloppyPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, int slop, byte[] norms) ]
org.apache.lucene.search.Searchable =====> [ Explanation explain(Query query, int doc), void search(Query query, HitCollector results), void setSimilarity(Similarity similarity), void IndexSearcher(IndexReader r), void search(Query query, Filter filter, HitCollector results), Hits search(Query query, Filter filter, Sort sort), Query rewrite(Query original), void main(String[] args), Document doc(int n), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), void IndexSearcher(String path), Hits search(Query query, Filter filter), int[] getStarts(), void MultiSearcher(Searchable[] searchables), int maxDoc(), int subSearcher(int n), void close(), Hits search(Query query), void IndexSearcher(Directory directory), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int searcherIndex(int n), Hits search(Query query, Sort sort), Query rewrite(Query query), TopDocs search(Query query, Filter filter, int nDocs), Similarity getSimilarity(), void ParallelMultiSearcher(Searchable[] searchables), int subDoc(int n), Document doc(int i), void IndexSearcher(IndexReader r, boolean closeReader), int docFreq(Term term), TopDocs search(Query query, Filter filter, int n), void RemoteSearchable(Searchable local) ]
org.apache.lucene.search.Searcher =====> [ void search(Query query, HitCollector results), Explanation explain(Query query, int doc), void setSimilarity(Similarity similarity), void IndexSearcher(IndexReader r), void search(Query query, Filter filter, HitCollector results), Hits search(Query query, Filter filter, Sort sort), Query rewrite(Query original), Document doc(int n), void IndexSearcher(String path), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), Hits search(Query query, Filter filter), int[] getStarts(), void MultiSearcher(Searchable[] searchables), int maxDoc(), int subSearcher(int n), Hits search(Query query), void close(), void IndexSearcher(Directory directory), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int searcherIndex(int n), Hits search(Query query, Sort sort), TopDocs search(Query query, Filter filter, int nDocs), Similarity getSimilarity(), void ParallelMultiSearcher(Searchable[] searchables), int subDoc(int n), Document doc(int i), void IndexSearcher(IndexReader r, boolean closeReader), int docFreq(Term term) ]
org.apache.lucene.search.Similarity =====> [ float lengthNorm(String fieldName, int numTokens), float queryNorm(float sumOfSquaredWeights), Similarity getDefault(), float idf(int docFreq, int numDocs), void setDefault(Similarity similarity), float idf(Term term, Searcher searcher), float lengthNorm(String fieldName, int numTerms), float byteToFloat(byte b), byte encodeNorm(float f), float sloppyFreq(int distance), float tf(float freq), float idf(Collection terms, Searcher searcher), float tf(int freq), byte floatToByte(float f), float decodeNorm(byte b), float coord(int overlap, int maxOverlap) ]
org.apache.lucene.search.SloppyPhraseScorer =====> [ float phraseFreq(), void SloppyPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, int slop, byte[] norms) ]
org.apache.lucene.search.Sort =====> [ void setSort(String[] fieldnames), void setSort(SortField[] fields), void Sort(), void Sort(String field, boolean reverse), void Sort(SortField field), void Sort(SortField[] fields), void Sort(String field), void setSort(SortField field), void setSort(String field), void Sort(String[] fields), void setSort(String field, boolean reverse) ]
org.apache.lucene.search.SortComparator =====> [ Comparable getComparable(String termtext), ScoreDocComparator newComparator(IndexReader reader, String fieldname) ]
org.apache.lucene.search.SortComparatorSource =====> [ Comparable getComparable(String termtext), ScoreDocComparator newComparator(IndexReader reader, String fieldname) ]
org.apache.lucene.search.SortField =====> [ void SortField(String field, Locale locale), void SortField(String field, SortComparatorSource comparator), void SortField(String field, int type), boolean getReverse(), void SortField(String field, SortComparatorSource comparator, boolean reverse), SortComparatorSource getFactory(), String getField(), int getType(), void SortField(String field, boolean reverse), void SortField(String field, Locale locale, boolean reverse), void SortField(String field, int type, boolean reverse), Locale getLocale(), void SortField(String field) ]
org.apache.lucene.search.TermQuery =====> [ void TermQuery(Term t), Weight createWeight(Searcher searcher), String toString(String field), Term getTerm() ]
org.apache.lucene.search.TermQuery.TermWeight =====> [ float sumOfSquaredWeights(), void TermWeight(Searcher searcher), Scorer scorer(IndexReader reader), float getValue(), Explanation explain(IndexReader reader, int doc), Query getQuery(), void normalize(float queryNorm) ]
org.apache.lucene.search.TermScorer =====> [ Explanation explain(int doc), void TermScorer(Weight weight, TermDocs td, Similarity similarity, byte[] norms), boolean next(), boolean skipTo(int target), float score(), int doc() ]
org.apache.lucene.search.TopDocs =====> [ void TopFieldDocs(int totalHits, ScoreDoc[] scoreDocs, SortField[] fields), void TopDocs(int totalHits, ScoreDoc[] scoreDocs) ]
org.apache.lucene.search.TopFieldDocs =====> [ void TopFieldDocs(int totalHits, ScoreDoc[] scoreDocs, SortField[] fields) ]
org.apache.lucene.search.Weight =====> [ float sumOfSquaredWeights(), void normalize(float norm), void SpanWeight(SpanQuery query, Searcher searcher), void BooleanWeight(Searcher searcher), void PhraseWeight(Searcher searcher), void TermWeight(Searcher searcher), void PhrasePrefixWeight(Searcher searcher), Scorer scorer(IndexReader reader), float getValue(), Explanation explain(IndexReader reader, int doc), Query getQuery(), void normalize(float queryNorm) ]
org.apache.lucene.search.WildcardQuery =====> [ void WildcardQuery(Term term), FilteredTermEnum getEnum(IndexReader reader) ]
org.apache.lucene.search.WildcardTermEnum =====> [ void close(), boolean wildcardEquals(String pattern, int patternIdx, String string, int stringIdx), void WildcardTermEnum(IndexReader reader, Term term), boolean termCompare(Term term), float difference(), boolean endEnum() ]
org.apache.lucene.search.spans.NearSpans =====> [ int end(), void partialListToQueue(), SpansCell min(), void queueToList(), boolean firstNonOrderedNextToPartialList(), boolean atMatch(), int start(), void firstToLast(), void initList(boolean next), boolean checkSlop(), boolean matchIsOrdered(), void listToQueue(), boolean next(), boolean skipTo(int target), void NearSpans(SpanNearQuery query, IndexReader reader), void addToList(SpansCell cell), int doc() ]
org.apache.lucene.search.spans.NearSpans.CellQueue =====> [ boolean lessThan(Object o1, Object o2), void CellQueue(int size) ]
org.apache.lucene.search.spans.NearSpans.SpansCell =====> [ int end(), boolean next(), boolean skipTo(int target), void SpansCell(Spans spans, int index), int doc(), int start() ]
org.apache.lucene.search.spans.SpanFirstQuery =====> [ Collection getTerms(), int getEnd(), SpanQuery getMatch(), String toString(String field), void SpanFirstQuery(SpanQuery match, int end), Spans getSpans(IndexReader reader), String getField() ]
org.apache.lucene.search.spans.SpanNearQuery =====> [ int getSlop(), Collection getTerms(), SpanQuery[] getClauses(), boolean isInOrder(), String toString(String field), void SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder), Spans getSpans(IndexReader reader), String getField() ]
org.apache.lucene.search.spans.SpanNotQuery =====> [ Collection getTerms(), SpanQuery getInclude(), String toString(String field), SpanQuery getExclude(), void SpanNotQuery(SpanQuery include, SpanQuery exclude), Spans getSpans(IndexReader reader), String getField() ]
org.apache.lucene.search.spans.SpanOrQuery =====> [ Collection getTerms(), SpanQuery[] getClauses(), String toString(String field), void SpanOrQuery(SpanQuery[] clauses), Spans getSpans(IndexReader reader), String getField() ]
org.apache.lucene.search.spans.SpanOrQuery.SpanQueue =====> [ boolean lessThan(Object o1, Object o2), void SpanQueue(int size) ]
org.apache.lucene.search.spans.SpanQuery =====> [ int getSlop(), Collection getTerms(), void SpanTermQuery(Term term), SpanQuery[] getClauses(), boolean isInOrder(), SpanQuery getMatch(), void SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder), void SpanNotQuery(SpanQuery include, SpanQuery exclude), void SpanOrQuery(SpanQuery[] clauses), String getField(), int getEnd(), Weight createWeight(Searcher searcher), SpanQuery getInclude(), String toString(String field), SpanQuery getExclude(), Spans getSpans(IndexReader reader), void SpanFirstQuery(SpanQuery match, int end), Term getTerm() ]
org.apache.lucene.search.spans.SpanScorer =====> [ Explanation explain(int doc), boolean next(), boolean skipTo(int target), float score(), void SpanScorer(Spans spans, Weight weight, Similarity similarity, byte[] norms), int doc() ]
org.apache.lucene.search.spans.SpanTermQuery =====> [ Collection getTerms(), void SpanTermQuery(Term term), String toString(String field), Spans getSpans(IndexReader reader), String getField(), Term getTerm() ]
org.apache.lucene.search.spans.SpanWeight =====> [ void SpanWeight(SpanQuery query, Searcher searcher), float sumOfSquaredWeights(), Scorer scorer(IndexReader reader), float getValue(), Explanation explain(IndexReader reader, int doc), Query getQuery(), void normalize(float queryNorm) ]
org.apache.lucene.search.spans.Spans =====> [ int end(), void partialListToQueue(), SpansCell min(), void queueToList(), boolean firstNonOrderedNextToPartialList(), boolean atMatch(), int start(), void firstToLast(), void initList(boolean next), boolean checkSlop(), boolean matchIsOrdered(), void listToQueue(), boolean next(), boolean skipTo(int target), void SpansCell(Spans spans, int index), void NearSpans(SpanNearQuery query, IndexReader reader), void addToList(SpansCell cell), int doc() ]
org.apache.lucene.store.Directory =====> [ void RAMDirectory(String dir), InputStream openFile(String name), void touchFile(String name), void CompoundFileReader(Directory dir, String name), long fileModified(File directory, String name), StringBuffer getLockPrefix(), void renameFile(String from, String to), void deleteFile(String name), void create(), void RAMDirectory(File dir), String getName(), boolean fileExists(String name), void close(), void FSDirectory(File path, boolean create), Lock makeLock(String name), FSDirectory getDirectory(String path, boolean create), void RAMDirectory(Directory dir, boolean closeDir), void RAMDirectory(), long fileLength(String name), OutputStream createFile(String name), File getFile(), void RAMDirectory(Directory dir), Directory getDirectory(), String[] list(), FSDirectory getDirectory(File file, boolean create), long fileModified(String name), InputStream openFile(String id) ]
org.apache.lucene.store.FSDirectory =====> [ InputStream openFile(String name), long fileLength(String name), OutputStream createFile(String name), File getFile(), void touchFile(String name), long fileModified(File directory, String name), StringBuffer getLockPrefix(), void renameFile(String from, String to), void create(), void deleteFile(String name), boolean fileExists(String name), String[] list(), void close(), FSDirectory getDirectory(File file, boolean create), long fileModified(String name), void FSDirectory(File path, boolean create), Lock makeLock(String name), FSDirectory getDirectory(String path, boolean create) ]
org.apache.lucene.store.FSInputStream =====> [ void close(), void FSInputStream(File path), void readInternal(byte[] b, int offset, int len), boolean isFDValid(), void seekInternal(long position) ]
org.apache.lucene.store.FSInputStream.Descriptor =====> [ void Descriptor(File file, String mode) ]
org.apache.lucene.store.FSOutputStream =====> [ void FSOutputStream(File path), void close(), long length(), void flushBuffer(byte[] b, int size), void seek(long pos) ]
org.apache.lucene.store.InputStream =====> [ void refill(), int readVInt(), void readInternal(byte[] dest, int destOffset, int len), String readString(), void readInternal(byte[] b, int offset, int length), int readInt(), void readChars(char[] buffer, int start, int length), void seekInternal(long position), void close(), long getFilePointer(), void seekInternal(long pos), void CSInputStream(InputStream base, long fileOffset, long length), long length(), long readVLong(), void FSInputStream(File path), void RAMInputStream(RAMFile f), long readLong(), byte readByte(), void readBytes(byte[] b, int offset, int len), void readInternal(byte[] b, int offset, int len), boolean isFDValid(), void seek(long pos) ]
org.apache.lucene.store.Lock =====> [ void release(), boolean obtain(long lockWaitTimeout), boolean obtain(), boolean isLocked() ]
org.apache.lucene.store.Lock.With =====> [ void With(Lock lock, long lockWaitTimeout), Object run(), void With(Lock lock), Object doBody() ]
org.apache.lucene.store.OutputStream =====> [ void writeChars(String s, int start, int length), void RAMOutputStream(), void writeTo(OutputStream out), void reset(), void writeByte(byte b), void RAMOutputStream(RAMFile f), void writeLong(long i), void FSOutputStream(File path), void writeVLong(long i), void flushBuffer(byte[] b, int len), void close(), long getFilePointer(), long length(), void flushBuffer(byte[] src, int len), void writeInt(int i), void writeBytes(byte[] b, int length), void writeVInt(int i), void flush(), void flushBuffer(byte[] b, int size), void writeString(String s), void seek(long pos) ]
org.apache.lucene.store.RAMDirectory =====> [ void RAMDirectory(), void RAMDirectory(String dir), InputStream openFile(String name), long fileLength(String name), OutputStream createFile(String name), void touchFile(String name), void RAMDirectory(Directory dir), void renameFile(String from, String to), void RAMDirectory(File dir), void deleteFile(String name), boolean fileExists(String name), String[] list(), void close(), long fileModified(String name), Lock makeLock(String name), void RAMDirectory(Directory dir, boolean closeDir) ]
org.apache.lucene.store.RAMInputStream =====> [ void readInternal(byte[] dest, int destOffset, int len), void close(), void seekInternal(long pos), void RAMInputStream(RAMFile f) ]
org.apache.lucene.store.RAMOutputStream =====> [ void RAMOutputStream(RAMFile f), void RAMOutputStream(), void close(), void writeTo(OutputStream out), void reset(), long length(), void flushBuffer(byte[] src, int len), void seek(long pos) ]
org.apache.lucene.util.BitVector =====> [ int size(), int count(), void BitVector(Directory d, String name), boolean get(int bit), void write(Directory d, String name), void BitVector(int n), void clear(int bit), void set(int bit) ]
org.apache.lucene.util.Constants =====> [ void Constants() ]
org.apache.lucene.util.PriorityQueue =====> [ int size(), Object top(), ScoreDocComparator comparatorFloat(IndexReader reader, String fieldname), void FieldDocSortedHitQueue(SortField[] fields, int size), Object pop(), boolean insert(Object element), Object store(IndexReader reader, String field, int type, Object factory, Object value), void SpanQueue(int size), void put(Object element), TermPositions peek(), FieldDoc fillFields(FieldDoc doc), ScoreDocComparator getCachedComparator(IndexReader reader, String fieldname, int type, Locale locale, SortComparatorSource factory), void SegmentMergeQueue(int size), void close(), ScoreDocComparator comparatorStringLocale(IndexReader reader, String fieldname, Locale locale), SortField[] getFields(), ScoreDocComparator comparatorString(IndexReader reader, String fieldname), Collator[] hasCollators(SortField[] fields), void PhraseQueue(int size), void TermPositionsQueue(List termPositions), void setFields(SortField[] fields), void upHeap(), void initialize(int maxSize), ScoreDocComparator lookup(IndexReader reader, String field, int type, Object factory), boolean lessThan(Object a, Object b), void CellQueue(int size), void downHeap(), ScoreDocComparator comparatorAuto(IndexReader reader, String fieldname), void HitQueue(int size), boolean lessThan(Object o1, Object o2), void clear(), void FieldSortedHitQueue(IndexReader reader, SortField[] fields, int size), ScoreDocComparator comparatorInt(IndexReader reader, String fieldname), void adjustTop() ]
org.apache.lucene.util.StringHelper =====> [ void StringHelper(), int stringDifference(String s1, String s2) ]

Done building lattice!
NODE_0[[org.apache.lucene.analysis.Analyzer, org.apache.lucene.analysis.CharTokenizer, org.apache.lucene.analysis.LetterTokenizer, org.apache.lucene.analysis.LowerCaseFilter, org.apache.lucene.analysis.LowerCaseTokenizer, org.apache.lucene.analysis.PerFieldAnalyzerWrapper, org.apache.lucene.analysis.PorterStemFilter, org.apache.lucene.analysis.PorterStemmer, org.apache.lucene.analysis.SimpleAnalyzer, org.apache.lucene.analysis.StopAnalyzer, org.apache.lucene.analysis.StopFilter, org.apache.lucene.analysis.Token, org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer, org.apache.lucene.analysis.WhitespaceAnalyzer, org.apache.lucene.analysis.WhitespaceTokenizer, org.apache.lucene.analysis.de.GermanAnalyzer, org.apache.lucene.analysis.de.GermanStemFilter, org.apache.lucene.analysis.de.GermanStemmer, org.apache.lucene.analysis.de.WordlistLoader, org.apache.lucene.analysis.ru.RussianAnalyzer, org.apache.lucene.analysis.ru.RussianCharsets, org.apache.lucene.analysis.ru.RussianLetterTokenizer, org.apache.lucene.analysis.ru.RussianLowerCaseFilter, org.apache.lucene.analysis.ru.RussianStemFilter, org.apache.lucene.analysis.ru.RussianStemmer, org.apache.lucene.analysis.standard.CharStream, org.apache.lucene.analysis.standard.FastCharStream, org.apache.lucene.analysis.standard.ParseException, org.apache.lucene.analysis.standard.StandardAnalyzer, org.apache.lucene.analysis.standard.StandardFilter, org.apache.lucene.analysis.standard.StandardTokenizer, org.apache.lucene.analysis.standard.StandardTokenizerConstants, org.apache.lucene.analysis.standard.StandardTokenizerTokenManager, org.apache.lucene.analysis.standard.Token, org.apache.lucene.analysis.standard.TokenMgrError, org.apache.lucene.document.DateField, org.apache.lucene.document.Document, org.apache.lucene.document.Field, org.apache.lucene.index.CompoundFileReader, org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.index.CompoundFileWriter, org.apache.lucene.index.DocumentWriter, org.apache.lucene.index.FieldInfo, org.apache.lucene.index.FieldInfos, org.apache.lucene.index.FieldsReader, org.apache.lucene.index.FieldsWriter, org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.FilterIndexReader.FilterTermPositions, org.apache.lucene.index.IndexReader, org.apache.lucene.index.IndexWriter, org.apache.lucene.index.MultiReader, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.MultiTermPositions, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.MultipleTermPositions.IntQueue, org.apache.lucene.index.MultipleTermPositions.TermPositionsQueue, org.apache.lucene.index.Posting, org.apache.lucene.index.SegmentInfo, org.apache.lucene.index.SegmentInfos, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.index.SegmentMergeQueue, org.apache.lucene.index.SegmentMerger, org.apache.lucene.index.SegmentReader, org.apache.lucene.index.SegmentReader.Norm, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.SegmentTermVector, org.apache.lucene.index.Term, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermEnum, org.apache.lucene.index.TermFreqVector, org.apache.lucene.index.TermInfo, org.apache.lucene.index.TermInfosReader, org.apache.lucene.index.TermInfosWriter, org.apache.lucene.index.TermPositionVector, org.apache.lucene.index.TermPositions, org.apache.lucene.index.TermVectorsReader, org.apache.lucene.index.TermVectorsWriter, org.apache.lucene.index.TermVectorsWriter.TVField, org.apache.lucene.queryParser.CharStream, org.apache.lucene.queryParser.FastCharStream, org.apache.lucene.queryParser.MultiFieldQueryParser, org.apache.lucene.queryParser.ParseException, org.apache.lucene.queryParser.QueryParser, org.apache.lucene.queryParser.QueryParserConstants, org.apache.lucene.queryParser.QueryParserTokenManager, org.apache.lucene.queryParser.Token, org.apache.lucene.queryParser.TokenMgrError, org.apache.lucene.search.BooleanClause, org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.BooleanScorer.BucketTable, org.apache.lucene.search.BooleanScorer.Collector, org.apache.lucene.search.BooleanScorer.SubScorer, org.apache.lucene.search.CachingWrapperFilter, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.DateFilter, org.apache.lucene.search.DefaultSimilarity, org.apache.lucene.search.ExactPhraseScorer, org.apache.lucene.search.Explanation, org.apache.lucene.search.FieldCache, org.apache.lucene.search.FieldCache.StringIndex, org.apache.lucene.search.FieldCacheImpl, org.apache.lucene.search.FieldCacheImpl.Entry, org.apache.lucene.search.FieldDoc, org.apache.lucene.search.FieldDocSortedHitQueue, org.apache.lucene.search.FieldSortedHitQueue, org.apache.lucene.search.Filter, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.FuzzyQuery, org.apache.lucene.search.FuzzyTermEnum, org.apache.lucene.search.HitCollector, org.apache.lucene.search.HitDoc, org.apache.lucene.search.HitQueue, org.apache.lucene.search.Hits, org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.MultiSearcherThread, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.ParallelMultiSearcher, org.apache.lucene.search.PhrasePositions, org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.PhraseQueue, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.QueryFilter, org.apache.lucene.search.QueryTermVector, org.apache.lucene.search.RangeQuery, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.ScoreDoc, org.apache.lucene.search.ScoreDocComparator, org.apache.lucene.search.Scorer, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher, org.apache.lucene.search.Similarity, org.apache.lucene.search.SloppyPhraseScorer, org.apache.lucene.search.Sort, org.apache.lucene.search.SortComparator, org.apache.lucene.search.SortComparatorSource, org.apache.lucene.search.SortField, org.apache.lucene.search.TermQuery, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.TermScorer, org.apache.lucene.search.TopDocs, org.apache.lucene.search.TopFieldDocs, org.apache.lucene.search.Weight, org.apache.lucene.search.WildcardQuery, org.apache.lucene.search.WildcardTermEnum, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.CellQueue, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanOrQuery.SpanQueue, org.apache.lucene.search.spans.SpanQuery, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.SpanTermQuery, org.apache.lucene.search.spans.SpanWeight, org.apache.lucene.search.spans.Spans, org.apache.lucene.store.Directory, org.apache.lucene.store.FSDirectory, org.apache.lucene.store.FSInputStream, org.apache.lucene.store.FSInputStream.Descriptor, org.apache.lucene.store.FSOutputStream, org.apache.lucene.store.InputStream, org.apache.lucene.store.Lock, org.apache.lucene.store.Lock.With, org.apache.lucene.store.OutputStream, org.apache.lucene.store.RAMDirectory, org.apache.lucene.store.RAMInputStream, org.apache.lucene.store.RAMOutputStream, org.apache.lucene.util.BitVector, org.apache.lucene.util.Constants, org.apache.lucene.util.PriorityQueue, org.apache.lucene.util.StringHelper],[]]
ITS CHILDREN:=================
	->NODE_1[[org.apache.lucene.analysis.de.GermanStemmer],[String stem(String term), boolean isStemmable(String term), void optimize(StringBuffer buffer), void removeParticleDenotion(StringBuffer buffer), void resubstitute(StringBuffer buffer), void strip(StringBuffer buffer), void substitute(StringBuffer buffer)]]
	->ITS CHILDREN:=================
	->	->NODE_2[[],[Analyzer getAnalyzer(), BitSet bits(IndexReader reader), BooleanClause[] getClauses(), Collator[] hasCollators(SortField[] fields), Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Collection getTerms(), Comparable getComparable(String termtext), Comparable sortValue(ScoreDoc i), Comparable[] getCustom(IndexReader reader, String field, SortComparator comparator), Date stringToDate(String s), DateFilter After(String field, Date date), DateFilter After(String field, long time), DateFilter Before(String field, Date date), DateFilter Before(String field, long time), Directory directory(), Directory getDirectory(), Document doc(int i), Document doc(int n), Document document(int n), Enumeration fields(), Explanation explain(IndexReader reader, int doc), Explanation explain(Query query, int doc), Explanation explain(int doc), Explanation[] getDetails(), FSDirectory getDirectory(File file, boolean create), FSDirectory getDirectory(String path, boolean create), Field Keyword(String name, Date value), Field Keyword(String name, String value), Field Text(String name, Reader value), Field Text(String name, Reader value, boolean storeTermVector), Field Text(String name, String value), Field Text(String name, String value, boolean storeTermVector), Field UnIndexed(String name, String value), Field UnStored(String name, String value), Field UnStored(String name, String value, boolean storeTermVector), Field getField(String name), FieldDoc fillFields(FieldDoc doc), FieldInfo fieldInfo(String fieldName), FieldInfo fieldInfo(int fieldNumber), Field[] getFields(String name), File getFile(), FilteredTermEnum getEnum(IndexReader reader), HashSet getWordSet(File wordfile), Hashtable getWordtable(File wordfile), Hashtable getWordtable(String path, String wordfile), Hashtable getWordtable(String wordfile), Hashtable makeStopTable(String[] stopWords), Hashtable makeWordTable(HashSet wordSet), HitCollector newCollector(int mask), HitDoc hitDoc(int n), Hits search(Query query), Hits search(Query query, Filter filter), Hits search(Query query, Filter filter, Sort sort), Hits search(Query query, Sort sort), IOException getIOException(), IndexReader open(Directory directory), IndexReader open(Directory directory, boolean closeDirectory), IndexReader open(File path), IndexReader open(String path), IndexReader segmentReader(int i), InputStream openFile(String id), InputStream openFile(String name), Locale getLocale(), Lock makeLock(String name), Object doBody(), Object getAuto(IndexReader reader, String field), Object lookup(IndexReader reader, String field, Object comparer), Object lookup(IndexReader reader, String field, int type), Object pop(), Object run(), Object store(IndexReader reader, String field, Object comparer, Object value), Object store(IndexReader reader, String field, int type, Object factory, Object value), Object store(IndexReader reader, String field, int type, Object value), Object top(), OutputStream createFile(String name), ParseException generateParseException(), Posting[] sortPostingTable(), Query Clause(String field), Query Query(String field), Query Term(String field), Query combine(Query[] queries), Query getBooleanQuery(Vector clauses), Query getFieldQuery(String field, Analyzer analyzer, String queryText), Query getFieldQuery(String field, Analyzer analyzer, String queryText, int slop), Query getFuzzyQuery(String field, String termStr), Query getPrefixQuery(String field, String termStr), Query getQuery(), Query getRangeQuery(String field, Analyzer analyzer, String part1, String part2, boolean inclusive), Query getWildcardQuery(String field, String termStr), Query mergeBooleanQueries(Query[] queries), Query parse(String query), Query parse(String query, String field, Analyzer analyzer), Query parse(String query, String[] fields, Analyzer analyzer), Query parse(String query, String[] fields, int[] flags, Analyzer analyzer), Query rewrite(IndexReader reader), Query rewrite(Query original), Query rewrite(Query query), Reader readerValue(), ScoreDocComparator comparatorAuto(IndexReader reader, String fieldname), ScoreDocComparator comparatorFloat(IndexReader reader, String fieldname), ScoreDocComparator comparatorInt(IndexReader reader, String fieldname), ScoreDocComparator comparatorString(IndexReader reader, String fieldname), ScoreDocComparator comparatorStringLocale(IndexReader reader, String fieldname, Locale locale), ScoreDocComparator getCachedComparator(IndexReader reader, String fieldname, int type, Locale locale, SortComparatorSource factory), ScoreDocComparator lookup(IndexReader reader, String field, int type, Object factory), ScoreDocComparator newComparator(IndexReader reader, String fieldname), Scorer first(), Scorer last(), Scorer scorer(IndexReader reader), SegmentInfo info(int i), SegmentTermEnum getEnum(), SegmentTermEnum terms(), SegmentTermEnum terms(Term term), SegmentTermVector readTermVector(String field, long tvfPointer), SegmentTermVector[] readTermVectors(String[] fields, long[] tvfPointers), Set makeStopSet(String[] stopWords), Similarity getDefault(), Similarity getSimilarity(), Similarity getSimilarity(Searcher searcher), SortComparatorSource getFactory(), SortField[] getFields(), SpanQuery getExclude(), SpanQuery getInclude(), SpanQuery getMatch(), SpanQuery[] getClauses(), Spans getSpans(IndexReader reader), SpansCell min(), String GetImage(), String LexicalError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar), String MAX_DATE_STRING(), String MIN_DATE_STRING(), String addEscapes(String str), String add_escapes(String str), String dateToString(Date date), String discardEscapeChar(String input), String field(), String fieldName(int fieldNumber), String get(String name), String getDescription(), String getField(), String getName(), String name(), String newSegmentName(), String readString(), String stem(String input), String stem(String s), String stem(String term), String stem(String theWord, char[] charset), String stringValue(), String termText(), String text(), String timeToString(long time), String toHtml(), String toString(String f), String toString(String field), String toString(String s), String toString(int depth), String type(), StringBuffer getLockPrefix(), StringIndex getStringIndex(IndexReader reader, String field), String[] getStrings(IndexReader reader, String field), String[] getTerms(), String[] getValues(String name), String[] list(), String[] makeStopWords(char[] charset), Term get(int position), Term getLowerTerm(), Term getPrefix(), Term getTerm(), Term getUpperTerm(), Term readTerm(), Term scanEnum(int position), Term term(), TermDocs termDocs(), TermDocs termDocs(IndexReader reader), TermDocs termDocs(Term term), TermDocs termDocs(int i), TermEnum terms(), TermEnum terms(Term t), TermEnum terms(Term term), TermFreqVector get(int docNum, String field), TermFreqVector getTermFreqVector(int docNumber, String field), TermFreqVector getTermFreqVector(int n, String field), TermFreqVector[] get(int docNum), TermFreqVector[] getTermFreqVectors(int docNumber), TermFreqVector[] getTermFreqVectors(int n), TermInfo get(Term term), TermInfo scanEnum(Term term), TermInfo termInfo(), TermPositions peek(), TermPositions termPositions(), TermPositions termPositions(Term term), Term[] getTerms(), Token getNextToken(), Token getToken(int index), Token jjFillToken(), Token jj_consume_token(int kind), Token newToken(int ofKind), Token next(), TokenStream tokenStream(Reader reader), TokenStream tokenStream(String fieldName, Reader reader), TopDocs search(Query query, Filter filter, int n), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), Vector files(), Vector readDeleteableFiles(), Weight createWeight(Searcher searcher), Weight weight(Searcher searcher), boolean adjectival(StringBuffer stemmingZone), boolean atMatch(), boolean checkSlop(), boolean cons(int i), boolean cvc(int i), boolean derivational(StringBuffer stemmingZone), boolean doNext(), boolean doublec(int j), boolean endEnum(), boolean ends(String s), boolean fileExists(String name), boolean findAndRemoveEnding(StringBuffer stemmingZone, char[][] theEndingClass), boolean findAndRemoveEnding(StringBuffer stemmingZone, char[][] theEndingClass, char[][] thePredessors), boolean firstNonOrderedNextToPartialList(), boolean get(int bit), boolean getLowercaseWildcardTerms(), boolean getReverse(), boolean getUseCompoundFile(), boolean hasDeletions(), boolean hasDeletions(SegmentInfo si), boolean hasSeparateNorms(SegmentInfo si), boolean hasVectors(), boolean indexExists(Directory directory), boolean indexExists(File directory), boolean indexExists(String directory), boolean insert(Object element), boolean isDeleted(int n), boolean isDocumentOpen(), boolean isFDValid(), boolean isFieldOpen(), boolean isInOrder(), boolean isInclusive(), boolean isIndexed(), boolean isLocked(), boolean isLocked(Directory directory), boolean isLocked(String directory), boolean isStemmable(String term), boolean isStored(), boolean isTermVectorStored(), boolean isTokenChar(char c), boolean isTokenized(), boolean isVowel(char letter), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), boolean jjCanMove_1(int hiByte, int i1, int i2, long l1, long l2), boolean jjCanMove_2(int hiByte, int i1, int i2, long l1, long l2), boolean jj_2_1(int xla), boolean jj_3_1(), boolean jj_scan_token(int kind), boolean lessThan(Object a, Object b), boolean lessThan(Object o1, Object o2), boolean matchIsOrdered(), boolean next(), boolean nextPosition(), boolean noun(StringBuffer stemmingZone), boolean obtain(), boolean obtain(long lockWaitTimeout), boolean perfectiveGerund(StringBuffer stemmingZone), boolean reflexive(StringBuffer stemmingZone), boolean removeI(StringBuffer stemmingZone), boolean removeSoft(StringBuffer stemmingZone), boolean skipTo(Term target), boolean skipTo(int i), boolean skipTo(int target), boolean stem(), boolean stem(char[] word), boolean stem(char[] word, int wordLen), boolean stem(char[] wordBuffer, int offset, int wordLen), boolean stem(int i0), boolean superlative(StringBuffer stemmingZone), boolean termCompare(Term term), boolean undoubleN(StringBuffer stemmingZone), boolean usesCompoundFile(SegmentInfo si), boolean verb(StringBuffer stemmingZone), boolean vowelinstem(), boolean wildcardEquals(String pattern, int patternIdx, String string, int stringIdx), byte encodeNorm(float f), byte floatToByte(float f), byte readByte(), byte[] norms(String f), byte[] norms(String field), char BeginToken(), char normalize(char c), char readChar(), char toLowerCase(char letter, char[] charset), char[] GetSuffix(int len), char[] getResultBuffer(), float byteToFloat(byte b), float coord(int overlap, int maxOverlap), float decodeNorm(byte b), float difference(), float getBoost(), float getValue(), float idf(Collection terms, Searcher searcher), float idf(Term term, Searcher searcher), float idf(int docFreq, int numDocs), float lengthNorm(String fieldName, int numTerms), float lengthNorm(String fieldName, int numTokens), float phraseFreq(), float queryNorm(float sumOfSquaredWeights), float score(), float score(int n), float sloppyFreq(int distance), float sumOfSquaredWeights(), float tf(float freq), float tf(int freq), float[] getFloats(IndexReader reader, String field), int Conjunction(), int Modifiers(), int appendPostings(SegmentMergeInfo[] smis, int n), int compare(ScoreDoc i, ScoreDoc j), int compareTo(Object other), int compareTo(Term other), int count(), int delete(Term term), int doc(), int docCount(), int docFreq(), int docFreq(Term t), int docFreq(Term term), int editDistance(String s, String t, int n, int m), int end(), int endOffset(), int fieldNumber(String fieldName), int findEnding(StringBuffer stemmingZone, char[][] theEndingClass), int findEnding(StringBuffer stemmingZone, int startIndex, char[][] theEndingClass), int freq(), int getBeginColumn(), int getBeginLine(), int getColumn(), int getEnd(), int getEndColumn(), int getEndLine(), int getIndexOffset(Term term), int getLine(), int getMaxClauseCount(), int getOperator(), int getPhraseSlop(), int getPositionIncrement(), int getResultLength(), int getSegmentsCounter(), int getSkipInterval(), int getSlop(), int getType(), int hits(), int id(int n), int indexOf(String term), int indexOf(String termText), int jjMoveNfa_0(int startState, int curPos), int jjMoveNfa_1(int startState, int curPos), int jjMoveNfa_2(int startState, int curPos), int jjMoveNfa_3(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), int jjMoveStringLiteralDfa0_1(), int jjMoveStringLiteralDfa0_2(), int jjMoveStringLiteralDfa0_3(), int jjMoveStringLiteralDfa1_1(long active0), int jjMoveStringLiteralDfa1_2(long active0), int jjStartNfaWithStates_1(int pos, int kind, int state), int jjStartNfaWithStates_2(int pos, int kind, int state), int jjStartNfaWithStates_3(int pos, int kind, int state), int jjStartNfa_1(int pos, long active0), int jjStartNfa_2(int pos, long active0), int jjStartNfa_3(int pos, long active0), int jjStopAtPos(int pos, int kind), int jjStopStringLiteralDfa_1(int pos, long active0), int jjStopStringLiteralDfa_2(int pos, long active0), int jjStopStringLiteralDfa_3(int pos, long active0), int jj_ntk(), int length(), int m(), int maxDoc(), int merge(), int mergeFields(), int min(int a, int b, int c), int next(), int nextPosition(), int numDocs(), int read(int[] arg0, int[] arg1), int read(int[] docs, int[] freqs), int readInt(), int readVInt(), int readerIndex(int n), int searcherIndex(int n), int size(), int sortType(), int start(), int startOffset(), int stringDifference(String s1, String s2), int subDoc(int n), int subSearcher(int n), int[] getInts(IndexReader reader, String field), int[] getStarts(), int[] getTermFrequencies(), int[] getTermPositions(int index), int[] indexesOf(String[] termNumbers, int start, int len), int[] indexesOf(String[] terms, int start, int len), long fileLength(String name), long fileModified(File directory, String name), long fileModified(String name), long freqPointer(), long getCurrentVersion(Directory directory), long getCurrentVersion(File directory), long getCurrentVersion(String directory), long getFilePointer(), long getPosition(Term term), long getVersion(), long lastModified(Directory directory), long lastModified(File directory), long lastModified(String directory), long length(), long proxPointer(), long readCurrentVersion(Directory directory), long readLong(), long readVLong(), long size(), long stringToTime(String s), long writeSkip(), org.apache.lucene.analysis.Token next(), void BitVector(Directory d, String name), void BitVector(int n), void BooleanClause(Query q, boolean r, boolean p), void BooleanQuery(), void BooleanScorer(Similarity similarity), void BooleanWeight(Searcher searcher), void BucketTable(BooleanScorer scorer), void CSInputStream(InputStream base, long fileOffset, long length), void CachingWrapperFilter(Filter filter), void CellQueue(int size), void CharTokenizer(Reader input), void Collector(int mask, BucketTable bucketTable), void CompoundFileReader(Directory dir, String name), void CompoundFileWriter(Directory dir, String name), void ConjunctionScorer(Similarity similarity), void Constants(), void DateField(), void DateFilter(String f), void DateFilter(String f, Date from, Date to), void DateFilter(String f, long from, long to), void Descriptor(File file, String mode), void Document(), void DocumentWriter(Directory directory, Analyzer analyzer, Similarity similarity, int maxFieldLength), void Done(), void Entry(IndexReader reader, String field, Object custom), void Entry(IndexReader reader, String field, int type), void ExactPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void Explanation(), void Explanation(float value, String description), void FSDirectory(File path, boolean create), void FSInputStream(File path), void FSOutputStream(File path), void FastCharStream(Reader r), void Field(String name, Reader reader), void Field(String name, String string, boolean store, boolean index, boolean token), void Field(String name, String string, boolean store, boolean index, boolean token, boolean storeTermVector), void FieldDoc(int doc, float score), void FieldDoc(int doc, float score, Comparable[] fields), void FieldDocSortedHitQueue(SortField[] fields, int size), void FieldInfo(String na, boolean tk, int nu, boolean storeTermVector), void FieldInfos(), void FieldInfos(Directory d, String name), void FieldSortedHitQueue(IndexReader reader, SortField[] fields, int size), void FieldsReader(Directory d, String segment, FieldInfos fn), void FieldsWriter(Directory d, String segment, FieldInfos fn), void FilterIndexReader(IndexReader in), void FilterTermDocs(TermDocs in), void FilterTermEnum(TermEnum in), void FilterTermPositions(TermPositions in), void FilteredQuery(Query query, Filter filter), void FilteredTermEnum(), void FuzzyQuery(Term term), void FuzzyTermEnum(IndexReader reader, Term term), void GermanAnalyzer(), void GermanAnalyzer(File stopwords), void GermanAnalyzer(Hashtable stopwords), void GermanAnalyzer(String[] stopwords), void GermanStemFilter(TokenStream in), void GermanStemFilter(TokenStream in, Hashtable exclusiontable), void GermanStemFilter(TokenStream in, Set exclusionSet), void HitDoc(float s, int i), void HitQueue(int size), void Hits(Searcher s, Query q, Filter f), void Hits(Searcher s, Query q, Filter f, Sort o), void IndexReader(Directory directory), void IndexReader(Directory directory, SegmentInfos segmentInfos, boolean closeDirectory), void IndexSearcher(Directory directory), void IndexSearcher(IndexReader r), void IndexSearcher(IndexReader r, boolean closeReader), void IndexSearcher(String path), void IndexWriter(Directory d, Analyzer a, boolean create), void IndexWriter(Directory d, Analyzer a, boolean create, boolean closeDir), void IndexWriter(File path, Analyzer a, boolean create), void IndexWriter(String path, Analyzer a, boolean create), void LetterTokenizer(Reader in), void LowerCaseFilter(TokenStream in), void LowerCaseTokenizer(Reader in), void MultiFieldQueryParser(CharStream stream), void MultiFieldQueryParser(QueryParserTokenManager tm), void MultiFieldQueryParser(String f, Analyzer a), void MultiReader(Directory directory, SegmentInfos sis, boolean closeDirectory, IndexReader[] subReaders), void MultiReader(IndexReader[] subReaders), void MultiSearcher(Searchable[] searchables), void MultiSearcherThread(Searchable searchable, Query query, Filter filter, int nDocs, FieldDocSortedHitQueue hq, Sort sort, int i, int[] starts, String name), void MultiSearcherThread(Searchable searchable, Query query, Filter filter, int nDocs, HitQueue hq, int i, int[] starts, String name), void MultiTermDocs(IndexReader[] r, int[] s), void MultiTermEnum(IndexReader[] readers, int[] starts, Term t), void MultiTermPositions(IndexReader[] r, int[] s), void MultiTermQuery(Term term), void MultipleTermPositions(IndexReader indexReader, Term[] terms), void NearSpans(SpanNearQuery query, IndexReader reader), void Norm(InputStream in, int number), void ParallelMultiSearcher(Searchable[] searchables), void ParseException(), void ParseException(String message), void ParseException(Token currentTokenVal, int[][] expectedTokenSequencesVal, String[] tokenImageVal), void PerFieldAnalyzerWrapper(Analyzer defaultAnalyzer), void PhrasePositions(TermPositions t, int o), void PhrasePrefixWeight(Searcher searcher), void PhraseQuery(), void PhraseQueue(int size), void PhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void PhraseWeight(Searcher searcher), void PorterStemFilter(TokenStream in), void PorterStemmer(), void Posting(Term t, int position), void PrefixQuery(Term prefix), void QueryFilter(Query query), void QueryParser(CharStream stream), void QueryParser(QueryParserTokenManager tm), void QueryParser(String f, Analyzer a), void QueryParserTokenManager(CharStream stream), void QueryParserTokenManager(CharStream stream, int lexState), void QueryTermVector(String queryString, Analyzer analyzer), void QueryTermVector(String[] queryTerms), void RAMDirectory(), void RAMDirectory(Directory dir), void RAMDirectory(Directory dir, boolean closeDir), void RAMDirectory(File dir), void RAMDirectory(String dir), void RAMInputStream(RAMFile f), void RAMOutputStream(), void RAMOutputStream(RAMFile f), void RangeQuery(Term lowerTerm, Term upperTerm, boolean inclusive), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInit(QueryParserTokenManager tm), void ReInit(StandardTokenizerTokenManager tm), void ReInitRounds(), void RemoteSearchable(Searchable local), void RussianAnalyzer(), void RussianAnalyzer(char[] charset), void RussianAnalyzer(char[] charset, Hashtable stopwords), void RussianAnalyzer(char[] charset, String[] stopwords), void RussianLetterTokenizer(Reader in, char[] charset), void RussianLowerCaseFilter(TokenStream in, char[] charset), void RussianStemFilter(TokenStream in, char[] charset), void RussianStemmer(), void RussianStemmer(char[] charset), void ScoreDoc(int doc, float score), void Scorer(Similarity similarity), void SegmentInfo(String name, int docCount, Directory dir), void SegmentMergeInfo(int b, TermEnum te, IndexReader r), void SegmentMergeQueue(int size), void SegmentMerger(Directory dir, String name, boolean compoundFile), void SegmentReader(SegmentInfo si), void SegmentReader(SegmentInfos sis, SegmentInfo si, boolean closeDir), void SegmentTermDocs(SegmentReader parent), void SegmentTermEnum(InputStream i, FieldInfos fis, boolean isi), void SegmentTermPositions(SegmentReader p), void SegmentTermVector(String field, String[] terms, int[] termFreqs), void SloppyPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, int slop, byte[] norms), void Sort(), void Sort(SortField field), void Sort(SortField[] fields), void Sort(String field), void Sort(String field, boolean reverse), void Sort(String[] fields), void SortField(String field), void SortField(String field, Locale locale), void SortField(String field, Locale locale, boolean reverse), void SortField(String field, SortComparatorSource comparator), void SortField(String field, SortComparatorSource comparator, boolean reverse), void SortField(String field, boolean reverse), void SortField(String field, int type), void SortField(String field, int type, boolean reverse), void SpanFirstQuery(SpanQuery match, int end), void SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder), void SpanNotQuery(SpanQuery include, SpanQuery exclude), void SpanOrQuery(SpanQuery[] clauses), void SpanQueue(int size), void SpanScorer(Spans spans, Weight weight, Similarity similarity, byte[] norms), void SpanTermQuery(Term term), void SpanWeight(SpanQuery query, Searcher searcher), void SpansCell(Spans spans, int index), void StandardAnalyzer(), void StandardAnalyzer(String[] stopWords), void StandardFilter(TokenStream in), void StandardTokenizer(CharStream stream), void StandardTokenizer(Reader reader), void StandardTokenizer(StandardTokenizerTokenManager tm), void StandardTokenizerTokenManager(CharStream stream), void StandardTokenizerTokenManager(CharStream stream, int lexState), void StopAnalyzer(), void StopAnalyzer(String[] stopWords), void StopFilter(TokenStream in, Hashtable stopTable), void StopFilter(TokenStream in, Set stopWords), void StopFilter(TokenStream in, String[] stopWords), void StringHelper(), void StringIndex(int[] values, String[] lookup), void SubScorer(Scorer scorer, boolean required, boolean prohibited, HitCollector collector, SubScorer next), void SwitchTo(int lexState), void TVField(int number), void Term(String fld, String txt), void Term(String fld, String txt, boolean intern), void TermInfo(), void TermInfo(TermInfo ti), void TermInfo(int df, long fp, long pp), void TermInfosReader(Directory dir, String seg, FieldInfos fis), void TermInfosWriter(Directory directory, String segment, FieldInfos fis), void TermInfosWriter(Directory directory, String segment, FieldInfos fis, boolean isIndex), void TermPositionsQueue(List termPositions), void TermQuery(Term t), void TermScorer(Weight weight, TermDocs td, Similarity similarity, byte[] norms), void TermVectorsReader(Directory d, String segment, FieldInfos fieldInfos), void TermVectorsWriter(Directory directory, String segment, FieldInfos fieldInfos), void TermWeight(Searcher searcher), void Token(String text, int start, int end), void Token(String text, int start, int end, String typ), void TokenFilter(), void TokenFilter(TokenStream input), void TokenMgrError(), void TokenMgrError(String message, int reason), void TokenMgrError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar, int reason), void Tokenizer(), void Tokenizer(Reader input), void TopDocs(int totalHits, ScoreDoc[] scoreDocs), void TopFieldDocs(int totalHits, ScoreDoc[] scoreDocs, SortField[] fields), void WhitespaceTokenizer(Reader in), void WildcardQuery(Term term), void WildcardTermEnum(IndexReader reader, Term term), void With(Lock lock), void With(Lock lock, long lockWaitTimeout), void add(BooleanClause clause), void add(Collection names, boolean isIndexed), void add(Document doc), void add(Field field), void add(IndexReader reader), void add(Query query, boolean required, boolean prohibited), void add(Scorer scorer), void add(Scorer scorer, boolean required, boolean prohibited), void add(String name, boolean isIndexed), void add(String name, boolean isIndexed, boolean storeTermVector), void add(Term term), void add(Term term, TermInfo ti), void add(Term[] terms), void add(char ch), void add(int i), void addAnalyzer(String fieldName, Analyzer analyzer), void addClause(Vector clauses, int conj, int mods, Query q), void addDetail(Explanation detail), void addDocument(Document doc), void addDocument(Document doc, Analyzer analyzer), void addDocument(String segment, Document doc), void addFile(String file), void addIndexed(Collection names, boolean storeTermVectors), void addIndexes(Directory[] dirs), void addIndexes(IndexReader[] readers), void addInternal(String name, boolean isIndexed, boolean storeTermVector), void addPosition(String field, String text, int position), void addTerm(String termText, int freq), void addTermFreqVector(TermFreqVector vector), void addTermFreqVectorInternal(TermFreqVector vector), void addTermInternal(String termText, int freq), void addToFront(HitDoc hitDoc), void addToList(SpansCell cell), void addVectors(TermFreqVector[] vectors), void adjustTop(), void aquireWriteLock(), void backup(int amount), void bufferSkip(int doc), void checkValidFormat(InputStream in), void clear(), void clear(int bit), void close(), void closeDocument(), void closeField(), void closeNorms(), void closeReaders(), void collect(int doc, float score), void commit(), void computeCoordFactors(), void copyFile(FileEntry source, OutputStream os, byte[] buffer), void create(), void createCompoundFile(), void delete(int docNum), void deleteFile(String name), void deleteFiles(Vector files, Directory directory), void deleteFiles(Vector files, Vector deletable), void deleteSegments(Vector segments), void disable_tracing(), void doClose(), void doCommit(), void doDelete(int docNum), void doDelete(int n), void doSetNorm(int d, String f, byte b), void doSetNorm(int doc, String field, byte value), void doSetNorm(int n, String field, byte value), void doUndeleteAll(), void downHeap(), void enable_tracing(), void firstPosition(), void firstToLast(), void flush(), void flushBuffer(byte[] b, int len), void flushBuffer(byte[] b, int size), void flushBuffer(byte[] src, int len), void flushRamSegments(), void getMoreDocs(int min), void growArray(), void growBuffer(int length), void init(), void initList(boolean next), void initialize(Directory directory, String segment, FieldInfos fis, boolean isi), void initialize(IndexReader[] subReaders), void initialize(SegmentInfo si), void initialize(int maxSize), void invertDocument(Document doc), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void jj_add_error_token(int kind, int pos), void jj_la1_0(), void jj_la1_1(), void jj_rescan_token(), void jj_save(int index, int xla), void listToQueue(), void main(String[] args), void markPositions(String word), void maybeMergeSegments(), void mergeNorms(), void mergeSegments(int minSegment), void mergeTermInfo(SegmentMergeInfo[] smis, int n), void mergeTermInfos(), void mergeTerms(), void mergeVectors(), void normalize(float norm), void normalize(float queryNorm), void norms(String f, byte[] bytes, int offset), void norms(String field, byte[] bytes, int offset), void norms(String field, byte[] result, int offset), void openDocument(), void openField(String field), void openNorms(Directory cfsDir), void optimize(), void optimize(StringBuffer buffer), void partialListToQueue(), void pqToList(), void processTerms(String[] queryTerms), void put(Object element), void queueToList(), void quickSort(Posting[] postings, int lo, int hi), void r(String s), void reWrite(), void read(Directory directory), void read(InputStream input), void readBytes(byte[] b, int offset, int len), void readChars(char[] buffer, int start, int length), void readIndex(), void readInternal(byte[] b, int offset, int len), void readInternal(byte[] b, int offset, int length), void readInternal(byte[] dest, int destOffset, int len), void readObject(java.io.ObjectInputStream in), void refill(), void release(), void remove(HitDoc hitDoc), void removeField(String name), void removeFields(String name), void removeParticleDenotion(StringBuffer buffer), void renameFile(String from, String to), void reset(), void resetSkip(), void resubstitute(StringBuffer buffer), void score(HitCollector hc), void search(Query query, Filter filter, HitCollector results), void search(Query query, HitCollector results), void seek(Term arg0), void seek(Term term), void seek(TermEnum termEnum), void seek(TermInfo ti), void seek(long pointer, int p, Term t, TermInfo ti), void seek(long pos), void seekEnum(int indexOffset), void seekInternal(long pos), void seekInternal(long position), void set(String fld, String txt), void set(TermInfo ti), void set(int bit), void set(int docFreq, long freqPointer, long proxPointer, int skipOffset), void setBoost(float b), void setBoost(float boost), void setCharset(char[] newCharset), void setDebugStream(java.io.PrintStream ds), void setDefault(Similarity similarity), void setDescription(String description), void setEndings(), void setEnum(TermEnum actualEnum), void setExclusionSet(Set exclusionSet), void setExclusionTable(Hashtable exclusiontable), void setFields(SortField[] fields), void setLocale(Locale locale), void setLowercaseWildcardTerms(boolean lowercaseWildcardTerms), void setMaxClauseCount(int maxClauseCount), void setNorm(int doc, String field, byte value), void setNorm(int doc, String field, float value), void setOperator(int operator), void setPhraseSlop(int phraseSlop), void setPositionIncrement(int positionIncrement), void setSimilarity(Similarity similarity), void setSlop(int s), void setSort(SortField field), void setSort(SortField[] fields), void setSort(String field), void setSort(String field, boolean reverse), void setSort(String[] fieldnames), void setStemExclusionTable(File exclusionlist), void setStemExclusionTable(Hashtable exclusionlist), void setStemExclusionTable(String[] exclusionlist), void setStemmer(GermanStemmer stemmer), void setStemmer(RussianStemmer stemmer), void setUseCompoundFile(boolean value), void setValue(float value), void setto(String s), void skipProx(long proxPointer), void skippingDoc(), void sort(), void sortScorers(), void step1(), void step2(), void step3(), void step4(), void step5(), void step6(), void strip(StringBuffer buffer), void substitute(StringBuffer buffer), void termInfo(TermInfo ti), void touchFile(String name), void undeleteAll(), void unlock(Directory directory), void upHeap(), void write(Directory d, String name), void write(Directory directory), void write(OutputStream output), void writeByte(byte b), void writeBytes(byte[] b, int length), void writeChars(String s, int start, int length), void writeDeleteableFiles(Vector files), void writeDoc(), void writeField(), void writeInt(int i), void writeLong(long i), void writeNorms(Document doc, String segment), void writePostings(Posting[] postings, String segment), void writeString(String s), void writeTerm(Term term), void writeTo(OutputStream out), void writeVInt(int i), void writeVLong(long i)]]
	->NODE_3[[org.apache.lucene.index.MultipleTermPositions.TermPositionsQueue, org.apache.lucene.index.SegmentMergeQueue, org.apache.lucene.search.FieldDocSortedHitQueue, org.apache.lucene.search.FieldSortedHitQueue, org.apache.lucene.search.HitQueue, org.apache.lucene.util.PriorityQueue],[boolean lessThan(Object a, Object b)]]
	->ITS CHILDREN:=================
	->	->NODE_4[[org.apache.lucene.search.FieldDocSortedHitQueue, org.apache.lucene.search.FieldSortedHitQueue, org.apache.lucene.util.PriorityQueue],[SortField[] getFields(), boolean lessThan(Object a, Object b)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_5[[org.apache.lucene.search.FieldSortedHitQueue, org.apache.lucene.util.PriorityQueue],[FieldDoc fillFields(FieldDoc doc), Object store(IndexReader reader, String field, int type, Object factory, Object value), ScoreDocComparator comparatorAuto(IndexReader reader, String fieldname), ScoreDocComparator comparatorFloat(IndexReader reader, String fieldname), ScoreDocComparator comparatorInt(IndexReader reader, String fieldname), ScoreDocComparator comparatorString(IndexReader reader, String fieldname), ScoreDocComparator comparatorStringLocale(IndexReader reader, String fieldname, Locale locale), ScoreDocComparator getCachedComparator(IndexReader reader, String fieldname, int type, Locale locale, SortComparatorSource factory), ScoreDocComparator lookup(IndexReader reader, String field, int type, Object factory), SortField[] getFields(), boolean lessThan(Object a, Object b), void FieldSortedHitQueue(IndexReader reader, SortField[] fields, int size)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_6[[org.apache.lucene.util.PriorityQueue],[Collator[] hasCollators(SortField[] fields), FieldDoc fillFields(FieldDoc doc), Object pop(), Object store(IndexReader reader, String field, int type, Object factory, Object value), Object top(), ScoreDocComparator comparatorAuto(IndexReader reader, String fieldname), ScoreDocComparator comparatorFloat(IndexReader reader, String fieldname), ScoreDocComparator comparatorInt(IndexReader reader, String fieldname), ScoreDocComparator comparatorString(IndexReader reader, String fieldname), ScoreDocComparator comparatorStringLocale(IndexReader reader, String fieldname, Locale locale), ScoreDocComparator getCachedComparator(IndexReader reader, String fieldname, int type, Locale locale, SortComparatorSource factory), ScoreDocComparator lookup(IndexReader reader, String field, int type, Object factory), SortField[] getFields(), TermPositions peek(), boolean insert(Object element), boolean lessThan(Object a, Object b), boolean lessThan(Object o1, Object o2), int size(), void CellQueue(int size), void FieldDocSortedHitQueue(SortField[] fields, int size), void FieldSortedHitQueue(IndexReader reader, SortField[] fields, int size), void HitQueue(int size), void PhraseQueue(int size), void SegmentMergeQueue(int size), void SpanQueue(int size), void TermPositionsQueue(List termPositions), void adjustTop(), void clear(), void close(), void downHeap(), void initialize(int maxSize), void put(Object element), void setFields(SortField[] fields), void upHeap()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_7[[org.apache.lucene.search.FieldDocSortedHitQueue, org.apache.lucene.util.PriorityQueue],[Collator[] hasCollators(SortField[] fields), SortField[] getFields(), boolean lessThan(Object a, Object b), void FieldDocSortedHitQueue(SortField[] fields, int size), void setFields(SortField[] fields)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_6[...,...]
	->	->NODE_8[[org.apache.lucene.index.SegmentMergeQueue, org.apache.lucene.util.PriorityQueue],[boolean lessThan(Object a, Object b), void SegmentMergeQueue(int size), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->	->NODE_9[[org.apache.lucene.index.MultipleTermPositions.TermPositionsQueue, org.apache.lucene.util.PriorityQueue],[TermPositions peek(), boolean lessThan(Object a, Object b), void TermPositionsQueue(List termPositions)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->	->NODE_10[[org.apache.lucene.search.HitQueue, org.apache.lucene.util.PriorityQueue],[boolean lessThan(Object a, Object b), void HitQueue(int size)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->NODE_11[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.FuzzyQuery, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery, org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanQuery, org.apache.lucene.search.spans.SpanTermQuery],[String toString(String field)]]
	->ITS CHILDREN:=================
	->	->NODE_12[[org.apache.lucene.search.FuzzyQuery, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.Query],[FilteredTermEnum getEnum(IndexReader reader), String toString(String field), void FuzzyQuery(Term term)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_13[[org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.Query],[FilteredTermEnum getEnum(IndexReader reader), Query combine(Query[] queries), Query rewrite(IndexReader reader), String toString(String field), Term getTerm(), void FuzzyQuery(Term term), void MultiTermQuery(Term term), void WildcardQuery(Term term)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_14[[org.apache.lucene.search.Query],[BooleanClause[] getClauses(), Collection getTerms(), FilteredTermEnum getEnum(IndexReader reader), Query combine(Query[] queries), Query getQuery(), Query mergeBooleanQueries(Query[] queries), Query rewrite(IndexReader reader), Similarity getSimilarity(Searcher searcher), SpanQuery getExclude(), SpanQuery getInclude(), SpanQuery getMatch(), SpanQuery[] getClauses(), Spans getSpans(IndexReader reader), String getField(), String toString(String f), String toString(String field), String toString(String s), Term getLowerTerm(), Term getPrefix(), Term getTerm(), Term getUpperTerm(), Term[] getTerms(), Weight createWeight(Searcher searcher), Weight weight(Searcher searcher), boolean isInOrder(), boolean isInclusive(), float getBoost(), int getEnd(), int getMaxClauseCount(), int getSlop(), void BooleanQuery(), void FilteredQuery(Query query, Filter filter), void FuzzyQuery(Term term), void MultiTermQuery(Term term), void PhraseQuery(), void PrefixQuery(Term prefix), void RangeQuery(Term lowerTerm, Term upperTerm, boolean inclusive), void SpanFirstQuery(SpanQuery match, int end), void SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder), void SpanNotQuery(SpanQuery include, SpanQuery exclude), void SpanOrQuery(SpanQuery[] clauses), void SpanTermQuery(Term term), void TermQuery(Term t), void WildcardQuery(Term term), void add(BooleanClause clause), void add(Query query, boolean required, boolean prohibited), void add(Term term), void add(Term[] terms), void setBoost(float b), void setMaxClauseCount(int maxClauseCount), void setSlop(int s)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->NODE_15[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.Query, org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanQuery],[String toString(String field), Weight createWeight(Searcher searcher)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_16[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.Query],[BooleanClause[] getClauses(), Query rewrite(IndexReader reader), String toString(String field), Weight createWeight(Searcher searcher), int getMaxClauseCount(), void BooleanQuery(), void add(BooleanClause clause), void add(Query query, boolean required, boolean prohibited), void setMaxClauseCount(int maxClauseCount)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_14[...,...]
	->	->	->NODE_17[[org.apache.lucene.search.Query, org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanQuery],[String toString(String field), Term getTerm(), Weight createWeight(Searcher searcher)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_18[[org.apache.lucene.search.Query, org.apache.lucene.search.TermQuery],[String toString(String field), Term getTerm(), Weight createWeight(Searcher searcher), void TermQuery(Term t)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_14[...,...]
	->	->	->	->NODE_19[[org.apache.lucene.search.Query, org.apache.lucene.search.spans.SpanQuery],[Collection getTerms(), SpanQuery getExclude(), SpanQuery getInclude(), SpanQuery getMatch(), SpanQuery[] getClauses(), Spans getSpans(IndexReader reader), String getField(), String toString(String field), Term getTerm(), Weight createWeight(Searcher searcher), boolean isInOrder(), int getEnd(), int getSlop(), void SpanFirstQuery(SpanQuery match, int end), void SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder), void SpanNotQuery(SpanQuery include, SpanQuery exclude), void SpanOrQuery(SpanQuery[] clauses), void SpanTermQuery(Term term)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_14[...,...]
	->	->NODE_20[[org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery, org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanQuery, org.apache.lucene.search.spans.SpanTermQuery],[String getField(), String toString(String field)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_21[[org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery],[Query combine(Query[] queries), Query rewrite(IndexReader reader), String getField(), String toString(String field), Term getLowerTerm(), Term getUpperTerm(), boolean isInclusive(), void RangeQuery(Term lowerTerm, Term upperTerm, boolean inclusive)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_14[...,...]
	->	->	->NODE_22[[org.apache.lucene.search.Query, org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanQuery, org.apache.lucene.search.spans.SpanTermQuery],[Collection getTerms(), Spans getSpans(IndexReader reader), String getField(), String toString(String field)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_23[[org.apache.lucene.search.Query, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanQuery],[Collection getTerms(), SpanQuery getExclude(), SpanQuery getInclude(), Spans getSpans(IndexReader reader), String getField(), String toString(String field), void SpanNotQuery(SpanQuery include, SpanQuery exclude)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_19[...,...]
	->	->	->	->NODE_24[[org.apache.lucene.search.Query, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanQuery],[Collection getTerms(), SpanQuery[] getClauses(), Spans getSpans(IndexReader reader), String getField(), String toString(String field)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_25[[org.apache.lucene.search.Query, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanQuery],[Collection getTerms(), SpanQuery[] getClauses(), Spans getSpans(IndexReader reader), String getField(), String toString(String field), boolean isInOrder(), int getSlop(), void SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_19[...,...]
	->	->	->	->	->NODE_26[[org.apache.lucene.search.Query, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanQuery],[Collection getTerms(), SpanQuery[] getClauses(), Spans getSpans(IndexReader reader), String getField(), String toString(String field), void SpanOrQuery(SpanQuery[] clauses)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_19[...,...]
	->	->	->	->NODE_27[[org.apache.lucene.search.Query, org.apache.lucene.search.spans.SpanQuery, org.apache.lucene.search.spans.SpanTermQuery],[Collection getTerms(), Spans getSpans(IndexReader reader), String getField(), String toString(String field), Term getTerm(), void SpanTermQuery(Term term)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_19[...,...]
	->	->	->	->NODE_28[[org.apache.lucene.search.Query, org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanQuery],[Collection getTerms(), SpanQuery getMatch(), Spans getSpans(IndexReader reader), String getField(), String toString(String field), int getEnd(), void SpanFirstQuery(SpanQuery match, int end)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_19[...,...]
	->	->NODE_29[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery],[Query rewrite(IndexReader reader), String toString(String field)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_16[...,...]
	->	->	->NODE_30[[org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery],[Query combine(Query[] queries), Query rewrite(IndexReader reader), String toString(String field)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_13[...,...]
	->	->	->	->NODE_21[...,...]
	->	->	->	->NODE_31[[org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query],[Query combine(Query[] queries), Query rewrite(IndexReader reader), String toString(String field), Term getPrefix(), void PrefixQuery(Term prefix)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_14[...,...]
	->	->NODE_32[[org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.Query, org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanQuery, org.apache.lucene.search.spans.SpanTermQuery],[String toString(String field), Term getTerm()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_13[...,...]
	->	->	->NODE_27[...,...]
	->	->	->NODE_17[...,...]
	->NODE_33[[org.apache.lucene.analysis.standard.ParseException, org.apache.lucene.queryParser.ParseException],[String add_escapes(String str), void ParseException(), void ParseException(String message), void ParseException(Token currentTokenVal, int[][] expectedTokenSequencesVal, String[] tokenImageVal)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_34[[org.apache.lucene.search.BooleanScorer.SubScorer],[void SubScorer(Scorer scorer, boolean required, boolean prohibited, HitCollector collector, SubScorer next)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_35[[org.apache.lucene.analysis.ru.RussianCharsets],[char toLowerCase(char letter, char[] charset)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_36[[org.apache.lucene.search.ExactPhraseScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.SloppyPhraseScorer],[float phraseFreq()]]
	->ITS CHILDREN:=================
	->	->NODE_37[[org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.SloppyPhraseScorer],[float phraseFreq(), void SloppyPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, int slop, byte[] norms)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_38[[org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer],[Explanation explain(int doc), boolean doNext(), boolean next(), boolean skipTo(int target), float phraseFreq(), float score(), int doc(), void ExactPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void PhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void SloppyPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, int slop, byte[] norms), void firstToLast(), void init(), void pqToList(), void sort()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_39[[org.apache.lucene.search.Scorer],[Explanation explain(int doc), Scorer first(), Scorer last(), Similarity getSimilarity(), boolean doNext(), boolean next(), boolean skipTo(int target), float phraseFreq(), float score(), int doc(), void BooleanScorer(Similarity similarity), void ConjunctionScorer(Similarity similarity), void ExactPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void PhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void Scorer(Similarity similarity), void SloppyPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, int slop, byte[] norms), void SpanScorer(Spans spans, Weight weight, Similarity similarity, byte[] norms), void TermScorer(Weight weight, TermDocs td, Similarity similarity, byte[] norms), void add(Scorer scorer), void add(Scorer scorer, boolean required, boolean prohibited), void computeCoordFactors(), void firstToLast(), void init(), void pqToList(), void score(HitCollector hc), void sort(), void sortScorers()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->NODE_40[[org.apache.lucene.search.ExactPhraseScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer],[float phraseFreq(), void ExactPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_38[...,...]
	->NODE_41[[org.apache.lucene.queryParser.MultiFieldQueryParser, org.apache.lucene.queryParser.QueryParser, org.apache.lucene.queryParser.QueryParserConstants],[Query parse(String query, String[] fields, Analyzer analyzer), Query parse(String query, String[] fields, int[] flags, Analyzer analyzer), void MultiFieldQueryParser(CharStream stream), void MultiFieldQueryParser(QueryParserTokenManager tm), void MultiFieldQueryParser(String f, Analyzer a)]]
	->ITS CHILDREN:=================
	->	->NODE_42[[org.apache.lucene.queryParser.QueryParser, org.apache.lucene.queryParser.QueryParserConstants],[Locale getLocale(), ParseException generateParseException(), Query Clause(String field), Query Query(String field), Query Term(String field), Query getBooleanQuery(Vector clauses), Query getFieldQuery(String field, Analyzer analyzer, String queryText), Query getFieldQuery(String field, Analyzer analyzer, String queryText, int slop), Query getFuzzyQuery(String field, String termStr), Query getPrefixQuery(String field, String termStr), Query getRangeQuery(String field, Analyzer analyzer, String part1, String part2, boolean inclusive), Query getWildcardQuery(String field, String termStr), Query parse(String query), Query parse(String query, String field, Analyzer analyzer), Query parse(String query, String[] fields, Analyzer analyzer), Query parse(String query, String[] fields, int[] flags, Analyzer analyzer), String discardEscapeChar(String input), Token getNextToken(), Token getToken(int index), Token jj_consume_token(int kind), boolean getLowercaseWildcardTerms(), boolean jj_2_1(int xla), boolean jj_3_1(), boolean jj_scan_token(int kind), int Conjunction(), int Modifiers(), int getOperator(), int getPhraseSlop(), int jj_ntk(), void MultiFieldQueryParser(CharStream stream), void MultiFieldQueryParser(QueryParserTokenManager tm), void MultiFieldQueryParser(String f, Analyzer a), void QueryParser(CharStream stream), void QueryParser(QueryParserTokenManager tm), void QueryParser(String f, Analyzer a), void ReInit(CharStream stream), void ReInit(QueryParserTokenManager tm), void addClause(Vector clauses, int conj, int mods, Query q), void disable_tracing(), void enable_tracing(), void jj_add_error_token(int kind, int pos), void jj_la1_0(), void jj_la1_1(), void jj_rescan_token(), void jj_save(int index, int xla), void main(String[] args), void setLocale(Locale locale), void setLowercaseWildcardTerms(boolean lowercaseWildcardTerms), void setOperator(int operator), void setPhraseSlop(int phraseSlop)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_43[[org.apache.lucene.queryParser.QueryParserConstants],[Locale getLocale(), ParseException generateParseException(), Query Clause(String field), Query Query(String field), Query Term(String field), Query getBooleanQuery(Vector clauses), Query getFieldQuery(String field, Analyzer analyzer, String queryText), Query getFieldQuery(String field, Analyzer analyzer, String queryText, int slop), Query getFuzzyQuery(String field, String termStr), Query getPrefixQuery(String field, String termStr), Query getRangeQuery(String field, Analyzer analyzer, String part1, String part2, boolean inclusive), Query getWildcardQuery(String field, String termStr), Query parse(String query), Query parse(String query, String field, Analyzer analyzer), Query parse(String query, String[] fields, Analyzer analyzer), Query parse(String query, String[] fields, int[] flags, Analyzer analyzer), String discardEscapeChar(String input), Token getNextToken(), Token getToken(int index), Token jjFillToken(), Token jj_consume_token(int kind), boolean getLowercaseWildcardTerms(), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), boolean jj_2_1(int xla), boolean jj_3_1(), boolean jj_scan_token(int kind), int Conjunction(), int Modifiers(), int getOperator(), int getPhraseSlop(), int jjMoveNfa_0(int startState, int curPos), int jjMoveNfa_1(int startState, int curPos), int jjMoveNfa_2(int startState, int curPos), int jjMoveNfa_3(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), int jjMoveStringLiteralDfa0_1(), int jjMoveStringLiteralDfa0_2(), int jjMoveStringLiteralDfa0_3(), int jjMoveStringLiteralDfa1_1(long active0), int jjMoveStringLiteralDfa1_2(long active0), int jjStartNfaWithStates_1(int pos, int kind, int state), int jjStartNfaWithStates_2(int pos, int kind, int state), int jjStartNfaWithStates_3(int pos, int kind, int state), int jjStartNfa_1(int pos, long active0), int jjStartNfa_2(int pos, long active0), int jjStartNfa_3(int pos, long active0), int jjStopAtPos(int pos, int kind), int jjStopStringLiteralDfa_1(int pos, long active0), int jjStopStringLiteralDfa_2(int pos, long active0), int jjStopStringLiteralDfa_3(int pos, long active0), int jj_ntk(), void MultiFieldQueryParser(CharStream stream), void MultiFieldQueryParser(QueryParserTokenManager tm), void MultiFieldQueryParser(String f, Analyzer a), void QueryParser(CharStream stream), void QueryParser(QueryParserTokenManager tm), void QueryParser(String f, Analyzer a), void QueryParserTokenManager(CharStream stream), void QueryParserTokenManager(CharStream stream, int lexState), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInit(QueryParserTokenManager tm), void ReInitRounds(), void SwitchTo(int lexState), void addClause(Vector clauses, int conj, int mods, Query q), void disable_tracing(), void enable_tracing(), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void jj_add_error_token(int kind, int pos), void jj_la1_0(), void jj_la1_1(), void jj_rescan_token(), void jj_save(int index, int xla), void main(String[] args), void setDebugStream(java.io.PrintStream ds), void setLocale(Locale locale), void setLowercaseWildcardTerms(boolean lowercaseWildcardTerms), void setOperator(int operator), void setPhraseSlop(int phraseSlop)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->NODE_44[[org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer, org.apache.lucene.index.CompoundFileReader, org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.index.CompoundFileWriter, org.apache.lucene.index.FieldsReader, org.apache.lucene.index.FieldsWriter, org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.IndexReader, org.apache.lucene.index.IndexWriter, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.index.SegmentMergeQueue, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermEnum, org.apache.lucene.index.TermInfosReader, org.apache.lucene.index.TermInfosWriter, org.apache.lucene.index.TermPositions, org.apache.lucene.index.TermVectorsReader, org.apache.lucene.index.TermVectorsWriter, org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.FuzzyTermEnum, org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher, org.apache.lucene.search.WildcardTermEnum, org.apache.lucene.store.Directory, org.apache.lucene.store.FSDirectory, org.apache.lucene.store.FSInputStream, org.apache.lucene.store.FSOutputStream, org.apache.lucene.store.InputStream, org.apache.lucene.store.OutputStream, org.apache.lucene.store.RAMDirectory, org.apache.lucene.store.RAMInputStream, org.apache.lucene.store.RAMOutputStream, org.apache.lucene.util.PriorityQueue],[void close()]]
	->ITS CHILDREN:=================
	->	->NODE_45[[org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.store.FSInputStream, org.apache.lucene.store.InputStream],[void close(), void readInternal(byte[] b, int offset, int len)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_46[[org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.store.InputStream],[void CSInputStream(InputStream base, long fileOffset, long length), void close(), void readInternal(byte[] b, int offset, int len), void seekInternal(long pos)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_47[[org.apache.lucene.store.InputStream],[String readString(), boolean isFDValid(), byte readByte(), int readInt(), int readVInt(), long getFilePointer(), long length(), long readLong(), long readVLong(), void CSInputStream(InputStream base, long fileOffset, long length), void FSInputStream(File path), void RAMInputStream(RAMFile f), void close(), void readBytes(byte[] b, int offset, int len), void readChars(char[] buffer, int start, int length), void readInternal(byte[] b, int offset, int len), void readInternal(byte[] b, int offset, int length), void readInternal(byte[] dest, int destOffset, int len), void refill(), void seek(long pos), void seekInternal(long pos), void seekInternal(long position)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_48[[org.apache.lucene.store.FSInputStream, org.apache.lucene.store.InputStream],[boolean isFDValid(), void FSInputStream(File path), void close(), void readInternal(byte[] b, int offset, int len), void seekInternal(long position)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_47[...,...]
	->	->NODE_49[[org.apache.lucene.index.FieldsReader, org.apache.lucene.index.TermVectorsReader, org.apache.lucene.util.PriorityQueue],[int size(), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->	->	->NODE_50[[org.apache.lucene.index.TermVectorsReader],[SegmentTermVector readTermVector(String field, long tvfPointer), SegmentTermVector[] readTermVectors(String[] fields, long[] tvfPointers), TermFreqVector get(int docNum, String field), TermFreqVector[] get(int docNum), int size(), void TermVectorsReader(Directory d, String segment, FieldInfos fieldInfos), void checkValidFormat(InputStream in), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_51[[org.apache.lucene.index.FieldsReader],[Document doc(int n), int size(), void FieldsReader(Directory d, String segment, FieldInfos fn), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_52[[org.apache.lucene.index.IndexReader, org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[int maxDoc(), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_53[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Explanation explain(Query query, int doc), Query rewrite(Query original), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_54[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Explanation explain(Query query, int doc), Query rewrite(Query original), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_55[[org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Document doc(int n), Explanation explain(Query query, int doc), Query rewrite(Query original), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), int maxDoc(), int searcherIndex(int n), int subDoc(int n), int subSearcher(int n), int[] getStarts(), void MultiSearcher(Searchable[] searchables), void ParallelMultiSearcher(Searchable[] searchables), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_56[[org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Document doc(int i), Document doc(int n), Explanation explain(Query query, int doc), Hits search(Query query), Hits search(Query query, Filter filter), Hits search(Query query, Filter filter, Sort sort), Hits search(Query query, Sort sort), Query rewrite(Query original), Similarity getSimilarity(), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), int maxDoc(), int searcherIndex(int n), int subDoc(int n), int subSearcher(int n), int[] getStarts(), void IndexSearcher(Directory directory), void IndexSearcher(IndexReader r), void IndexSearcher(IndexReader r, boolean closeReader), void IndexSearcher(String path), void MultiSearcher(Searchable[] searchables), void ParallelMultiSearcher(Searchable[] searchables), void close(), void search(Query query, Filter filter, HitCollector results), void search(Query query, HitCollector results), void setSimilarity(Similarity similarity)]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_57[[org.apache.lucene.search.Searchable],[Document doc(int i), Document doc(int n), Explanation explain(Query query, int doc), Hits search(Query query), Hits search(Query query, Filter filter), Hits search(Query query, Filter filter, Sort sort), Hits search(Query query, Sort sort), Query rewrite(Query original), Query rewrite(Query query), Similarity getSimilarity(), TopDocs search(Query query, Filter filter, int n), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), int maxDoc(), int searcherIndex(int n), int subDoc(int n), int subSearcher(int n), int[] getStarts(), void IndexSearcher(Directory directory), void IndexSearcher(IndexReader r), void IndexSearcher(IndexReader r, boolean closeReader), void IndexSearcher(String path), void MultiSearcher(Searchable[] searchables), void ParallelMultiSearcher(Searchable[] searchables), void RemoteSearchable(Searchable local), void close(), void main(String[] args), void search(Query query, Filter filter, HitCollector results), void search(Query query, HitCollector results), void setSimilarity(Similarity similarity)]]
	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->NODE_2[...,...]
	->	->	->	->	->NODE_58[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Document doc(int i), Explanation explain(Query query, int doc), Query rewrite(Query original), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), int maxDoc(), void IndexSearcher(Directory directory), void IndexSearcher(IndexReader r), void IndexSearcher(IndexReader r, boolean closeReader), void IndexSearcher(String path), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_56[...,...]
	->	->	->	->NODE_59[[org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Explanation explain(Query query, int doc), Query rewrite(Query original), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_55[...,...]
	->	->	->	->	->NODE_60[[org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Document doc(int i), Explanation explain(Query query, int doc), Query rewrite(Query original), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_56[...,...]
	->	->	->	->	->	->NODE_61[[org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable],[Document doc(int i), Explanation explain(Query query, int doc), Query rewrite(Query original), TopDocs search(Query query, Filter filter, int n), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), int docFreq(Term term), int maxDoc(), void RemoteSearchable(Searchable local), void close(), void main(String[] args), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_57[...,...]
	->	->	->	->NODE_62[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Document doc(int i), Explanation explain(Query query, int doc), Query rewrite(Query original), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_60[...,...]
	->	->	->	->	->NODE_58[...,...]
	->	->	->NODE_63[[org.apache.lucene.index.IndexReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Directory directory(), Document document(int n), IndexReader open(Directory directory), IndexReader open(Directory directory, boolean closeDirectory), IndexReader open(File path), IndexReader open(String path), TermDocs termDocs(), TermDocs termDocs(Term term), TermEnum terms(), TermEnum terms(Term t), TermEnum terms(Term term), TermFreqVector getTermFreqVector(int docNumber, String field), TermFreqVector getTermFreqVector(int n, String field), TermFreqVector[] getTermFreqVectors(int docNumber), TermFreqVector[] getTermFreqVectors(int n), TermPositions termPositions(), TermPositions termPositions(Term term), Vector files(), boolean hasDeletions(), boolean hasDeletions(SegmentInfo si), boolean hasSeparateNorms(SegmentInfo si), boolean indexExists(Directory directory), boolean indexExists(File directory), boolean indexExists(String directory), boolean isDeleted(int n), boolean isLocked(Directory directory), boolean isLocked(String directory), boolean usesCompoundFile(SegmentInfo si), byte[] norms(String f), byte[] norms(String field), int delete(Term term), int docFreq(Term t), int maxDoc(), int numDocs(), int readerIndex(int n), long getCurrentVersion(Directory directory), long getCurrentVersion(File directory), long getCurrentVersion(String directory), long lastModified(Directory directory), long lastModified(File directory), long lastModified(String directory), void FilterIndexReader(IndexReader in), void IndexReader(Directory directory), void IndexReader(Directory directory, SegmentInfos segmentInfos, boolean closeDirectory), void MultiReader(Directory directory, SegmentInfos sis, boolean closeDirectory, IndexReader[] subReaders), void MultiReader(IndexReader[] subReaders), void SegmentReader(SegmentInfo si), void SegmentReader(SegmentInfos sis, SegmentInfo si, boolean closeDir), void aquireWriteLock(), void close(), void closeNorms(), void commit(), void delete(int docNum), void doClose(), void doCommit(), void doDelete(int docNum), void doDelete(int n), void doSetNorm(int d, String f, byte b), void doSetNorm(int doc, String field, byte value), void doSetNorm(int n, String field, byte value), void doUndeleteAll(), void initialize(IndexReader[] subReaders), void initialize(SegmentInfo si), void norms(String f, byte[] bytes, int offset), void norms(String field, byte[] bytes, int offset), void norms(String field, byte[] result, int offset), void openNorms(Directory cfsDir), void setNorm(int doc, String field, byte value), void setNorm(int doc, String field, float value), void undeleteAll(), void unlock(Directory directory)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_64[[org.apache.lucene.index.TermVectorsWriter],[boolean isDocumentOpen(), boolean isFieldOpen(), void TermVectorsWriter(Directory directory, String segment, FieldInfos fieldInfos), void addTerm(String termText, int freq), void addTermFreqVector(TermFreqVector vector), void addTermFreqVectorInternal(TermFreqVector vector), void addTermInternal(String termText, int freq), void addVectors(TermFreqVector[] vectors), void close(), void closeDocument(), void closeField(), void openDocument(), void openField(String field), void writeDoc(), void writeField()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->	->NODE_65[[org.apache.lucene.store.FSOutputStream, org.apache.lucene.store.InputStream, org.apache.lucene.store.OutputStream, org.apache.lucene.store.RAMOutputStream],[long length(), void close(), void seek(long pos)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_66[[org.apache.lucene.store.InputStream, org.apache.lucene.store.OutputStream],[long getFilePointer(), long length(), void close(), void seek(long pos)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_47[...,...]
	->	->	->	->NODE_67[[org.apache.lucene.store.OutputStream],[long getFilePointer(), long length(), void FSOutputStream(File path), void RAMOutputStream(), void RAMOutputStream(RAMFile f), void close(), void flush(), void flushBuffer(byte[] b, int len), void flushBuffer(byte[] b, int size), void flushBuffer(byte[] src, int len), void reset(), void seek(long pos), void writeByte(byte b), void writeBytes(byte[] b, int length), void writeChars(String s, int start, int length), void writeInt(int i), void writeLong(long i), void writeString(String s), void writeTo(OutputStream out), void writeVInt(int i), void writeVLong(long i)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_68[[org.apache.lucene.store.FSOutputStream, org.apache.lucene.store.OutputStream],[long length(), void FSOutputStream(File path), void close(), void flushBuffer(byte[] b, int size), void seek(long pos)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_67[...,...]
	->	->	->NODE_69[[org.apache.lucene.store.OutputStream, org.apache.lucene.store.RAMOutputStream],[long length(), void RAMOutputStream(), void RAMOutputStream(RAMFile f), void close(), void flushBuffer(byte[] src, int len), void reset(), void seek(long pos), void writeTo(OutputStream out)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_67[...,...]
	->	->NODE_70[[org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.store.InputStream, org.apache.lucene.store.RAMInputStream],[void close(), void seekInternal(long pos)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_71[[org.apache.lucene.store.InputStream, org.apache.lucene.store.RAMInputStream],[void RAMInputStream(RAMFile f), void close(), void readInternal(byte[] dest, int destOffset, int len), void seekInternal(long pos)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_47[...,...]
	->	->	->NODE_46[...,...]
	->	->NODE_72[[org.apache.lucene.index.IndexWriter, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Similarity getSimilarity(), void close(), void setSimilarity(Similarity similarity)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_56[...,...]
	->	->	->NODE_73[[org.apache.lucene.index.IndexWriter],[Analyzer getAnalyzer(), Similarity getSimilarity(), String newSegmentName(), Vector readDeleteableFiles(), boolean getUseCompoundFile(), int docCount(), int getSegmentsCounter(), void IndexWriter(Directory d, Analyzer a, boolean create), void IndexWriter(Directory d, Analyzer a, boolean create, boolean closeDir), void IndexWriter(File path, Analyzer a, boolean create), void IndexWriter(String path, Analyzer a, boolean create), void addDocument(Document doc), void addDocument(Document doc, Analyzer analyzer), void addIndexes(Directory[] dirs), void addIndexes(IndexReader[] readers), void close(), void deleteFiles(Vector files, Directory directory), void deleteFiles(Vector files, Vector deletable), void deleteSegments(Vector segments), void flushRamSegments(), void maybeMergeSegments(), void mergeSegments(int minSegment), void optimize(), void setSimilarity(Similarity similarity), void setUseCompoundFile(boolean value), void writeDeleteableFiles(Vector files)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_74[[org.apache.lucene.index.CompoundFileReader, org.apache.lucene.index.CompoundFileWriter, org.apache.lucene.store.Directory],[Directory getDirectory(), String getName(), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_75[[org.apache.lucene.index.CompoundFileReader, org.apache.lucene.store.Directory],[Directory getDirectory(), InputStream openFile(String id), Lock makeLock(String name), OutputStream createFile(String name), String getName(), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(String name), void CompoundFileReader(Directory dir, String name), void close(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_76[[org.apache.lucene.store.Directory],[Directory getDirectory(), FSDirectory getDirectory(File file, boolean create), FSDirectory getDirectory(String path, boolean create), File getFile(), InputStream openFile(String id), InputStream openFile(String name), Lock makeLock(String name), OutputStream createFile(String name), String getName(), StringBuffer getLockPrefix(), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(File directory, String name), long fileModified(String name), void CompoundFileReader(Directory dir, String name), void FSDirectory(File path, boolean create), void RAMDirectory(), void RAMDirectory(Directory dir), void RAMDirectory(Directory dir, boolean closeDir), void RAMDirectory(File dir), void RAMDirectory(String dir), void close(), void create(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_77[[org.apache.lucene.index.CompoundFileWriter],[Directory getDirectory(), String getName(), void CompoundFileWriter(Directory dir, String name), void addFile(String file), void close(), void copyFile(FileEntry source, OutputStream os, byte[] buffer)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_78[[org.apache.lucene.index.TermInfosReader],[SegmentTermEnum getEnum(), SegmentTermEnum terms(), SegmentTermEnum terms(Term term), Term get(int position), Term scanEnum(int position), TermInfo get(Term term), TermInfo scanEnum(Term term), int getIndexOffset(Term term), int getSkipInterval(), long getPosition(Term term), long size(), void TermInfosReader(Directory dir, String seg, FieldInfos fis), void close(), void readIndex(), void seekEnum(int indexOffset)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->	->NODE_79[[org.apache.lucene.index.TermEnum, org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.FuzzyTermEnum, org.apache.lucene.search.WildcardTermEnum],[boolean endEnum(), boolean termCompare(Term term), float difference(), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_80[[org.apache.lucene.index.TermEnum, org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.FuzzyTermEnum],[boolean endEnum(), boolean termCompare(Term term), float difference(), int editDistance(String s, String t, int n, int m), int min(int a, int b, int c), void FuzzyTermEnum(IndexReader reader, Term term), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_81[[org.apache.lucene.index.TermEnum, org.apache.lucene.search.FilteredTermEnum],[Term term(), boolean endEnum(), boolean next(), boolean termCompare(Term term), boolean wildcardEquals(String pattern, int patternIdx, String string, int stringIdx), float difference(), int docFreq(), int editDistance(String s, String t, int n, int m), int min(int a, int b, int c), void FilteredTermEnum(), void FuzzyTermEnum(IndexReader reader, Term term), void WildcardTermEnum(IndexReader reader, Term term), void close(), void setEnum(TermEnum actualEnum)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_82[[org.apache.lucene.index.TermEnum],[Term readTerm(), Term term(), TermInfo termInfo(), boolean endEnum(), boolean next(), boolean skipTo(Term target), boolean termCompare(Term term), boolean wildcardEquals(String pattern, int patternIdx, String string, int stringIdx), float difference(), int docFreq(), int editDistance(String s, String t, int n, int m), int min(int a, int b, int c), long freqPointer(), long proxPointer(), void FilterTermEnum(TermEnum in), void FilteredTermEnum(), void FuzzyTermEnum(IndexReader reader, Term term), void MultiTermEnum(IndexReader[] readers, int[] starts, Term t), void SegmentTermEnum(InputStream i, FieldInfos fis, boolean isi), void WildcardTermEnum(IndexReader reader, Term term), void close(), void growBuffer(int length), void seek(long pointer, int p, Term t, TermInfo ti), void setEnum(TermEnum actualEnum), void termInfo(TermInfo ti)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_83[[org.apache.lucene.index.TermEnum, org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.WildcardTermEnum],[boolean endEnum(), boolean termCompare(Term term), boolean wildcardEquals(String pattern, int patternIdx, String string, int stringIdx), float difference(), void WildcardTermEnum(IndexReader reader, Term term), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_81[...,...]
	->	->NODE_84[[org.apache.lucene.index.TermInfosWriter],[void TermInfosWriter(Directory directory, String segment, FieldInfos fis), void TermInfosWriter(Directory directory, String segment, FieldInfos fis, boolean isIndex), void add(Term term, TermInfo ti), void close(), void initialize(Directory directory, String segment, FieldInfos fis, boolean isi), void writeTerm(Term term)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->	->NODE_85[[org.apache.lucene.index.FieldsReader, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Document doc(int n), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_55[...,...]
	->	->	->NODE_51[...,...]
	->	->NODE_8[...,...]
	->	->NODE_86[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermEnum, org.apache.lucene.index.TermPositions, org.apache.lucene.search.FilteredTermEnum],[boolean next(), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_87[[org.apache.lucene.index.SegmentMergeInfo],[boolean next(), void SegmentMergeInfo(int b, TermEnum te, IndexReader r), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_88[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[boolean next(), int nextPosition(), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_89[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[boolean next(), int nextPosition(), int read(int[] docs, int[] freqs), void close()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_90[[org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[boolean next(), int nextPosition(), int read(int[] docs, int[] freqs), void SegmentTermPositions(SegmentReader p), void close(), void seek(TermInfo ti), void skipProx(long proxPointer), void skippingDoc()]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_91[[org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void SegmentTermPositions(SegmentReader p), void close(), void seek(TermEnum termEnum), void seek(TermInfo ti), void skipProx(long proxPointer), void skippingDoc()]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_92[[org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void SegmentTermDocs(SegmentReader parent), void SegmentTermPositions(SegmentReader p), void close(), void seek(Term term), void seek(TermEnum termEnum), void seek(TermInfo ti), void skipProx(long proxPointer), void skippingDoc()]]
	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->NODE_93[[org.apache.lucene.index.TermDocs],[TermDocs termDocs(IndexReader reader), TermDocs termDocs(int i), boolean next(), boolean skipTo(int i), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] arg0, int[] arg1), int read(int[] docs, int[] freqs), void FilterTermDocs(TermDocs in), void FilterTermPositions(TermPositions in), void MultiTermDocs(IndexReader[] r, int[] s), void MultiTermPositions(IndexReader[] r, int[] s), void MultipleTermPositions(IndexReader indexReader, Term[] terms), void SegmentTermDocs(SegmentReader parent), void SegmentTermPositions(SegmentReader p), void close(), void seek(Term arg0), void seek(Term term), void seek(TermEnum termEnum), void seek(TermInfo ti), void skipProx(long proxPointer), void skippingDoc()]]
	->	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->	->NODE_2[...,...]
	->	->	->	->	->	->	->NODE_94[[org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[TermDocs termDocs(IndexReader reader), boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] arg0, int[] arg1), int read(int[] docs, int[] freqs), void FilterTermPositions(TermPositions in), void MultiTermPositions(IndexReader[] r, int[] s), void MultipleTermPositions(IndexReader indexReader, Term[] terms), void SegmentTermPositions(SegmentReader p), void close(), void seek(Term arg0), void seek(TermEnum termEnum), void seek(TermInfo ti), void skipProx(long proxPointer), void skippingDoc()]]
	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->NODE_93[...,...]
	->	->	->	->	->NODE_95[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[boolean next(), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void close(), void seek(TermEnum termEnum)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_96[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[boolean next(), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void FilterTermPositions(TermPositions in), void close(), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_97[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.TermDocs],[boolean next(), boolean skipTo(int i), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void FilterTermDocs(TermDocs in), void FilterTermPositions(TermPositions in), void close(), void seek(Term term), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->NODE_93[...,...]
	->	->	->	->	->	->	->NODE_94[...,...]
	->	->	->	->	->	->NODE_98[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs],[boolean next(), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void close(), void seek(Term term), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_97[...,...]
	->	->	->	->	->	->	->NODE_99[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void close(), void seek(Term term), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->NODE_100[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.TermDocs],[TermDocs termDocs(IndexReader reader), TermDocs termDocs(int i), boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void MultiTermDocs(IndexReader[] r, int[] s), void MultiTermPositions(IndexReader[] r, int[] s), void close(), void seek(Term term), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->	->NODE_93[...,...]
	->	->	->	->	->	->	->	->NODE_92[...,...]
	->	->	->	->	->	->NODE_101[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void close(), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_91[...,...]
	->	->	->	->	->	->	->NODE_102[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[TermDocs termDocs(IndexReader reader), boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void MultiTermPositions(IndexReader[] r, int[] s), void close(), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->NODE_100[...,...]
	->	->	->	->	->	->	->	->NODE_94[...,...]
	->	->	->	->	->	->	->NODE_99[...,...]
	->	->	->	->NODE_103[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[boolean next(), int doc(), int freq(), int nextPosition(), void close(), void seek(TermEnum termEnum)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_104[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), void close(), void seek(TermEnum termEnum)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_105[[org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] arg0, int[] arg1), void MultipleTermPositions(IndexReader indexReader, Term[] terms), void close(), void seek(Term arg0), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_94[...,...]
	->	->	->	->	->	->NODE_101[...,...]
	->	->	->	->	->NODE_95[...,...]
	->	->	->NODE_106[[org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.TermEnum, org.apache.lucene.search.FilteredTermEnum],[Term term(), boolean next(), int docFreq(), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_107[[org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.TermEnum],[Term term(), boolean next(), int docFreq(), void FilterTermEnum(TermEnum in), void close()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_82[...,...]
	->	->	->	->NODE_108[[org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.TermEnum],[Term readTerm(), Term term(), TermInfo termInfo(), boolean next(), int docFreq(), long freqPointer(), long proxPointer(), void SegmentTermEnum(InputStream i, FieldInfos fis, boolean isi), void close(), void growBuffer(int length), void seek(long pointer, int p, Term t, TermInfo ti), void termInfo(TermInfo ti)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_82[...,...]
	->	->	->	->NODE_81[...,...]
	->	->	->	->NODE_109[[org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.TermEnum],[Term term(), boolean next(), int docFreq(), void MultiTermEnum(IndexReader[] readers, int[] starts, Term t), void close()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_82[...,...]
	->	->NODE_110[[org.apache.lucene.index.FieldsWriter, org.apache.lucene.index.IndexWriter],[void addDocument(Document doc), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_111[[org.apache.lucene.index.FieldsWriter],[void FieldsWriter(Directory d, String segment, FieldInfos fn), void addDocument(Document doc), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_73[...,...]
	->	->NODE_112[[org.apache.lucene.index.CompoundFileReader, org.apache.lucene.store.Directory, org.apache.lucene.store.FSDirectory, org.apache.lucene.store.RAMDirectory],[Lock makeLock(String name), OutputStream createFile(String name), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(String name), void close(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_113[[org.apache.lucene.store.Directory, org.apache.lucene.store.FSDirectory, org.apache.lucene.store.RAMDirectory],[InputStream openFile(String name), Lock makeLock(String name), OutputStream createFile(String name), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(String name), void close(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_114[[org.apache.lucene.store.Directory, org.apache.lucene.store.RAMDirectory],[InputStream openFile(String name), Lock makeLock(String name), OutputStream createFile(String name), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(String name), void RAMDirectory(), void RAMDirectory(Directory dir), void RAMDirectory(Directory dir, boolean closeDir), void RAMDirectory(File dir), void RAMDirectory(String dir), void close(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_76[...,...]
	->	->	->	->NODE_115[[org.apache.lucene.store.Directory, org.apache.lucene.store.FSDirectory],[FSDirectory getDirectory(File file, boolean create), FSDirectory getDirectory(String path, boolean create), File getFile(), InputStream openFile(String name), Lock makeLock(String name), OutputStream createFile(String name), StringBuffer getLockPrefix(), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(File directory, String name), long fileModified(String name), void FSDirectory(File path, boolean create), void close(), void create(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_76[...,...]
	->	->	->NODE_75[...,...]
	->	->NODE_116[[org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer],[Token next(), org.apache.lucene.analysis.Token next(), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_117[[org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jj_consume_token(int kind), Token next(), boolean isTokenChar(char c), char normalize(char c), int jj_ntk(), org.apache.lucene.analysis.Token next(), void CharTokenizer(Reader input), void LetterTokenizer(Reader in), void LowerCaseTokenizer(Reader in), void ReInit(CharStream stream), void ReInit(StandardTokenizerTokenManager tm), void RussianLetterTokenizer(Reader in, char[] charset), void StandardTokenizer(CharStream stream), void StandardTokenizer(Reader reader), void StandardTokenizer(StandardTokenizerTokenManager tm), void Tokenizer(), void Tokenizer(Reader input), void WhitespaceTokenizer(Reader in), void close(), void disable_tracing(), void enable_tracing(), void jj_la1_0()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_118[[org.apache.lucene.analysis.TokenStream],[Hashtable makeStopTable(String[] stopWords), ParseException generateParseException(), Set makeStopSet(String[] stopWords), Token getNextToken(), Token getToken(int index), Token jj_consume_token(int kind), Token next(), boolean isTokenChar(char c), char normalize(char c), int jj_ntk(), org.apache.lucene.analysis.Token next(), void CharTokenizer(Reader input), void GermanStemFilter(TokenStream in), void GermanStemFilter(TokenStream in, Hashtable exclusiontable), void GermanStemFilter(TokenStream in, Set exclusionSet), void LetterTokenizer(Reader in), void LowerCaseFilter(TokenStream in), void LowerCaseTokenizer(Reader in), void PorterStemFilter(TokenStream in), void ReInit(CharStream stream), void ReInit(StandardTokenizerTokenManager tm), void RussianLetterTokenizer(Reader in, char[] charset), void RussianLowerCaseFilter(TokenStream in, char[] charset), void RussianStemFilter(TokenStream in, char[] charset), void StandardFilter(TokenStream in), void StandardTokenizer(CharStream stream), void StandardTokenizer(Reader reader), void StandardTokenizer(StandardTokenizerTokenManager tm), void StopFilter(TokenStream in, Hashtable stopTable), void StopFilter(TokenStream in, Set stopWords), void StopFilter(TokenStream in, String[] stopWords), void TokenFilter(), void TokenFilter(TokenStream input), void Tokenizer(), void Tokenizer(Reader input), void WhitespaceTokenizer(Reader in), void close(), void disable_tracing(), void enable_tracing(), void jj_la1_0(), void setExclusionSet(Set exclusionSet), void setExclusionTable(Hashtable exclusiontable), void setStemmer(GermanStemmer stemmer), void setStemmer(RussianStemmer stemmer)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_119[[org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream],[Hashtable makeStopTable(String[] stopWords), Set makeStopSet(String[] stopWords), Token next(), org.apache.lucene.analysis.Token next(), void GermanStemFilter(TokenStream in), void GermanStemFilter(TokenStream in, Hashtable exclusiontable), void GermanStemFilter(TokenStream in, Set exclusionSet), void LowerCaseFilter(TokenStream in), void PorterStemFilter(TokenStream in), void RussianLowerCaseFilter(TokenStream in, char[] charset), void RussianStemFilter(TokenStream in, char[] charset), void StandardFilter(TokenStream in), void StopFilter(TokenStream in, Hashtable stopTable), void StopFilter(TokenStream in, Set stopWords), void StopFilter(TokenStream in, String[] stopWords), void TokenFilter(), void TokenFilter(TokenStream input), void close(), void setExclusionSet(Set exclusionSet), void setExclusionTable(Hashtable exclusiontable), void setStemmer(GermanStemmer stemmer), void setStemmer(RussianStemmer stemmer)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_118[...,...]
	->NODE_120[[org.apache.lucene.analysis.CharTokenizer, org.apache.lucene.analysis.LowerCaseFilter, org.apache.lucene.analysis.PorterStemFilter, org.apache.lucene.analysis.StopFilter, org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer, org.apache.lucene.analysis.de.GermanStemFilter, org.apache.lucene.analysis.ru.RussianLowerCaseFilter, org.apache.lucene.analysis.ru.RussianStemFilter],[Token next()]]
	->ITS CHILDREN:=================
	->	->NODE_121[[org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.ru.RussianStemFilter],[Token next(), void RussianStemFilter(TokenStream in, char[] charset), void setStemmer(RussianStemmer stemmer)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_119[...,...]
	->	->NODE_122[[org.apache.lucene.analysis.LowerCaseFilter, org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream],[Token next(), void LowerCaseFilter(TokenStream in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_119[...,...]
	->	->NODE_123[[org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.de.GermanStemFilter],[Token next(), void GermanStemFilter(TokenStream in), void GermanStemFilter(TokenStream in, Hashtable exclusiontable), void GermanStemFilter(TokenStream in, Set exclusionSet), void setExclusionSet(Set exclusionSet), void setExclusionTable(Hashtable exclusiontable), void setStemmer(GermanStemmer stemmer)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_119[...,...]
	->	->NODE_124[[org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.ru.RussianLowerCaseFilter],[Token next(), void RussianLowerCaseFilter(TokenStream in, char[] charset)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_119[...,...]
	->	->NODE_116[...,...]
	->	->NODE_125[[org.apache.lucene.analysis.CharTokenizer, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer],[Token next(), boolean isTokenChar(char c), char normalize(char c), void CharTokenizer(Reader input), void LetterTokenizer(Reader in), void LowerCaseTokenizer(Reader in), void RussianLetterTokenizer(Reader in, char[] charset), void WhitespaceTokenizer(Reader in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_117[...,...]
	->	->NODE_126[[org.apache.lucene.analysis.StopFilter, org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream],[Hashtable makeStopTable(String[] stopWords), Set makeStopSet(String[] stopWords), Token next(), void StopFilter(TokenStream in, Hashtable stopTable), void StopFilter(TokenStream in, Set stopWords), void StopFilter(TokenStream in, String[] stopWords)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_119[...,...]
	->	->NODE_127[[org.apache.lucene.analysis.PorterStemFilter, org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream],[Token next(), void PorterStemFilter(TokenStream in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_119[...,...]
	->NODE_128[[org.apache.lucene.analysis.standard.Token, org.apache.lucene.queryParser.Token],[Token newToken(int ofKind)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_129[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.FilterIndexReader.FilterTermPositions, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultiTermPositions, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[int nextPosition()]]
	->ITS CHILDREN:=================
	->	->NODE_88[...,...]
	->	->NODE_130[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultiTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[TermDocs termDocs(IndexReader reader), int nextPosition(), void MultiTermPositions(IndexReader[] r, int[] s)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_102[...,...]
	->	->NODE_131[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.FilterIndexReader.FilterTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions],[int nextPosition(), void FilterTermPositions(TermPositions in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_96[...,...]
	->NODE_132[[org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer, org.apache.lucene.analysis.standard.StandardTokenizer, org.apache.lucene.analysis.standard.StandardTokenizerConstants, org.apache.lucene.analysis.standard.StandardTokenizerTokenManager, org.apache.lucene.queryParser.QueryParser, org.apache.lucene.queryParser.QueryParserConstants, org.apache.lucene.queryParser.QueryParserTokenManager],[Token getNextToken(), void ReInit(CharStream stream)]]
	->ITS CHILDREN:=================
	->	->NODE_133[[org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer, org.apache.lucene.analysis.standard.StandardTokenizer, org.apache.lucene.analysis.standard.StandardTokenizerConstants, org.apache.lucene.queryParser.QueryParser, org.apache.lucene.queryParser.QueryParserConstants],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jj_consume_token(int kind), int jj_ntk(), void ReInit(CharStream stream), void disable_tracing(), void enable_tracing(), void jj_la1_0()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_134[[org.apache.lucene.analysis.standard.StandardTokenizerConstants, org.apache.lucene.queryParser.QueryParserConstants],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jjFillToken(), Token jj_consume_token(int kind), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), int jjMoveNfa_0(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), int jj_ntk(), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInitRounds(), void SwitchTo(int lexState), void disable_tracing(), void enable_tracing(), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void jj_la1_0(), void setDebugStream(java.io.PrintStream ds)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_135[[org.apache.lucene.analysis.standard.StandardTokenizerConstants],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jjFillToken(), Token jj_consume_token(int kind), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), boolean jjCanMove_1(int hiByte, int i1, int i2, long l1, long l2), boolean jjCanMove_2(int hiByte, int i1, int i2, long l1, long l2), int jjMoveNfa_0(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), int jj_ntk(), org.apache.lucene.analysis.Token next(), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInit(StandardTokenizerTokenManager tm), void ReInitRounds(), void StandardFilter(TokenStream in), void StandardTokenizer(CharStream stream), void StandardTokenizer(Reader reader), void StandardTokenizer(StandardTokenizerTokenManager tm), void StandardTokenizerTokenManager(CharStream stream), void StandardTokenizerTokenManager(CharStream stream, int lexState), void SwitchTo(int lexState), void disable_tracing(), void enable_tracing(), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void jj_la1_0(), void setDebugStream(java.io.PrintStream ds)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->	->NODE_43[...,...]
	->	->	->NODE_42[...,...]
	->	->	->NODE_136[[org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer, org.apache.lucene.analysis.standard.StandardTokenizer, org.apache.lucene.analysis.standard.StandardTokenizerConstants],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jj_consume_token(int kind), int jj_ntk(), org.apache.lucene.analysis.Token next(), void ReInit(CharStream stream), void ReInit(StandardTokenizerTokenManager tm), void StandardTokenizer(CharStream stream), void StandardTokenizer(Reader reader), void StandardTokenizer(StandardTokenizerTokenManager tm), void disable_tracing(), void enable_tracing(), void jj_la1_0()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_117[...,...]
	->	->	->	->NODE_137[[org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.standard.StandardTokenizerConstants],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jj_consume_token(int kind), int jj_ntk(), org.apache.lucene.analysis.Token next(), void ReInit(CharStream stream), void ReInit(StandardTokenizerTokenManager tm), void StandardFilter(TokenStream in), void StandardTokenizer(CharStream stream), void StandardTokenizer(Reader reader), void StandardTokenizer(StandardTokenizerTokenManager tm), void disable_tracing(), void enable_tracing(), void jj_la1_0()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_135[...,...]
	->	->	->	->	->NODE_118[...,...]
	->	->NODE_138[[org.apache.lucene.analysis.standard.StandardTokenizerConstants, org.apache.lucene.analysis.standard.StandardTokenizerTokenManager, org.apache.lucene.queryParser.QueryParserConstants, org.apache.lucene.queryParser.QueryParserTokenManager],[Token getNextToken(), Token jjFillToken(), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), int jjMoveNfa_0(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInitRounds(), void SwitchTo(int lexState), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void setDebugStream(java.io.PrintStream ds)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_139[[org.apache.lucene.analysis.standard.StandardTokenizerConstants, org.apache.lucene.analysis.standard.StandardTokenizerTokenManager],[Token getNextToken(), Token jjFillToken(), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), boolean jjCanMove_1(int hiByte, int i1, int i2, long l1, long l2), boolean jjCanMove_2(int hiByte, int i1, int i2, long l1, long l2), int jjMoveNfa_0(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInitRounds(), void StandardTokenizerTokenManager(CharStream stream), void StandardTokenizerTokenManager(CharStream stream, int lexState), void SwitchTo(int lexState), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void setDebugStream(java.io.PrintStream ds)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_135[...,...]
	->	->	->NODE_134[...,...]
	->	->	->NODE_140[[org.apache.lucene.queryParser.QueryParserConstants, org.apache.lucene.queryParser.QueryParserTokenManager],[Token getNextToken(), Token jjFillToken(), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), int jjMoveNfa_0(int startState, int curPos), int jjMoveNfa_1(int startState, int curPos), int jjMoveNfa_2(int startState, int curPos), int jjMoveNfa_3(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), int jjMoveStringLiteralDfa0_1(), int jjMoveStringLiteralDfa0_2(), int jjMoveStringLiteralDfa0_3(), int jjMoveStringLiteralDfa1_1(long active0), int jjMoveStringLiteralDfa1_2(long active0), int jjStartNfaWithStates_1(int pos, int kind, int state), int jjStartNfaWithStates_2(int pos, int kind, int state), int jjStartNfaWithStates_3(int pos, int kind, int state), int jjStartNfa_1(int pos, long active0), int jjStartNfa_2(int pos, long active0), int jjStartNfa_3(int pos, long active0), int jjStopAtPos(int pos, int kind), int jjStopStringLiteralDfa_1(int pos, long active0), int jjStopStringLiteralDfa_2(int pos, long active0), int jjStopStringLiteralDfa_3(int pos, long active0), void QueryParserTokenManager(CharStream stream), void QueryParserTokenManager(CharStream stream, int lexState), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInitRounds(), void SwitchTo(int lexState), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void setDebugStream(java.io.PrintStream ds)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_43[...,...]
	->NODE_141[[org.apache.lucene.document.DateField],[Date stringToDate(String s), String MAX_DATE_STRING(), String MIN_DATE_STRING(), String dateToString(Date date), String timeToString(long time), long stringToTime(String s), void DateField()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_142[[org.apache.lucene.analysis.Analyzer, org.apache.lucene.analysis.PerFieldAnalyzerWrapper, org.apache.lucene.analysis.SimpleAnalyzer, org.apache.lucene.analysis.StopAnalyzer, org.apache.lucene.analysis.WhitespaceAnalyzer, org.apache.lucene.analysis.de.GermanAnalyzer, org.apache.lucene.analysis.ru.RussianAnalyzer, org.apache.lucene.analysis.standard.StandardAnalyzer],[TokenStream tokenStream(String fieldName, Reader reader)]]
	->ITS CHILDREN:=================
	->	->NODE_143[[org.apache.lucene.analysis.Analyzer, org.apache.lucene.analysis.ru.RussianAnalyzer],[String[] makeStopWords(char[] charset), TokenStream tokenStream(String fieldName, Reader reader), void RussianAnalyzer(), void RussianAnalyzer(char[] charset), void RussianAnalyzer(char[] charset, Hashtable stopwords), void RussianAnalyzer(char[] charset, String[] stopwords)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_144[[org.apache.lucene.analysis.Analyzer],[String[] makeStopWords(char[] charset), TokenStream tokenStream(Reader reader), TokenStream tokenStream(String fieldName, Reader reader), void GermanAnalyzer(), void GermanAnalyzer(File stopwords), void GermanAnalyzer(Hashtable stopwords), void GermanAnalyzer(String[] stopwords), void PerFieldAnalyzerWrapper(Analyzer defaultAnalyzer), void RussianAnalyzer(), void RussianAnalyzer(char[] charset), void RussianAnalyzer(char[] charset, Hashtable stopwords), void RussianAnalyzer(char[] charset, String[] stopwords), void StandardAnalyzer(), void StandardAnalyzer(String[] stopWords), void StopAnalyzer(), void StopAnalyzer(String[] stopWords), void addAnalyzer(String fieldName, Analyzer analyzer), void setStemExclusionTable(File exclusionlist), void setStemExclusionTable(Hashtable exclusionlist), void setStemExclusionTable(String[] exclusionlist)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_145[[org.apache.lucene.analysis.Analyzer, org.apache.lucene.analysis.PerFieldAnalyzerWrapper],[TokenStream tokenStream(String fieldName, Reader reader), void PerFieldAnalyzerWrapper(Analyzer defaultAnalyzer), void addAnalyzer(String fieldName, Analyzer analyzer)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_144[...,...]
	->	->NODE_146[[org.apache.lucene.analysis.Analyzer, org.apache.lucene.analysis.de.GermanAnalyzer],[TokenStream tokenStream(String fieldName, Reader reader), void GermanAnalyzer(), void GermanAnalyzer(File stopwords), void GermanAnalyzer(Hashtable stopwords), void GermanAnalyzer(String[] stopwords), void setStemExclusionTable(File exclusionlist), void setStemExclusionTable(Hashtable exclusionlist), void setStemExclusionTable(String[] exclusionlist)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_144[...,...]
	->	->NODE_147[[org.apache.lucene.analysis.Analyzer, org.apache.lucene.analysis.StopAnalyzer],[TokenStream tokenStream(String fieldName, Reader reader), void StopAnalyzer(), void StopAnalyzer(String[] stopWords)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_144[...,...]
	->	->NODE_148[[org.apache.lucene.analysis.Analyzer, org.apache.lucene.analysis.standard.StandardAnalyzer],[TokenStream tokenStream(String fieldName, Reader reader), void StandardAnalyzer(), void StandardAnalyzer(String[] stopWords)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_144[...,...]
	->NODE_149[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.PhraseQuery, org.apache.lucene.search.Query, org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanQuery],[Weight createWeight(Searcher searcher)]]
	->ITS CHILDREN:=================
	->	->NODE_150[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.Query],[Query rewrite(IndexReader reader), Weight createWeight(Searcher searcher)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_151[[org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.Query],[Query getQuery(), Query rewrite(IndexReader reader), String toString(String s), Weight createWeight(Searcher searcher), void FilteredQuery(Query query, Filter filter)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_14[...,...]
	->	->	->NODE_16[...,...]
	->	->NODE_15[...,...]
	->	->NODE_152[[org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.PhraseQuery, org.apache.lucene.search.Query, org.apache.lucene.search.spans.SpanQuery],[Weight createWeight(Searcher searcher), int getSlop()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_19[...,...]
	->	->	->NODE_153[[org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.PhraseQuery, org.apache.lucene.search.Query],[String toString(String f), Weight createWeight(Searcher searcher), int getSlop(), void add(Term term), void setSlop(int s)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_154[[org.apache.lucene.search.PhraseQuery, org.apache.lucene.search.Query],[String toString(String f), Term[] getTerms(), Weight createWeight(Searcher searcher), int getSlop(), void PhraseQuery(), void add(Term term), void setSlop(int s)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_14[...,...]
	->	->	->	->NODE_155[[org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.Query],[String toString(String f), Weight createWeight(Searcher searcher), int getSlop(), void add(Term term), void add(Term[] terms), void setSlop(int s)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_14[...,...]
	->NODE_156[[org.apache.lucene.analysis.standard.TokenMgrError, org.apache.lucene.queryParser.TokenMgrError],[String LexicalError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar), String addEscapes(String str), void TokenMgrError(), void TokenMgrError(String message, int reason), void TokenMgrError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar, int reason)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_157[[org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.Query, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.Weight, org.apache.lucene.search.spans.SpanWeight],[Query getQuery()]]
	->ITS CHILDREN:=================
	->	->NODE_151[...,...]
	->	->NODE_158[[org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.Weight, org.apache.lucene.search.spans.SpanWeight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_159[[org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.Weight, org.apache.lucene.search.spans.SpanWeight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void normalize(float queryNorm)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_160[[org.apache.lucene.search.Weight, org.apache.lucene.search.spans.SpanWeight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void SpanWeight(SpanQuery query, Searcher searcher), void normalize(float queryNorm)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_161[[org.apache.lucene.search.Weight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void BooleanWeight(Searcher searcher), void PhrasePrefixWeight(Searcher searcher), void PhraseWeight(Searcher searcher), void SpanWeight(SpanQuery query, Searcher searcher), void TermWeight(Searcher searcher), void normalize(float norm), void normalize(float queryNorm)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_2[...,...]
	->	->	->	->NODE_162[[org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.Weight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void PhrasePrefixWeight(Searcher searcher), void normalize(float queryNorm)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_161[...,...]
	->	->	->	->NODE_163[[org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.Weight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void PhraseWeight(Searcher searcher), void normalize(float queryNorm)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_161[...,...]
	->	->	->	->NODE_164[[org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.Weight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void TermWeight(Searcher searcher), void normalize(float queryNorm)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_161[...,...]
	->	->	->NODE_165[[org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.Weight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void BooleanWeight(Searcher searcher), void normalize(float norm)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_161[...,...]
	->NODE_166[[org.apache.lucene.index.SegmentInfo],[void SegmentInfo(String name, int docCount, Directory dir)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_167[[org.apache.lucene.store.Lock],[boolean isLocked(), boolean obtain(), boolean obtain(long lockWaitTimeout), void release()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_168[[org.apache.lucene.index.FieldsReader, org.apache.lucene.search.Hits, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Document doc(int n)]]
	->ITS CHILDREN:=================
	->	->NODE_85[...,...]
	->	->NODE_169[[org.apache.lucene.search.Hits],[Document doc(int n), HitDoc hitDoc(int n), float score(int n), int id(int n), int length(), void Hits(Searcher s, Query q, Filter f), void Hits(Searcher s, Query q, Filter f, Sort o), void addToFront(HitDoc hitDoc), void getMoreDocs(int min), void remove(HitDoc hitDoc)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_170[[org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.IndexReader, org.apache.lucene.index.MultiReader, org.apache.lucene.index.SegmentReader, org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[int maxDoc()]]
	->ITS CHILDREN:=================
	->	->NODE_52[...,...]
	->	->NODE_171[[org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.IndexReader, org.apache.lucene.index.MultiReader, org.apache.lucene.index.SegmentReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), int docFreq(Term t), int maxDoc(), int numDocs(), void doClose(), void doCommit(), void doUndeleteAll()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_172[[org.apache.lucene.index.IndexReader, org.apache.lucene.index.MultiReader, org.apache.lucene.index.SegmentReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), byte[] norms(String field), int docFreq(Term t), int maxDoc(), int numDocs(), void doClose(), void doCommit(), void doUndeleteAll()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_173[[org.apache.lucene.index.IndexReader, org.apache.lucene.index.MultiReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermEnum terms(Term term), TermFreqVector getTermFreqVector(int n, String field), TermFreqVector[] getTermFreqVectors(int n), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), byte[] norms(String field), int docFreq(Term t), int maxDoc(), int numDocs(), int readerIndex(int n), void MultiReader(Directory directory, SegmentInfos sis, boolean closeDirectory, IndexReader[] subReaders), void MultiReader(IndexReader[] subReaders), void doClose(), void doCommit(), void doDelete(int n), void doSetNorm(int n, String field, byte value), void doUndeleteAll(), void initialize(IndexReader[] subReaders), void norms(String field, byte[] result, int offset)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_63[...,...]
	->	->	->	->NODE_174[[org.apache.lucene.index.IndexReader, org.apache.lucene.index.SegmentReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermEnum terms(Term t), TermFreqVector getTermFreqVector(int docNumber, String field), TermFreqVector[] getTermFreqVectors(int docNumber), TermPositions termPositions(), Vector files(), boolean hasDeletions(), boolean hasDeletions(SegmentInfo si), boolean hasSeparateNorms(SegmentInfo si), boolean isDeleted(int n), boolean usesCompoundFile(SegmentInfo si), byte[] norms(String field), int docFreq(Term t), int maxDoc(), int numDocs(), void SegmentReader(SegmentInfo si), void SegmentReader(SegmentInfos sis, SegmentInfo si, boolean closeDir), void closeNorms(), void doClose(), void doCommit(), void doDelete(int docNum), void doSetNorm(int doc, String field, byte value), void doUndeleteAll(), void initialize(SegmentInfo si), void norms(String field, byte[] bytes, int offset), void openNorms(Directory cfsDir)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_63[...,...]
	->	->	->NODE_175[[org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.IndexReader, org.apache.lucene.index.MultiReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), int docFreq(Term t), int maxDoc(), int numDocs(), void doClose(), void doCommit(), void doDelete(int n), void doUndeleteAll()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_173[...,...]
	->	->	->	->NODE_176[[org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.IndexReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermEnum terms(Term t), TermFreqVector getTermFreqVector(int docNumber, String field), TermFreqVector[] getTermFreqVectors(int docNumber), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), byte[] norms(String f), int docFreq(Term t), int maxDoc(), int numDocs(), void FilterIndexReader(IndexReader in), void doClose(), void doCommit(), void doDelete(int n), void doSetNorm(int d, String f, byte b), void doUndeleteAll(), void norms(String f, byte[] bytes, int offset)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_63[...,...]
	->	->	->NODE_177[[org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.IndexReader, org.apache.lucene.index.SegmentReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermEnum terms(Term t), TermFreqVector getTermFreqVector(int docNumber, String field), TermFreqVector[] getTermFreqVectors(int docNumber), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), int docFreq(Term t), int maxDoc(), int numDocs(), void doClose(), void doCommit(), void doUndeleteAll()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_176[...,...]
	->	->	->	->NODE_174[...,...]
	->NODE_178[[org.apache.lucene.search.MultiSearcherThread],[IOException getIOException(), int hits(), void MultiSearcherThread(Searchable searchable, Query query, Filter filter, int nDocs, FieldDocSortedHitQueue hq, Sort sort, int i, int[] starts, String name), void MultiSearcherThread(Searchable searchable, Query query, Filter filter, int nDocs, HitQueue hq, int i, int[] starts, String name)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_179[[org.apache.lucene.analysis.Token],[String termText(), String type(), int endOffset(), int getPositionIncrement(), int startOffset(), void Token(String text, int start, int end), void Token(String text, int start, int end, String typ), void setPositionIncrement(int positionIncrement)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_180[[org.apache.lucene.search.FieldCache.StringIndex],[void StringIndex(int[] values, String[] lookup)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_181[[org.apache.lucene.index.TermVectorsWriter.TVField],[void TVField(int number)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_182[[org.apache.lucene.analysis.CharTokenizer, org.apache.lucene.analysis.LetterTokenizer, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer, org.apache.lucene.analysis.WhitespaceTokenizer, org.apache.lucene.analysis.ru.RussianLetterTokenizer],[boolean isTokenChar(char c)]]
	->ITS CHILDREN:=================
	->	->NODE_183[[org.apache.lucene.analysis.CharTokenizer, org.apache.lucene.analysis.LetterTokenizer, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer],[boolean isTokenChar(char c), char normalize(char c), void LetterTokenizer(Reader in), void LowerCaseTokenizer(Reader in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_125[...,...]
	->	->NODE_184[[org.apache.lucene.analysis.CharTokenizer, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer, org.apache.lucene.analysis.ru.RussianLetterTokenizer],[boolean isTokenChar(char c), void RussianLetterTokenizer(Reader in, char[] charset)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_125[...,...]
	->	->NODE_185[[org.apache.lucene.analysis.CharTokenizer, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer, org.apache.lucene.analysis.WhitespaceTokenizer],[boolean isTokenChar(char c), void WhitespaceTokenizer(Reader in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_125[...,...]
	->NODE_186[[org.apache.lucene.index.Posting],[void Posting(Term t, int position)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_187[[org.apache.lucene.search.BooleanClause],[void BooleanClause(Query q, boolean r, boolean p)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_188[[org.apache.lucene.search.Sort],[void Sort(), void Sort(SortField field), void Sort(SortField[] fields), void Sort(String field), void Sort(String field, boolean reverse), void Sort(String[] fields), void setSort(SortField field), void setSort(SortField[] fields), void setSort(String field), void setSort(String field, boolean reverse), void setSort(String[] fieldnames)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_189[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermEnum, org.apache.lucene.index.TermPositions, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.PhrasePositions, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.Spans],[boolean next()]]
	->ITS CHILDREN:=================
	->	->NODE_190[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhrasePositions, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.Spans],[boolean next(), boolean skipTo(int target)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_191[[org.apache.lucene.search.PhrasePositions],[boolean next(), boolean nextPosition(), boolean skipTo(int target), void PhrasePositions(TermPositions t, int o), void firstPosition()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_192[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.Spans],[boolean next(), boolean skipTo(int target), int doc()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_193[[org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.SpanScorer],[Explanation explain(int doc), boolean next(), boolean skipTo(int target), float score(), int doc()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_194[[org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer],[Explanation explain(int doc), boolean doNext(), boolean next(), boolean skipTo(int target), float score(), int doc(), void init()]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_195[[org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.Scorer],[Explanation explain(int doc), Scorer first(), Scorer last(), boolean doNext(), boolean next(), boolean skipTo(int target), float score(), int doc(), void ConjunctionScorer(Similarity similarity), void add(Scorer scorer), void init(), void sortScorers()]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_39[...,...]
	->	->	->	->	->	->NODE_38[...,...]
	->	->	->	->	->NODE_196[[org.apache.lucene.search.Scorer, org.apache.lucene.search.spans.SpanScorer],[Explanation explain(int doc), boolean next(), boolean skipTo(int target), float score(), int doc(), void SpanScorer(Spans spans, Weight weight, Similarity similarity, byte[] norms)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_39[...,...]
	->	->	->	->	->NODE_197[[org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer],[Explanation explain(int doc), boolean next(), boolean skipTo(int target), float score(), int doc(), void TermScorer(Weight weight, TermDocs td, Similarity similarity, byte[] norms)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_39[...,...]
	->	->	->	->	->NODE_198[[org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.Scorer],[Explanation explain(int doc), boolean next(), boolean skipTo(int target), float score(), int doc(), void BooleanScorer(Similarity similarity), void add(Scorer scorer, boolean required, boolean prohibited), void computeCoordFactors()]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_39[...,...]
	->	->	->	->NODE_199[[org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.Spans],[boolean next(), boolean skipTo(int target), int doc(), int end(), int start()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_200[[org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.Spans],[SpansCell min(), boolean atMatch(), boolean checkSlop(), boolean firstNonOrderedNextToPartialList(), boolean matchIsOrdered(), boolean next(), boolean skipTo(int target), int doc(), int end(), int start(), void NearSpans(SpanNearQuery query, IndexReader reader), void addToList(SpansCell cell), void firstToLast(), void initList(boolean next), void listToQueue(), void partialListToQueue(), void queueToList()]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_201[[org.apache.lucene.search.spans.Spans],[SpansCell min(), boolean atMatch(), boolean checkSlop(), boolean firstNonOrderedNextToPartialList(), boolean matchIsOrdered(), boolean next(), boolean skipTo(int target), int doc(), int end(), int start(), void NearSpans(SpanNearQuery query, IndexReader reader), void SpansCell(Spans spans, int index), void addToList(SpansCell cell), void firstToLast(), void initList(boolean next), void listToQueue(), void partialListToQueue(), void queueToList()]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_2[...,...]
	->	->	->	->	->NODE_202[[org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.Spans],[boolean next(), boolean skipTo(int target), int doc(), int end(), int start(), void SpansCell(Spans spans, int index)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_201[...,...]
	->	->	->	->NODE_203[[org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.Spans],[boolean next(), boolean skipTo(int target), int doc(), void firstToLast()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_200[...,...]
	->	->	->	->	->NODE_38[...,...]
	->	->	->	->NODE_104[...,...]
	->	->NODE_204[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermPositions, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.Spans],[boolean next(), int doc()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_103[...,...]
	->	->	->NODE_192[...,...]
	->	->NODE_86[...,...]
	->NODE_205[[org.apache.lucene.analysis.CharTokenizer, org.apache.lucene.analysis.LetterTokenizer, org.apache.lucene.analysis.LowerCaseTokenizer, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer],[char normalize(char c), void LowerCaseTokenizer(Reader in)]]
	->ITS CHILDREN:=================
	->	->NODE_183[...,...]
	->NODE_206[[org.apache.lucene.analysis.de.WordlistLoader],[HashSet getWordSet(File wordfile), Hashtable getWordtable(File wordfile), Hashtable getWordtable(String path, String wordfile), Hashtable getWordtable(String wordfile), Hashtable makeWordTable(HashSet wordSet)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_207[[org.apache.lucene.search.FieldCache, org.apache.lucene.search.FieldCacheImpl],[Comparable[] getCustom(IndexReader reader, String field, SortComparator comparator), Object getAuto(IndexReader reader, String field), Object lookup(IndexReader reader, String field, Object comparer), Object lookup(IndexReader reader, String field, int type), Object store(IndexReader reader, String field, Object comparer, Object value), Object store(IndexReader reader, String field, int type, Object value), StringIndex getStringIndex(IndexReader reader, String field), String[] getStrings(IndexReader reader, String field), float[] getFloats(IndexReader reader, String field), int[] getInts(IndexReader reader, String field)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_208[[org.apache.lucene.analysis.ru.RussianStemmer],[String stem(String input), String stem(String theWord, char[] charset), boolean adjectival(StringBuffer stemmingZone), boolean derivational(StringBuffer stemmingZone), boolean findAndRemoveEnding(StringBuffer stemmingZone, char[][] theEndingClass), boolean findAndRemoveEnding(StringBuffer stemmingZone, char[][] theEndingClass, char[][] thePredessors), boolean isVowel(char letter), boolean noun(StringBuffer stemmingZone), boolean perfectiveGerund(StringBuffer stemmingZone), boolean reflexive(StringBuffer stemmingZone), boolean removeI(StringBuffer stemmingZone), boolean removeSoft(StringBuffer stemmingZone), boolean superlative(StringBuffer stemmingZone), boolean undoubleN(StringBuffer stemmingZone), boolean verb(StringBuffer stemmingZone), int findEnding(StringBuffer stemmingZone, char[][] theEndingClass), int findEnding(StringBuffer stemmingZone, int startIndex, char[][] theEndingClass), void RussianStemmer(), void RussianStemmer(char[] charset), void markPositions(String word), void setCharset(char[] newCharset), void setEndings()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_209[[org.apache.lucene.search.FuzzyQuery, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.Query, org.apache.lucene.search.WildcardQuery],[FilteredTermEnum getEnum(IndexReader reader)]]
	->ITS CHILDREN:=================
	->	->NODE_210[[org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.Query, org.apache.lucene.search.WildcardQuery],[FilteredTermEnum getEnum(IndexReader reader), void WildcardQuery(Term term)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_13[...,...]
	->	->NODE_12[...,...]
	->NODE_211[[org.apache.lucene.search.PhraseQueue, org.apache.lucene.search.spans.NearSpans.CellQueue, org.apache.lucene.search.spans.SpanOrQuery.SpanQueue, org.apache.lucene.util.PriorityQueue],[boolean lessThan(Object o1, Object o2)]]
	->ITS CHILDREN:=================
	->	->NODE_212[[org.apache.lucene.search.spans.SpanOrQuery.SpanQueue, org.apache.lucene.util.PriorityQueue],[boolean lessThan(Object o1, Object o2), void SpanQueue(int size)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->	->NODE_213[[org.apache.lucene.search.PhraseQueue, org.apache.lucene.util.PriorityQueue],[boolean lessThan(Object o1, Object o2), void PhraseQueue(int size)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->	->NODE_214[[org.apache.lucene.search.spans.NearSpans.CellQueue, org.apache.lucene.util.PriorityQueue],[boolean lessThan(Object o1, Object o2), void CellQueue(int size)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->NODE_215[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery],[Query rewrite(IndexReader reader)]]
	->ITS CHILDREN:=================
	->	->NODE_150[...,...]
	->	->NODE_29[...,...]
	->NODE_216[[org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.Explanation, org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.Weight, org.apache.lucene.search.spans.SpanWeight],[float getValue()]]
	->ITS CHILDREN:=================
	->	->NODE_217[[org.apache.lucene.search.Explanation],[Explanation[] getDetails(), String getDescription(), String toHtml(), String toString(int depth), float getValue(), void Explanation(), void Explanation(float value, String description), void addDetail(Explanation detail), void setDescription(String description), void setValue(float value)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->	->NODE_158[...,...]
	->NODE_218[[org.apache.lucene.index.SegmentInfos],[SegmentInfo info(int i), long getVersion(), long readCurrentVersion(Directory directory), void read(Directory directory), void write(Directory directory)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_219[[org.apache.lucene.search.BooleanScorer.Collector, org.apache.lucene.search.HitCollector],[void Collector(int mask, BucketTable bucketTable), void collect(int doc, float score)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_220[[org.apache.lucene.document.Document, org.apache.lucene.document.Field, org.apache.lucene.search.Query],[float getBoost()]]
	->ITS CHILDREN:=================
	->	->NODE_221[[org.apache.lucene.document.Document, org.apache.lucene.document.Field],[float getBoost(), void setBoost(float boost)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_222[[org.apache.lucene.document.Document],[Enumeration fields(), Field getField(String name), Field[] getFields(String name), String get(String name), String[] getValues(String name), float getBoost(), void Document(), void add(Field field), void removeField(String name), void removeFields(String name), void setBoost(float boost)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_223[[org.apache.lucene.document.Field],[Field Keyword(String name, Date value), Field Keyword(String name, String value), Field Text(String name, Reader value), Field Text(String name, Reader value, boolean storeTermVector), Field Text(String name, String value), Field Text(String name, String value, boolean storeTermVector), Field UnIndexed(String name, String value), Field UnStored(String name, String value), Field UnStored(String name, String value, boolean storeTermVector), Reader readerValue(), String name(), String stringValue(), boolean isIndexed(), boolean isStored(), boolean isTermVectorStored(), boolean isTokenized(), float getBoost(), void Field(String name, Reader reader), void Field(String name, String string, boolean store, boolean index, boolean token), void Field(String name, String string, boolean store, boolean index, boolean token, boolean storeTermVector), void setBoost(float boost)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_14[...,...]
	->NODE_224[[org.apache.lucene.index.TermInfo],[void TermInfo(), void TermInfo(TermInfo ti), void TermInfo(int df, long fp, long pp), void set(TermInfo ti), void set(int docFreq, long freqPointer, long proxPointer, int skipOffset)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_225[[org.apache.lucene.search.HitDoc],[void HitDoc(float s, int i)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_226[[org.apache.lucene.index.SegmentReader.Norm],[void Norm(InputStream in, int number), void reWrite()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_227[[org.apache.lucene.analysis.standard.CharStream, org.apache.lucene.analysis.standard.FastCharStream, org.apache.lucene.queryParser.CharStream, org.apache.lucene.queryParser.FastCharStream, org.apache.lucene.store.InputStream],[void refill()]]
	->ITS CHILDREN:=================
	->	->NODE_47[...,...]
	->	->NODE_228[[org.apache.lucene.analysis.standard.CharStream, org.apache.lucene.analysis.standard.FastCharStream, org.apache.lucene.queryParser.CharStream, org.apache.lucene.queryParser.FastCharStream],[String GetImage(), char BeginToken(), char readChar(), char[] GetSuffix(int len), int getBeginColumn(), int getBeginLine(), int getColumn(), int getEndColumn(), int getEndLine(), int getLine(), void Done(), void FastCharStream(Reader r), void backup(int amount), void refill()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_229[[org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer, org.apache.lucene.analysis.standard.StandardFilter, org.apache.lucene.analysis.standard.StandardTokenizer, org.apache.lucene.analysis.standard.StandardTokenizerConstants],[org.apache.lucene.analysis.Token next()]]
	->ITS CHILDREN:=================
	->	->NODE_230[[org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.standard.StandardFilter, org.apache.lucene.analysis.standard.StandardTokenizerConstants],[org.apache.lucene.analysis.Token next(), void StandardFilter(TokenStream in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_137[...,...]
	->	->	->NODE_119[...,...]
	->	->NODE_136[...,...]
	->	->NODE_116[...,...]
	->NODE_231[[org.apache.lucene.index.IndexWriter, org.apache.lucene.search.Scorer, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Similarity getSimilarity()]]
	->ITS CHILDREN:=================
	->	->NODE_39[...,...]
	->	->NODE_72[...,...]
	->NODE_232[[org.apache.lucene.search.SortComparator, org.apache.lucene.search.SortComparatorSource],[Comparable getComparable(String termtext), ScoreDocComparator newComparator(IndexReader reader, String fieldname)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_233[[org.apache.lucene.index.FieldInfos, org.apache.lucene.index.FieldsReader, org.apache.lucene.index.MultipleTermPositions.IntQueue, org.apache.lucene.index.SegmentTermVector, org.apache.lucene.index.TermFreqVector, org.apache.lucene.index.TermVectorsReader, org.apache.lucene.search.BooleanScorer.BucketTable, org.apache.lucene.search.QueryTermVector, org.apache.lucene.util.BitVector, org.apache.lucene.util.PriorityQueue],[int size()]]
	->ITS CHILDREN:=================
	->	->NODE_234[[org.apache.lucene.search.BooleanScorer.BucketTable],[HitCollector newCollector(int mask), int size(), void BucketTable(BooleanScorer scorer)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->	->NODE_49[...,...]
	->	->NODE_235[[org.apache.lucene.index.SegmentTermVector, org.apache.lucene.index.TermFreqVector, org.apache.lucene.search.QueryTermVector],[String getField(), String[] getTerms(), int size(), int[] getTermFrequencies()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_236[[org.apache.lucene.index.TermFreqVector, org.apache.lucene.search.QueryTermVector],[String getField(), String[] getTerms(), int indexOf(String term), int size(), int[] getTermFrequencies(), int[] indexesOf(String[] terms, int start, int len), void QueryTermVector(String queryString, Analyzer analyzer), void QueryTermVector(String[] queryTerms), void processTerms(String[] queryTerms)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_237[[org.apache.lucene.index.TermFreqVector],[String getField(), String[] getTerms(), int indexOf(String term), int indexOf(String termText), int size(), int[] getTermFrequencies(), int[] getTermPositions(int index), int[] indexesOf(String[] termNumbers, int start, int len), int[] indexesOf(String[] terms, int start, int len), void QueryTermVector(String queryString, Analyzer analyzer), void QueryTermVector(String[] queryTerms), void SegmentTermVector(String field, String[] terms, int[] termFreqs), void processTerms(String[] queryTerms)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_238[[org.apache.lucene.index.SegmentTermVector, org.apache.lucene.index.TermFreqVector],[String getField(), String[] getTerms(), int indexOf(String termText), int size(), int[] getTermFrequencies(), int[] indexesOf(String[] termNumbers, int start, int len), void SegmentTermVector(String field, String[] terms, int[] termFreqs)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_237[...,...]
	->	->NODE_239[[org.apache.lucene.index.FieldInfos, org.apache.lucene.util.BitVector],[int size(), void write(Directory d, String name)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_240[[org.apache.lucene.util.BitVector],[boolean get(int bit), int count(), int size(), void BitVector(Directory d, String name), void BitVector(int n), void clear(int bit), void set(int bit), void write(Directory d, String name)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_241[[org.apache.lucene.index.FieldInfos],[FieldInfo fieldInfo(String fieldName), FieldInfo fieldInfo(int fieldNumber), String fieldName(int fieldNumber), boolean hasVectors(), int fieldNumber(String fieldName), int size(), void FieldInfos(), void FieldInfos(Directory d, String name), void add(Collection names, boolean isIndexed), void add(Document doc), void add(String name, boolean isIndexed), void add(String name, boolean isIndexed, boolean storeTermVector), void addIndexed(Collection names, boolean storeTermVectors), void addInternal(String name, boolean isIndexed, boolean storeTermVector), void read(InputStream input), void write(Directory d, String name), void write(OutputStream output)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_242[[org.apache.lucene.index.MultipleTermPositions.IntQueue, org.apache.lucene.util.PriorityQueue],[int size(), void clear()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_243[[org.apache.lucene.index.MultipleTermPositions.IntQueue],[int next(), int size(), void add(int i), void clear(), void growArray(), void sort()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_6[...,...]
	->NODE_244[[org.apache.lucene.search.ScoreDocComparator],[Comparable sortValue(ScoreDoc i), int compare(ScoreDoc i, ScoreDoc j), int sortType()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_245[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.ParallelMultiSearcher, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Query rewrite(Query original), int docFreq(Term term), void search(Query query, Filter filter, HitCollector results)]]
	->ITS CHILDREN:=================
	->	->NODE_53[...,...]
	->	->NODE_246[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.ParallelMultiSearcher, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Query rewrite(Query original), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), void search(Query query, Filter filter, HitCollector results)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_247[[org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.ParallelMultiSearcher, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher],[Query rewrite(Query original), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), void ParallelMultiSearcher(Searchable[] searchables), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_55[...,...]
	->	->	->NODE_54[...,...]
	->NODE_248[[org.apache.lucene.index.TermFreqVector, org.apache.lucene.index.TermPositionVector],[int[] getTermPositions(int index)]]
	->ITS CHILDREN:=================
	->	->NODE_237[...,...]
	->NODE_249[[org.apache.lucene.index.SegmentTermVector, org.apache.lucene.index.TermFreqVector, org.apache.lucene.search.Query, org.apache.lucene.search.QueryTermVector, org.apache.lucene.search.RangeQuery, org.apache.lucene.search.SortField, org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanQuery, org.apache.lucene.search.spans.SpanTermQuery],[String getField()]]
	->ITS CHILDREN:=================
	->	->NODE_235[...,...]
	->	->NODE_20[...,...]
	->	->NODE_250[[org.apache.lucene.search.SortField],[Locale getLocale(), SortComparatorSource getFactory(), String getField(), boolean getReverse(), int getType(), void SortField(String field), void SortField(String field, Locale locale), void SortField(String field, Locale locale, boolean reverse), void SortField(String field, SortComparatorSource comparator), void SortField(String field, SortComparatorSource comparator, boolean reverse), void SortField(String field, boolean reverse), void SortField(String field, int type), void SortField(String field, int type, boolean reverse)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_251[[org.apache.lucene.analysis.PorterStemmer, org.apache.lucene.queryParser.QueryParser, org.apache.lucene.queryParser.QueryParserConstants, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable],[void main(String[] args)]]
	->ITS CHILDREN:=================
	->	->NODE_42[...,...]
	->	->NODE_61[...,...]
	->	->NODE_252[[org.apache.lucene.analysis.PorterStemmer],[String stem(String s), boolean cons(int i), boolean cvc(int i), boolean doublec(int j), boolean ends(String s), boolean stem(), boolean stem(char[] word), boolean stem(char[] word, int wordLen), boolean stem(char[] wordBuffer, int offset, int wordLen), boolean stem(int i0), boolean vowelinstem(), char[] getResultBuffer(), int getResultLength(), int m(), void PorterStemmer(), void add(char ch), void main(String[] args), void r(String s), void reset(), void setto(String s), void step1(), void step2(), void step3(), void step4(), void step5(), void step6()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_253[[org.apache.lucene.search.FieldDoc, org.apache.lucene.search.ScoreDoc],[void FieldDoc(int doc, float score), void FieldDoc(int doc, float score, Comparable[] fields)]]
	->ITS CHILDREN:=================
	->	->NODE_254[[org.apache.lucene.search.ScoreDoc],[void FieldDoc(int doc, float score), void FieldDoc(int doc, float score, Comparable[] fields), void ScoreDoc(int doc, float score)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_255[[org.apache.lucene.search.DefaultSimilarity, org.apache.lucene.search.Similarity],[float coord(int overlap, int maxOverlap), float idf(int docFreq, int numDocs), float lengthNorm(String fieldName, int numTerms), float queryNorm(float sumOfSquaredWeights), float sloppyFreq(int distance), float tf(float freq)]]
	->ITS CHILDREN:=================
	->	->NODE_256[[org.apache.lucene.search.Similarity],[Similarity getDefault(), byte encodeNorm(float f), byte floatToByte(float f), float byteToFloat(byte b), float coord(int overlap, int maxOverlap), float decodeNorm(byte b), float idf(Collection terms, Searcher searcher), float idf(Term term, Searcher searcher), float idf(int docFreq, int numDocs), float lengthNorm(String fieldName, int numTerms), float lengthNorm(String fieldName, int numTokens), float queryNorm(float sumOfSquaredWeights), float sloppyFreq(int distance), float tf(float freq), float tf(int freq), void setDefault(Similarity similarity)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_257[[org.apache.lucene.queryParser.QueryParser, org.apache.lucene.queryParser.QueryParserConstants, org.apache.lucene.search.SortField],[Locale getLocale()]]
	->ITS CHILDREN:=================
	->	->NODE_250[...,...]
	->	->NODE_42[...,...]
	->NODE_258[[org.apache.lucene.index.DocumentWriter],[Posting[] sortPostingTable(), void DocumentWriter(Directory directory, Analyzer analyzer, Similarity similarity, int maxFieldLength), void addDocument(String segment, Document doc), void addPosition(String field, String text, int position), void invertDocument(Document doc), void quickSort(Posting[] postings, int lo, int hi), void writeNorms(Document doc, String segment), void writePostings(Posting[] postings, String segment)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_259[[org.apache.lucene.store.FSInputStream.Descriptor],[void Descriptor(File file, String mode)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_260[[org.apache.lucene.index.FieldInfo],[void FieldInfo(String na, boolean tk, int nu, boolean storeTermVector)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_261[[org.apache.lucene.store.Lock.With],[Object doBody(), Object run(), void With(Lock lock), void With(Lock lock, long lockWaitTimeout)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_262[[org.apache.lucene.index.Term],[String field(), String text(), int compareTo(Object other), int compareTo(Term other), void Term(String fld, String txt), void Term(String fld, String txt, boolean intern), void readObject(java.io.ObjectInputStream in), void set(String fld, String txt)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_263[[org.apache.lucene.util.Constants],[void Constants()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_264[[org.apache.lucene.search.CachingWrapperFilter, org.apache.lucene.search.DateFilter, org.apache.lucene.search.Filter, org.apache.lucene.search.QueryFilter],[BitSet bits(IndexReader reader)]]
	->ITS CHILDREN:=================
	->	->NODE_265[[org.apache.lucene.search.Filter, org.apache.lucene.search.QueryFilter],[BitSet bits(IndexReader reader), void QueryFilter(Query query)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_266[[org.apache.lucene.search.Filter],[BitSet bits(IndexReader reader), DateFilter After(String field, Date date), DateFilter After(String field, long time), DateFilter Before(String field, Date date), DateFilter Before(String field, long time), void CachingWrapperFilter(Filter filter), void DateFilter(String f), void DateFilter(String f, Date from, Date to), void DateFilter(String f, long from, long to), void QueryFilter(Query query)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_267[[org.apache.lucene.search.CachingWrapperFilter, org.apache.lucene.search.Filter],[BitSet bits(IndexReader reader), void CachingWrapperFilter(Filter filter)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_266[...,...]
	->	->NODE_268[[org.apache.lucene.search.DateFilter, org.apache.lucene.search.Filter],[BitSet bits(IndexReader reader), DateFilter After(String field, Date date), DateFilter After(String field, long time), DateFilter Before(String field, Date date), DateFilter Before(String field, long time), void DateFilter(String f), void DateFilter(String f, Date from, Date to), void DateFilter(String f, long from, long to)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_266[...,...]
	->NODE_269[[org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.PhraseQuery, org.apache.lucene.search.Query, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanQuery],[int getSlop()]]
	->ITS CHILDREN:=================
	->	->NODE_25[...,...]
	->	->NODE_152[...,...]
	->NODE_270[[org.apache.lucene.search.TopDocs, org.apache.lucene.search.TopFieldDocs],[void TopFieldDocs(int totalHits, ScoreDoc[] scoreDocs, SortField[] fields)]]
	->ITS CHILDREN:=================
	->	->NODE_271[[org.apache.lucene.search.TopDocs],[void TopDocs(int totalHits, ScoreDoc[] scoreDocs), void TopFieldDocs(int totalHits, ScoreDoc[] scoreDocs, SortField[] fields)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_272[[org.apache.lucene.util.StringHelper],[int stringDifference(String s1, String s2), void StringHelper()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_273[[org.apache.lucene.index.SegmentMerger],[IndexReader segmentReader(int i), int appendPostings(SegmentMergeInfo[] smis, int n), int merge(), int mergeFields(), long writeSkip(), void SegmentMerger(Directory dir, String name, boolean compoundFile), void add(IndexReader reader), void bufferSkip(int doc), void closeReaders(), void createCompoundFile(), void mergeNorms(), void mergeTermInfo(SegmentMergeInfo[] smis, int n), void mergeTermInfos(), void mergeTerms(), void mergeVectors(), void resetSkip()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_274[[org.apache.lucene.analysis.PorterStemmer, org.apache.lucene.store.OutputStream, org.apache.lucene.store.RAMOutputStream],[void reset()]]
	->ITS CHILDREN:=================
	->	->NODE_69[...,...]
	->	->NODE_252[...,...]
	->NODE_275[[org.apache.lucene.search.FieldCacheImpl.Entry],[void Entry(IndexReader reader, String field, Object custom), void Entry(IndexReader reader, String field, int type)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_276[[org.apache.lucene.index.MultipleTermPositions.IntQueue, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer],[void sort()]]
	->ITS CHILDREN:=================
	->	->NODE_243[...,...]
	->	->NODE_38[...,...]
Done printing lattice!
Using complex purge
Printing lattice after purging extents
NODE_0[[org.apache.lucene.analysis.Analyzer, org.apache.lucene.analysis.CharTokenizer, org.apache.lucene.analysis.LetterTokenizer, org.apache.lucene.analysis.LowerCaseFilter, org.apache.lucene.analysis.LowerCaseTokenizer, org.apache.lucene.analysis.PerFieldAnalyzerWrapper, org.apache.lucene.analysis.PorterStemFilter, org.apache.lucene.analysis.PorterStemmer, org.apache.lucene.analysis.SimpleAnalyzer, org.apache.lucene.analysis.StopAnalyzer, org.apache.lucene.analysis.StopFilter, org.apache.lucene.analysis.Token, org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer, org.apache.lucene.analysis.WhitespaceAnalyzer, org.apache.lucene.analysis.WhitespaceTokenizer, org.apache.lucene.analysis.de.GermanAnalyzer, org.apache.lucene.analysis.de.GermanStemFilter, org.apache.lucene.analysis.de.GermanStemmer, org.apache.lucene.analysis.de.WordlistLoader, org.apache.lucene.analysis.ru.RussianAnalyzer, org.apache.lucene.analysis.ru.RussianCharsets, org.apache.lucene.analysis.ru.RussianLetterTokenizer, org.apache.lucene.analysis.ru.RussianLowerCaseFilter, org.apache.lucene.analysis.ru.RussianStemFilter, org.apache.lucene.analysis.ru.RussianStemmer, org.apache.lucene.analysis.standard.CharStream, org.apache.lucene.analysis.standard.FastCharStream, org.apache.lucene.analysis.standard.ParseException, org.apache.lucene.analysis.standard.StandardAnalyzer, org.apache.lucene.analysis.standard.StandardFilter, org.apache.lucene.analysis.standard.StandardTokenizer, org.apache.lucene.analysis.standard.StandardTokenizerConstants, org.apache.lucene.analysis.standard.StandardTokenizerTokenManager, org.apache.lucene.analysis.standard.Token, org.apache.lucene.analysis.standard.TokenMgrError, org.apache.lucene.document.DateField, org.apache.lucene.document.Document, org.apache.lucene.document.Field, org.apache.lucene.index.CompoundFileReader, org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.index.CompoundFileWriter, org.apache.lucene.index.DocumentWriter, org.apache.lucene.index.FieldInfo, org.apache.lucene.index.FieldInfos, org.apache.lucene.index.FieldsReader, org.apache.lucene.index.FieldsWriter, org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.FilterIndexReader.FilterTermPositions, org.apache.lucene.index.IndexReader, org.apache.lucene.index.IndexWriter, org.apache.lucene.index.MultiReader, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.MultiTermPositions, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.MultipleTermPositions.IntQueue, org.apache.lucene.index.MultipleTermPositions.TermPositionsQueue, org.apache.lucene.index.Posting, org.apache.lucene.index.SegmentInfo, org.apache.lucene.index.SegmentInfos, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.index.SegmentMergeQueue, org.apache.lucene.index.SegmentMerger, org.apache.lucene.index.SegmentReader, org.apache.lucene.index.SegmentReader.Norm, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.SegmentTermVector, org.apache.lucene.index.Term, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermEnum, org.apache.lucene.index.TermFreqVector, org.apache.lucene.index.TermInfo, org.apache.lucene.index.TermInfosReader, org.apache.lucene.index.TermInfosWriter, org.apache.lucene.index.TermPositionVector, org.apache.lucene.index.TermPositions, org.apache.lucene.index.TermVectorsReader, org.apache.lucene.index.TermVectorsWriter, org.apache.lucene.index.TermVectorsWriter.TVField, org.apache.lucene.queryParser.CharStream, org.apache.lucene.queryParser.FastCharStream, org.apache.lucene.queryParser.MultiFieldQueryParser, org.apache.lucene.queryParser.ParseException, org.apache.lucene.queryParser.QueryParser, org.apache.lucene.queryParser.QueryParserConstants, org.apache.lucene.queryParser.QueryParserTokenManager, org.apache.lucene.queryParser.Token, org.apache.lucene.queryParser.TokenMgrError, org.apache.lucene.search.BooleanClause, org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.BooleanScorer.BucketTable, org.apache.lucene.search.BooleanScorer.Collector, org.apache.lucene.search.BooleanScorer.SubScorer, org.apache.lucene.search.CachingWrapperFilter, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.DateFilter, org.apache.lucene.search.DefaultSimilarity, org.apache.lucene.search.ExactPhraseScorer, org.apache.lucene.search.Explanation, org.apache.lucene.search.FieldCache, org.apache.lucene.search.FieldCache.StringIndex, org.apache.lucene.search.FieldCacheImpl, org.apache.lucene.search.FieldCacheImpl.Entry, org.apache.lucene.search.FieldDoc, org.apache.lucene.search.FieldDocSortedHitQueue, org.apache.lucene.search.FieldSortedHitQueue, org.apache.lucene.search.Filter, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.FuzzyQuery, org.apache.lucene.search.FuzzyTermEnum, org.apache.lucene.search.HitCollector, org.apache.lucene.search.HitDoc, org.apache.lucene.search.HitQueue, org.apache.lucene.search.Hits, org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.MultiSearcherThread, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.ParallelMultiSearcher, org.apache.lucene.search.PhrasePositions, org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.PhraseQueue, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.QueryFilter, org.apache.lucene.search.QueryTermVector, org.apache.lucene.search.RangeQuery, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.ScoreDoc, org.apache.lucene.search.ScoreDocComparator, org.apache.lucene.search.Scorer, org.apache.lucene.search.Searchable, org.apache.lucene.search.Searcher, org.apache.lucene.search.Similarity, org.apache.lucene.search.SloppyPhraseScorer, org.apache.lucene.search.Sort, org.apache.lucene.search.SortComparator, org.apache.lucene.search.SortComparatorSource, org.apache.lucene.search.SortField, org.apache.lucene.search.TermQuery, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.TermScorer, org.apache.lucene.search.TopDocs, org.apache.lucene.search.TopFieldDocs, org.apache.lucene.search.Weight, org.apache.lucene.search.WildcardQuery, org.apache.lucene.search.WildcardTermEnum, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.CellQueue, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanOrQuery.SpanQueue, org.apache.lucene.search.spans.SpanQuery, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.SpanTermQuery, org.apache.lucene.search.spans.SpanWeight, org.apache.lucene.search.spans.Spans, org.apache.lucene.store.Directory, org.apache.lucene.store.FSDirectory, org.apache.lucene.store.FSInputStream, org.apache.lucene.store.FSInputStream.Descriptor, org.apache.lucene.store.FSOutputStream, org.apache.lucene.store.InputStream, org.apache.lucene.store.Lock, org.apache.lucene.store.Lock.With, org.apache.lucene.store.OutputStream, org.apache.lucene.store.RAMDirectory, org.apache.lucene.store.RAMInputStream, org.apache.lucene.store.RAMOutputStream, org.apache.lucene.util.BitVector, org.apache.lucene.util.Constants, org.apache.lucene.util.PriorityQueue, org.apache.lucene.util.StringHelper],[]]
ITS CHILDREN:=================
	->NODE_1[[org.apache.lucene.analysis.de.GermanStemmer],[String stem(String term), boolean isStemmable(String term), void optimize(StringBuffer buffer), void removeParticleDenotion(StringBuffer buffer), void resubstitute(StringBuffer buffer), void strip(StringBuffer buffer), void substitute(StringBuffer buffer)]]
	->ITS CHILDREN:=================
	->	->NODE_2[[],[Analyzer getAnalyzer(), BitSet bits(IndexReader reader), BooleanClause[] getClauses(), Collator[] hasCollators(SortField[] fields), Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Collection getTerms(), Comparable getComparable(String termtext), Comparable sortValue(ScoreDoc i), Comparable[] getCustom(IndexReader reader, String field, SortComparator comparator), Date stringToDate(String s), DateFilter After(String field, Date date), DateFilter After(String field, long time), DateFilter Before(String field, Date date), DateFilter Before(String field, long time), Directory directory(), Directory getDirectory(), Document doc(int i), Document doc(int n), Document document(int n), Enumeration fields(), Explanation explain(IndexReader reader, int doc), Explanation explain(Query query, int doc), Explanation explain(int doc), Explanation[] getDetails(), FSDirectory getDirectory(File file, boolean create), FSDirectory getDirectory(String path, boolean create), Field Keyword(String name, Date value), Field Keyword(String name, String value), Field Text(String name, Reader value), Field Text(String name, Reader value, boolean storeTermVector), Field Text(String name, String value), Field Text(String name, String value, boolean storeTermVector), Field UnIndexed(String name, String value), Field UnStored(String name, String value), Field UnStored(String name, String value, boolean storeTermVector), Field getField(String name), FieldDoc fillFields(FieldDoc doc), FieldInfo fieldInfo(String fieldName), FieldInfo fieldInfo(int fieldNumber), Field[] getFields(String name), File getFile(), FilteredTermEnum getEnum(IndexReader reader), HashSet getWordSet(File wordfile), Hashtable getWordtable(File wordfile), Hashtable getWordtable(String path, String wordfile), Hashtable getWordtable(String wordfile), Hashtable makeStopTable(String[] stopWords), Hashtable makeWordTable(HashSet wordSet), HitCollector newCollector(int mask), HitDoc hitDoc(int n), Hits search(Query query), Hits search(Query query, Filter filter), Hits search(Query query, Filter filter, Sort sort), Hits search(Query query, Sort sort), IOException getIOException(), IndexReader open(Directory directory), IndexReader open(Directory directory, boolean closeDirectory), IndexReader open(File path), IndexReader open(String path), IndexReader segmentReader(int i), InputStream openFile(String id), InputStream openFile(String name), Locale getLocale(), Lock makeLock(String name), Object doBody(), Object getAuto(IndexReader reader, String field), Object lookup(IndexReader reader, String field, Object comparer), Object lookup(IndexReader reader, String field, int type), Object pop(), Object run(), Object store(IndexReader reader, String field, Object comparer, Object value), Object store(IndexReader reader, String field, int type, Object factory, Object value), Object store(IndexReader reader, String field, int type, Object value), Object top(), OutputStream createFile(String name), ParseException generateParseException(), Posting[] sortPostingTable(), Query Clause(String field), Query Query(String field), Query Term(String field), Query combine(Query[] queries), Query getBooleanQuery(Vector clauses), Query getFieldQuery(String field, Analyzer analyzer, String queryText), Query getFieldQuery(String field, Analyzer analyzer, String queryText, int slop), Query getFuzzyQuery(String field, String termStr), Query getPrefixQuery(String field, String termStr), Query getQuery(), Query getRangeQuery(String field, Analyzer analyzer, String part1, String part2, boolean inclusive), Query getWildcardQuery(String field, String termStr), Query mergeBooleanQueries(Query[] queries), Query parse(String query), Query parse(String query, String field, Analyzer analyzer), Query parse(String query, String[] fields, Analyzer analyzer), Query parse(String query, String[] fields, int[] flags, Analyzer analyzer), Query rewrite(IndexReader reader), Query rewrite(Query original), Query rewrite(Query query), Reader readerValue(), ScoreDocComparator comparatorAuto(IndexReader reader, String fieldname), ScoreDocComparator comparatorFloat(IndexReader reader, String fieldname), ScoreDocComparator comparatorInt(IndexReader reader, String fieldname), ScoreDocComparator comparatorString(IndexReader reader, String fieldname), ScoreDocComparator comparatorStringLocale(IndexReader reader, String fieldname, Locale locale), ScoreDocComparator getCachedComparator(IndexReader reader, String fieldname, int type, Locale locale, SortComparatorSource factory), ScoreDocComparator lookup(IndexReader reader, String field, int type, Object factory), ScoreDocComparator newComparator(IndexReader reader, String fieldname), Scorer first(), Scorer last(), Scorer scorer(IndexReader reader), SegmentInfo info(int i), SegmentTermEnum getEnum(), SegmentTermEnum terms(), SegmentTermEnum terms(Term term), SegmentTermVector readTermVector(String field, long tvfPointer), SegmentTermVector[] readTermVectors(String[] fields, long[] tvfPointers), Set makeStopSet(String[] stopWords), Similarity getDefault(), Similarity getSimilarity(), Similarity getSimilarity(Searcher searcher), SortComparatorSource getFactory(), SortField[] getFields(), SpanQuery getExclude(), SpanQuery getInclude(), SpanQuery getMatch(), SpanQuery[] getClauses(), Spans getSpans(IndexReader reader), SpansCell min(), String GetImage(), String LexicalError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar), String MAX_DATE_STRING(), String MIN_DATE_STRING(), String addEscapes(String str), String add_escapes(String str), String dateToString(Date date), String discardEscapeChar(String input), String field(), String fieldName(int fieldNumber), String get(String name), String getDescription(), String getField(), String getName(), String name(), String newSegmentName(), String readString(), String stem(String input), String stem(String s), String stem(String term), String stem(String theWord, char[] charset), String stringValue(), String termText(), String text(), String timeToString(long time), String toHtml(), String toString(String f), String toString(String field), String toString(String s), String toString(int depth), String type(), StringBuffer getLockPrefix(), StringIndex getStringIndex(IndexReader reader, String field), String[] getStrings(IndexReader reader, String field), String[] getTerms(), String[] getValues(String name), String[] list(), String[] makeStopWords(char[] charset), Term get(int position), Term getLowerTerm(), Term getPrefix(), Term getTerm(), Term getUpperTerm(), Term readTerm(), Term scanEnum(int position), Term term(), TermDocs termDocs(), TermDocs termDocs(IndexReader reader), TermDocs termDocs(Term term), TermDocs termDocs(int i), TermEnum terms(), TermEnum terms(Term t), TermEnum terms(Term term), TermFreqVector get(int docNum, String field), TermFreqVector getTermFreqVector(int docNumber, String field), TermFreqVector getTermFreqVector(int n, String field), TermFreqVector[] get(int docNum), TermFreqVector[] getTermFreqVectors(int docNumber), TermFreqVector[] getTermFreqVectors(int n), TermInfo get(Term term), TermInfo scanEnum(Term term), TermInfo termInfo(), TermPositions peek(), TermPositions termPositions(), TermPositions termPositions(Term term), Term[] getTerms(), Token getNextToken(), Token getToken(int index), Token jjFillToken(), Token jj_consume_token(int kind), Token newToken(int ofKind), Token next(), TokenStream tokenStream(Reader reader), TokenStream tokenStream(String fieldName, Reader reader), TopDocs search(Query query, Filter filter, int n), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), Vector files(), Vector readDeleteableFiles(), Weight createWeight(Searcher searcher), Weight weight(Searcher searcher), boolean adjectival(StringBuffer stemmingZone), boolean atMatch(), boolean checkSlop(), boolean cons(int i), boolean cvc(int i), boolean derivational(StringBuffer stemmingZone), boolean doNext(), boolean doublec(int j), boolean endEnum(), boolean ends(String s), boolean fileExists(String name), boolean findAndRemoveEnding(StringBuffer stemmingZone, char[][] theEndingClass), boolean findAndRemoveEnding(StringBuffer stemmingZone, char[][] theEndingClass, char[][] thePredessors), boolean firstNonOrderedNextToPartialList(), boolean get(int bit), boolean getLowercaseWildcardTerms(), boolean getReverse(), boolean getUseCompoundFile(), boolean hasDeletions(), boolean hasDeletions(SegmentInfo si), boolean hasSeparateNorms(SegmentInfo si), boolean hasVectors(), boolean indexExists(Directory directory), boolean indexExists(File directory), boolean indexExists(String directory), boolean insert(Object element), boolean isDeleted(int n), boolean isDocumentOpen(), boolean isFDValid(), boolean isFieldOpen(), boolean isInOrder(), boolean isInclusive(), boolean isIndexed(), boolean isLocked(), boolean isLocked(Directory directory), boolean isLocked(String directory), boolean isStemmable(String term), boolean isStored(), boolean isTermVectorStored(), boolean isTokenChar(char c), boolean isTokenized(), boolean isVowel(char letter), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), boolean jjCanMove_1(int hiByte, int i1, int i2, long l1, long l2), boolean jjCanMove_2(int hiByte, int i1, int i2, long l1, long l2), boolean jj_2_1(int xla), boolean jj_3_1(), boolean jj_scan_token(int kind), boolean lessThan(Object a, Object b), boolean lessThan(Object o1, Object o2), boolean matchIsOrdered(), boolean next(), boolean nextPosition(), boolean noun(StringBuffer stemmingZone), boolean obtain(), boolean obtain(long lockWaitTimeout), boolean perfectiveGerund(StringBuffer stemmingZone), boolean reflexive(StringBuffer stemmingZone), boolean removeI(StringBuffer stemmingZone), boolean removeSoft(StringBuffer stemmingZone), boolean skipTo(Term target), boolean skipTo(int i), boolean skipTo(int target), boolean stem(), boolean stem(char[] word), boolean stem(char[] word, int wordLen), boolean stem(char[] wordBuffer, int offset, int wordLen), boolean stem(int i0), boolean superlative(StringBuffer stemmingZone), boolean termCompare(Term term), boolean undoubleN(StringBuffer stemmingZone), boolean usesCompoundFile(SegmentInfo si), boolean verb(StringBuffer stemmingZone), boolean vowelinstem(), boolean wildcardEquals(String pattern, int patternIdx, String string, int stringIdx), byte encodeNorm(float f), byte floatToByte(float f), byte readByte(), byte[] norms(String f), byte[] norms(String field), char BeginToken(), char normalize(char c), char readChar(), char toLowerCase(char letter, char[] charset), char[] GetSuffix(int len), char[] getResultBuffer(), float byteToFloat(byte b), float coord(int overlap, int maxOverlap), float decodeNorm(byte b), float difference(), float getBoost(), float getValue(), float idf(Collection terms, Searcher searcher), float idf(Term term, Searcher searcher), float idf(int docFreq, int numDocs), float lengthNorm(String fieldName, int numTerms), float lengthNorm(String fieldName, int numTokens), float phraseFreq(), float queryNorm(float sumOfSquaredWeights), float score(), float score(int n), float sloppyFreq(int distance), float sumOfSquaredWeights(), float tf(float freq), float tf(int freq), float[] getFloats(IndexReader reader, String field), int Conjunction(), int Modifiers(), int appendPostings(SegmentMergeInfo[] smis, int n), int compare(ScoreDoc i, ScoreDoc j), int compareTo(Object other), int compareTo(Term other), int count(), int delete(Term term), int doc(), int docCount(), int docFreq(), int docFreq(Term t), int docFreq(Term term), int editDistance(String s, String t, int n, int m), int end(), int endOffset(), int fieldNumber(String fieldName), int findEnding(StringBuffer stemmingZone, char[][] theEndingClass), int findEnding(StringBuffer stemmingZone, int startIndex, char[][] theEndingClass), int freq(), int getBeginColumn(), int getBeginLine(), int getColumn(), int getEnd(), int getEndColumn(), int getEndLine(), int getIndexOffset(Term term), int getLine(), int getMaxClauseCount(), int getOperator(), int getPhraseSlop(), int getPositionIncrement(), int getResultLength(), int getSegmentsCounter(), int getSkipInterval(), int getSlop(), int getType(), int hits(), int id(int n), int indexOf(String term), int indexOf(String termText), int jjMoveNfa_0(int startState, int curPos), int jjMoveNfa_1(int startState, int curPos), int jjMoveNfa_2(int startState, int curPos), int jjMoveNfa_3(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), int jjMoveStringLiteralDfa0_1(), int jjMoveStringLiteralDfa0_2(), int jjMoveStringLiteralDfa0_3(), int jjMoveStringLiteralDfa1_1(long active0), int jjMoveStringLiteralDfa1_2(long active0), int jjStartNfaWithStates_1(int pos, int kind, int state), int jjStartNfaWithStates_2(int pos, int kind, int state), int jjStartNfaWithStates_3(int pos, int kind, int state), int jjStartNfa_1(int pos, long active0), int jjStartNfa_2(int pos, long active0), int jjStartNfa_3(int pos, long active0), int jjStopAtPos(int pos, int kind), int jjStopStringLiteralDfa_1(int pos, long active0), int jjStopStringLiteralDfa_2(int pos, long active0), int jjStopStringLiteralDfa_3(int pos, long active0), int jj_ntk(), int length(), int m(), int maxDoc(), int merge(), int mergeFields(), int min(int a, int b, int c), int next(), int nextPosition(), int numDocs(), int read(int[] arg0, int[] arg1), int read(int[] docs, int[] freqs), int readInt(), int readVInt(), int readerIndex(int n), int searcherIndex(int n), int size(), int sortType(), int start(), int startOffset(), int stringDifference(String s1, String s2), int subDoc(int n), int subSearcher(int n), int[] getInts(IndexReader reader, String field), int[] getStarts(), int[] getTermFrequencies(), int[] getTermPositions(int index), int[] indexesOf(String[] termNumbers, int start, int len), int[] indexesOf(String[] terms, int start, int len), long fileLength(String name), long fileModified(File directory, String name), long fileModified(String name), long freqPointer(), long getCurrentVersion(Directory directory), long getCurrentVersion(File directory), long getCurrentVersion(String directory), long getFilePointer(), long getPosition(Term term), long getVersion(), long lastModified(Directory directory), long lastModified(File directory), long lastModified(String directory), long length(), long proxPointer(), long readCurrentVersion(Directory directory), long readLong(), long readVLong(), long size(), long stringToTime(String s), long writeSkip(), org.apache.lucene.analysis.Token next(), void BitVector(Directory d, String name), void BitVector(int n), void BooleanClause(Query q, boolean r, boolean p), void BooleanQuery(), void BooleanScorer(Similarity similarity), void BooleanWeight(Searcher searcher), void BucketTable(BooleanScorer scorer), void CSInputStream(InputStream base, long fileOffset, long length), void CachingWrapperFilter(Filter filter), void CellQueue(int size), void CharTokenizer(Reader input), void Collector(int mask, BucketTable bucketTable), void CompoundFileReader(Directory dir, String name), void CompoundFileWriter(Directory dir, String name), void ConjunctionScorer(Similarity similarity), void Constants(), void DateField(), void DateFilter(String f), void DateFilter(String f, Date from, Date to), void DateFilter(String f, long from, long to), void Descriptor(File file, String mode), void Document(), void DocumentWriter(Directory directory, Analyzer analyzer, Similarity similarity, int maxFieldLength), void Done(), void Entry(IndexReader reader, String field, Object custom), void Entry(IndexReader reader, String field, int type), void ExactPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void Explanation(), void Explanation(float value, String description), void FSDirectory(File path, boolean create), void FSInputStream(File path), void FSOutputStream(File path), void FastCharStream(Reader r), void Field(String name, Reader reader), void Field(String name, String string, boolean store, boolean index, boolean token), void Field(String name, String string, boolean store, boolean index, boolean token, boolean storeTermVector), void FieldDoc(int doc, float score), void FieldDoc(int doc, float score, Comparable[] fields), void FieldDocSortedHitQueue(SortField[] fields, int size), void FieldInfo(String na, boolean tk, int nu, boolean storeTermVector), void FieldInfos(), void FieldInfos(Directory d, String name), void FieldSortedHitQueue(IndexReader reader, SortField[] fields, int size), void FieldsReader(Directory d, String segment, FieldInfos fn), void FieldsWriter(Directory d, String segment, FieldInfos fn), void FilterIndexReader(IndexReader in), void FilterTermDocs(TermDocs in), void FilterTermEnum(TermEnum in), void FilterTermPositions(TermPositions in), void FilteredQuery(Query query, Filter filter), void FilteredTermEnum(), void FuzzyQuery(Term term), void FuzzyTermEnum(IndexReader reader, Term term), void GermanAnalyzer(), void GermanAnalyzer(File stopwords), void GermanAnalyzer(Hashtable stopwords), void GermanAnalyzer(String[] stopwords), void GermanStemFilter(TokenStream in), void GermanStemFilter(TokenStream in, Hashtable exclusiontable), void GermanStemFilter(TokenStream in, Set exclusionSet), void HitDoc(float s, int i), void HitQueue(int size), void Hits(Searcher s, Query q, Filter f), void Hits(Searcher s, Query q, Filter f, Sort o), void IndexReader(Directory directory), void IndexReader(Directory directory, SegmentInfos segmentInfos, boolean closeDirectory), void IndexSearcher(Directory directory), void IndexSearcher(IndexReader r), void IndexSearcher(IndexReader r, boolean closeReader), void IndexSearcher(String path), void IndexWriter(Directory d, Analyzer a, boolean create), void IndexWriter(Directory d, Analyzer a, boolean create, boolean closeDir), void IndexWriter(File path, Analyzer a, boolean create), void IndexWriter(String path, Analyzer a, boolean create), void LetterTokenizer(Reader in), void LowerCaseFilter(TokenStream in), void LowerCaseTokenizer(Reader in), void MultiFieldQueryParser(CharStream stream), void MultiFieldQueryParser(QueryParserTokenManager tm), void MultiFieldQueryParser(String f, Analyzer a), void MultiReader(Directory directory, SegmentInfos sis, boolean closeDirectory, IndexReader[] subReaders), void MultiReader(IndexReader[] subReaders), void MultiSearcher(Searchable[] searchables), void MultiSearcherThread(Searchable searchable, Query query, Filter filter, int nDocs, FieldDocSortedHitQueue hq, Sort sort, int i, int[] starts, String name), void MultiSearcherThread(Searchable searchable, Query query, Filter filter, int nDocs, HitQueue hq, int i, int[] starts, String name), void MultiTermDocs(IndexReader[] r, int[] s), void MultiTermEnum(IndexReader[] readers, int[] starts, Term t), void MultiTermPositions(IndexReader[] r, int[] s), void MultiTermQuery(Term term), void MultipleTermPositions(IndexReader indexReader, Term[] terms), void NearSpans(SpanNearQuery query, IndexReader reader), void Norm(InputStream in, int number), void ParallelMultiSearcher(Searchable[] searchables), void ParseException(), void ParseException(String message), void ParseException(Token currentTokenVal, int[][] expectedTokenSequencesVal, String[] tokenImageVal), void PerFieldAnalyzerWrapper(Analyzer defaultAnalyzer), void PhrasePositions(TermPositions t, int o), void PhrasePrefixWeight(Searcher searcher), void PhraseQuery(), void PhraseQueue(int size), void PhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void PhraseWeight(Searcher searcher), void PorterStemFilter(TokenStream in), void PorterStemmer(), void Posting(Term t, int position), void PrefixQuery(Term prefix), void QueryFilter(Query query), void QueryParser(CharStream stream), void QueryParser(QueryParserTokenManager tm), void QueryParser(String f, Analyzer a), void QueryParserTokenManager(CharStream stream), void QueryParserTokenManager(CharStream stream, int lexState), void QueryTermVector(String queryString, Analyzer analyzer), void QueryTermVector(String[] queryTerms), void RAMDirectory(), void RAMDirectory(Directory dir), void RAMDirectory(Directory dir, boolean closeDir), void RAMDirectory(File dir), void RAMDirectory(String dir), void RAMInputStream(RAMFile f), void RAMOutputStream(), void RAMOutputStream(RAMFile f), void RangeQuery(Term lowerTerm, Term upperTerm, boolean inclusive), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInit(QueryParserTokenManager tm), void ReInit(StandardTokenizerTokenManager tm), void ReInitRounds(), void RemoteSearchable(Searchable local), void RussianAnalyzer(), void RussianAnalyzer(char[] charset), void RussianAnalyzer(char[] charset, Hashtable stopwords), void RussianAnalyzer(char[] charset, String[] stopwords), void RussianLetterTokenizer(Reader in, char[] charset), void RussianLowerCaseFilter(TokenStream in, char[] charset), void RussianStemFilter(TokenStream in, char[] charset), void RussianStemmer(), void RussianStemmer(char[] charset), void ScoreDoc(int doc, float score), void Scorer(Similarity similarity), void SegmentInfo(String name, int docCount, Directory dir), void SegmentMergeInfo(int b, TermEnum te, IndexReader r), void SegmentMergeQueue(int size), void SegmentMerger(Directory dir, String name, boolean compoundFile), void SegmentReader(SegmentInfo si), void SegmentReader(SegmentInfos sis, SegmentInfo si, boolean closeDir), void SegmentTermDocs(SegmentReader parent), void SegmentTermEnum(InputStream i, FieldInfos fis, boolean isi), void SegmentTermPositions(SegmentReader p), void SegmentTermVector(String field, String[] terms, int[] termFreqs), void SloppyPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, int slop, byte[] norms), void Sort(), void Sort(SortField field), void Sort(SortField[] fields), void Sort(String field), void Sort(String field, boolean reverse), void Sort(String[] fields), void SortField(String field), void SortField(String field, Locale locale), void SortField(String field, Locale locale, boolean reverse), void SortField(String field, SortComparatorSource comparator), void SortField(String field, SortComparatorSource comparator, boolean reverse), void SortField(String field, boolean reverse), void SortField(String field, int type), void SortField(String field, int type, boolean reverse), void SpanFirstQuery(SpanQuery match, int end), void SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder), void SpanNotQuery(SpanQuery include, SpanQuery exclude), void SpanOrQuery(SpanQuery[] clauses), void SpanQueue(int size), void SpanScorer(Spans spans, Weight weight, Similarity similarity, byte[] norms), void SpanTermQuery(Term term), void SpanWeight(SpanQuery query, Searcher searcher), void SpansCell(Spans spans, int index), void StandardAnalyzer(), void StandardAnalyzer(String[] stopWords), void StandardFilter(TokenStream in), void StandardTokenizer(CharStream stream), void StandardTokenizer(Reader reader), void StandardTokenizer(StandardTokenizerTokenManager tm), void StandardTokenizerTokenManager(CharStream stream), void StandardTokenizerTokenManager(CharStream stream, int lexState), void StopAnalyzer(), void StopAnalyzer(String[] stopWords), void StopFilter(TokenStream in, Hashtable stopTable), void StopFilter(TokenStream in, Set stopWords), void StopFilter(TokenStream in, String[] stopWords), void StringHelper(), void StringIndex(int[] values, String[] lookup), void SubScorer(Scorer scorer, boolean required, boolean prohibited, HitCollector collector, SubScorer next), void SwitchTo(int lexState), void TVField(int number), void Term(String fld, String txt), void Term(String fld, String txt, boolean intern), void TermInfo(), void TermInfo(TermInfo ti), void TermInfo(int df, long fp, long pp), void TermInfosReader(Directory dir, String seg, FieldInfos fis), void TermInfosWriter(Directory directory, String segment, FieldInfos fis), void TermInfosWriter(Directory directory, String segment, FieldInfos fis, boolean isIndex), void TermPositionsQueue(List termPositions), void TermQuery(Term t), void TermScorer(Weight weight, TermDocs td, Similarity similarity, byte[] norms), void TermVectorsReader(Directory d, String segment, FieldInfos fieldInfos), void TermVectorsWriter(Directory directory, String segment, FieldInfos fieldInfos), void TermWeight(Searcher searcher), void Token(String text, int start, int end), void Token(String text, int start, int end, String typ), void TokenFilter(), void TokenFilter(TokenStream input), void TokenMgrError(), void TokenMgrError(String message, int reason), void TokenMgrError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar, int reason), void Tokenizer(), void Tokenizer(Reader input), void TopDocs(int totalHits, ScoreDoc[] scoreDocs), void TopFieldDocs(int totalHits, ScoreDoc[] scoreDocs, SortField[] fields), void WhitespaceTokenizer(Reader in), void WildcardQuery(Term term), void WildcardTermEnum(IndexReader reader, Term term), void With(Lock lock), void With(Lock lock, long lockWaitTimeout), void add(BooleanClause clause), void add(Collection names, boolean isIndexed), void add(Document doc), void add(Field field), void add(IndexReader reader), void add(Query query, boolean required, boolean prohibited), void add(Scorer scorer), void add(Scorer scorer, boolean required, boolean prohibited), void add(String name, boolean isIndexed), void add(String name, boolean isIndexed, boolean storeTermVector), void add(Term term), void add(Term term, TermInfo ti), void add(Term[] terms), void add(char ch), void add(int i), void addAnalyzer(String fieldName, Analyzer analyzer), void addClause(Vector clauses, int conj, int mods, Query q), void addDetail(Explanation detail), void addDocument(Document doc), void addDocument(Document doc, Analyzer analyzer), void addDocument(String segment, Document doc), void addFile(String file), void addIndexed(Collection names, boolean storeTermVectors), void addIndexes(Directory[] dirs), void addIndexes(IndexReader[] readers), void addInternal(String name, boolean isIndexed, boolean storeTermVector), void addPosition(String field, String text, int position), void addTerm(String termText, int freq), void addTermFreqVector(TermFreqVector vector), void addTermFreqVectorInternal(TermFreqVector vector), void addTermInternal(String termText, int freq), void addToFront(HitDoc hitDoc), void addToList(SpansCell cell), void addVectors(TermFreqVector[] vectors), void adjustTop(), void aquireWriteLock(), void backup(int amount), void bufferSkip(int doc), void checkValidFormat(InputStream in), void clear(), void clear(int bit), void close(), void closeDocument(), void closeField(), void closeNorms(), void closeReaders(), void collect(int doc, float score), void commit(), void computeCoordFactors(), void copyFile(FileEntry source, OutputStream os, byte[] buffer), void create(), void createCompoundFile(), void delete(int docNum), void deleteFile(String name), void deleteFiles(Vector files, Directory directory), void deleteFiles(Vector files, Vector deletable), void deleteSegments(Vector segments), void disable_tracing(), void doClose(), void doCommit(), void doDelete(int docNum), void doDelete(int n), void doSetNorm(int d, String f, byte b), void doSetNorm(int doc, String field, byte value), void doSetNorm(int n, String field, byte value), void doUndeleteAll(), void downHeap(), void enable_tracing(), void firstPosition(), void firstToLast(), void flush(), void flushBuffer(byte[] b, int len), void flushBuffer(byte[] b, int size), void flushBuffer(byte[] src, int len), void flushRamSegments(), void getMoreDocs(int min), void growArray(), void growBuffer(int length), void init(), void initList(boolean next), void initialize(Directory directory, String segment, FieldInfos fis, boolean isi), void initialize(IndexReader[] subReaders), void initialize(SegmentInfo si), void initialize(int maxSize), void invertDocument(Document doc), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void jj_add_error_token(int kind, int pos), void jj_la1_0(), void jj_la1_1(), void jj_rescan_token(), void jj_save(int index, int xla), void listToQueue(), void main(String[] args), void markPositions(String word), void maybeMergeSegments(), void mergeNorms(), void mergeSegments(int minSegment), void mergeTermInfo(SegmentMergeInfo[] smis, int n), void mergeTermInfos(), void mergeTerms(), void mergeVectors(), void normalize(float norm), void normalize(float queryNorm), void norms(String f, byte[] bytes, int offset), void norms(String field, byte[] bytes, int offset), void norms(String field, byte[] result, int offset), void openDocument(), void openField(String field), void openNorms(Directory cfsDir), void optimize(), void optimize(StringBuffer buffer), void partialListToQueue(), void pqToList(), void processTerms(String[] queryTerms), void put(Object element), void queueToList(), void quickSort(Posting[] postings, int lo, int hi), void r(String s), void reWrite(), void read(Directory directory), void read(InputStream input), void readBytes(byte[] b, int offset, int len), void readChars(char[] buffer, int start, int length), void readIndex(), void readInternal(byte[] b, int offset, int len), void readInternal(byte[] b, int offset, int length), void readInternal(byte[] dest, int destOffset, int len), void readObject(java.io.ObjectInputStream in), void refill(), void release(), void remove(HitDoc hitDoc), void removeField(String name), void removeFields(String name), void removeParticleDenotion(StringBuffer buffer), void renameFile(String from, String to), void reset(), void resetSkip(), void resubstitute(StringBuffer buffer), void score(HitCollector hc), void search(Query query, Filter filter, HitCollector results), void search(Query query, HitCollector results), void seek(Term arg0), void seek(Term term), void seek(TermEnum termEnum), void seek(TermInfo ti), void seek(long pointer, int p, Term t, TermInfo ti), void seek(long pos), void seekEnum(int indexOffset), void seekInternal(long pos), void seekInternal(long position), void set(String fld, String txt), void set(TermInfo ti), void set(int bit), void set(int docFreq, long freqPointer, long proxPointer, int skipOffset), void setBoost(float b), void setBoost(float boost), void setCharset(char[] newCharset), void setDebugStream(java.io.PrintStream ds), void setDefault(Similarity similarity), void setDescription(String description), void setEndings(), void setEnum(TermEnum actualEnum), void setExclusionSet(Set exclusionSet), void setExclusionTable(Hashtable exclusiontable), void setFields(SortField[] fields), void setLocale(Locale locale), void setLowercaseWildcardTerms(boolean lowercaseWildcardTerms), void setMaxClauseCount(int maxClauseCount), void setNorm(int doc, String field, byte value), void setNorm(int doc, String field, float value), void setOperator(int operator), void setPhraseSlop(int phraseSlop), void setPositionIncrement(int positionIncrement), void setSimilarity(Similarity similarity), void setSlop(int s), void setSort(SortField field), void setSort(SortField[] fields), void setSort(String field), void setSort(String field, boolean reverse), void setSort(String[] fieldnames), void setStemExclusionTable(File exclusionlist), void setStemExclusionTable(Hashtable exclusionlist), void setStemExclusionTable(String[] exclusionlist), void setStemmer(GermanStemmer stemmer), void setStemmer(RussianStemmer stemmer), void setUseCompoundFile(boolean value), void setValue(float value), void setto(String s), void skipProx(long proxPointer), void skippingDoc(), void sort(), void sortScorers(), void step1(), void step2(), void step3(), void step4(), void step5(), void step6(), void strip(StringBuffer buffer), void substitute(StringBuffer buffer), void termInfo(TermInfo ti), void touchFile(String name), void undeleteAll(), void unlock(Directory directory), void upHeap(), void write(Directory d, String name), void write(Directory directory), void write(OutputStream output), void writeByte(byte b), void writeBytes(byte[] b, int length), void writeChars(String s, int start, int length), void writeDeleteableFiles(Vector files), void writeDoc(), void writeField(), void writeInt(int i), void writeLong(long i), void writeNorms(Document doc, String segment), void writePostings(Posting[] postings, String segment), void writeString(String s), void writeTerm(Term term), void writeTo(OutputStream out), void writeVInt(int i), void writeVLong(long i)]]
	->NODE_3[[org.apache.lucene.index.MultipleTermPositions.TermPositionsQueue, org.apache.lucene.index.SegmentMergeQueue, org.apache.lucene.search.FieldDocSortedHitQueue, org.apache.lucene.search.FieldSortedHitQueue, org.apache.lucene.search.HitQueue, org.apache.lucene.util.PriorityQueue],[boolean lessThan(Object a, Object b)]]
	->ITS CHILDREN:=================
	->	->NODE_4[[org.apache.lucene.search.FieldDocSortedHitQueue, org.apache.lucene.search.FieldSortedHitQueue],[SortField[] getFields(), boolean lessThan(Object a, Object b)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_5[[org.apache.lucene.search.FieldSortedHitQueue],[FieldDoc fillFields(FieldDoc doc), Object store(IndexReader reader, String field, int type, Object factory, Object value), ScoreDocComparator comparatorAuto(IndexReader reader, String fieldname), ScoreDocComparator comparatorFloat(IndexReader reader, String fieldname), ScoreDocComparator comparatorInt(IndexReader reader, String fieldname), ScoreDocComparator comparatorString(IndexReader reader, String fieldname), ScoreDocComparator comparatorStringLocale(IndexReader reader, String fieldname, Locale locale), ScoreDocComparator getCachedComparator(IndexReader reader, String fieldname, int type, Locale locale, SortComparatorSource factory), ScoreDocComparator lookup(IndexReader reader, String field, int type, Object factory), SortField[] getFields(), boolean lessThan(Object a, Object b), void FieldSortedHitQueue(IndexReader reader, SortField[] fields, int size)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_6[[org.apache.lucene.util.PriorityQueue],[Collator[] hasCollators(SortField[] fields), FieldDoc fillFields(FieldDoc doc), Object pop(), Object store(IndexReader reader, String field, int type, Object factory, Object value), Object top(), ScoreDocComparator comparatorAuto(IndexReader reader, String fieldname), ScoreDocComparator comparatorFloat(IndexReader reader, String fieldname), ScoreDocComparator comparatorInt(IndexReader reader, String fieldname), ScoreDocComparator comparatorString(IndexReader reader, String fieldname), ScoreDocComparator comparatorStringLocale(IndexReader reader, String fieldname, Locale locale), ScoreDocComparator getCachedComparator(IndexReader reader, String fieldname, int type, Locale locale, SortComparatorSource factory), ScoreDocComparator lookup(IndexReader reader, String field, int type, Object factory), SortField[] getFields(), TermPositions peek(), boolean insert(Object element), boolean lessThan(Object a, Object b), boolean lessThan(Object o1, Object o2), int size(), void CellQueue(int size), void FieldDocSortedHitQueue(SortField[] fields, int size), void FieldSortedHitQueue(IndexReader reader, SortField[] fields, int size), void HitQueue(int size), void PhraseQueue(int size), void SegmentMergeQueue(int size), void SpanQueue(int size), void TermPositionsQueue(List termPositions), void adjustTop(), void clear(), void close(), void downHeap(), void initialize(int maxSize), void put(Object element), void setFields(SortField[] fields), void upHeap()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_7[[org.apache.lucene.search.FieldDocSortedHitQueue],[Collator[] hasCollators(SortField[] fields), SortField[] getFields(), boolean lessThan(Object a, Object b), void FieldDocSortedHitQueue(SortField[] fields, int size), void setFields(SortField[] fields)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_6[...,...]
	->	->NODE_8[[org.apache.lucene.index.SegmentMergeQueue],[boolean lessThan(Object a, Object b), void SegmentMergeQueue(int size), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->	->NODE_9[[org.apache.lucene.index.MultipleTermPositions.TermPositionsQueue],[TermPositions peek(), boolean lessThan(Object a, Object b), void TermPositionsQueue(List termPositions)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->	->NODE_10[[org.apache.lucene.search.HitQueue],[boolean lessThan(Object a, Object b), void HitQueue(int size)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->NODE_11[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.FuzzyQuery, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery, org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanTermQuery],[String toString(String field)]]
	->ITS CHILDREN:=================
	->	->NODE_12[[org.apache.lucene.search.FuzzyQuery],[FilteredTermEnum getEnum(IndexReader reader), String toString(String field), void FuzzyQuery(Term term)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_13[[org.apache.lucene.search.MultiTermQuery],[FilteredTermEnum getEnum(IndexReader reader), Query combine(Query[] queries), Query rewrite(IndexReader reader), String toString(String field), Term getTerm(), void FuzzyQuery(Term term), void MultiTermQuery(Term term), void WildcardQuery(Term term)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_14[[org.apache.lucene.search.Query],[BooleanClause[] getClauses(), Collection getTerms(), FilteredTermEnum getEnum(IndexReader reader), Query combine(Query[] queries), Query getQuery(), Query mergeBooleanQueries(Query[] queries), Query rewrite(IndexReader reader), Similarity getSimilarity(Searcher searcher), SpanQuery getExclude(), SpanQuery getInclude(), SpanQuery getMatch(), SpanQuery[] getClauses(), Spans getSpans(IndexReader reader), String getField(), String toString(String f), String toString(String field), String toString(String s), Term getLowerTerm(), Term getPrefix(), Term getTerm(), Term getUpperTerm(), Term[] getTerms(), Weight createWeight(Searcher searcher), Weight weight(Searcher searcher), boolean isInOrder(), boolean isInclusive(), float getBoost(), int getEnd(), int getMaxClauseCount(), int getSlop(), void BooleanQuery(), void FilteredQuery(Query query, Filter filter), void FuzzyQuery(Term term), void MultiTermQuery(Term term), void PhraseQuery(), void PrefixQuery(Term prefix), void RangeQuery(Term lowerTerm, Term upperTerm, boolean inclusive), void SpanFirstQuery(SpanQuery match, int end), void SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder), void SpanNotQuery(SpanQuery include, SpanQuery exclude), void SpanOrQuery(SpanQuery[] clauses), void SpanTermQuery(Term term), void TermQuery(Term t), void WildcardQuery(Term term), void add(BooleanClause clause), void add(Query query, boolean required, boolean prohibited), void add(Term term), void add(Term[] terms), void setBoost(float b), void setMaxClauseCount(int maxClauseCount), void setSlop(int s)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->NODE_15[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.Query, org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanQuery],[String toString(String field), Weight createWeight(Searcher searcher)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_16[[org.apache.lucene.search.BooleanQuery],[BooleanClause[] getClauses(), Query rewrite(IndexReader reader), String toString(String field), Weight createWeight(Searcher searcher), int getMaxClauseCount(), void BooleanQuery(), void add(BooleanClause clause), void add(Query query, boolean required, boolean prohibited), void setMaxClauseCount(int maxClauseCount)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_14[...,...]
	->	->	->NODE_17[[org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanQuery],[String toString(String field), Term getTerm(), Weight createWeight(Searcher searcher)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_18[[org.apache.lucene.search.TermQuery],[String toString(String field), Term getTerm(), Weight createWeight(Searcher searcher), void TermQuery(Term t)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_14[...,...]
	->	->	->	->NODE_19[[org.apache.lucene.search.spans.SpanQuery],[Collection getTerms(), SpanQuery getExclude(), SpanQuery getInclude(), SpanQuery getMatch(), SpanQuery[] getClauses(), Spans getSpans(IndexReader reader), String getField(), String toString(String field), Term getTerm(), Weight createWeight(Searcher searcher), boolean isInOrder(), int getEnd(), int getSlop(), void SpanFirstQuery(SpanQuery match, int end), void SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder), void SpanNotQuery(SpanQuery include, SpanQuery exclude), void SpanOrQuery(SpanQuery[] clauses), void SpanTermQuery(Term term)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_14[...,...]
	->	->NODE_20[[org.apache.lucene.search.RangeQuery, org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanTermQuery],[String getField(), String toString(String field)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_21[[org.apache.lucene.search.RangeQuery],[Query combine(Query[] queries), Query rewrite(IndexReader reader), String getField(), String toString(String field), Term getLowerTerm(), Term getUpperTerm(), boolean isInclusive(), void RangeQuery(Term lowerTerm, Term upperTerm, boolean inclusive)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_14[...,...]
	->	->	->NODE_22[[org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanTermQuery],[Collection getTerms(), Spans getSpans(IndexReader reader), String getField(), String toString(String field)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_23[[org.apache.lucene.search.spans.SpanNotQuery],[Collection getTerms(), SpanQuery getExclude(), SpanQuery getInclude(), Spans getSpans(IndexReader reader), String getField(), String toString(String field), void SpanNotQuery(SpanQuery include, SpanQuery exclude)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_19[...,...]
	->	->	->	->NODE_24[[org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanOrQuery],[Collection getTerms(), SpanQuery[] getClauses(), Spans getSpans(IndexReader reader), String getField(), String toString(String field)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_25[[org.apache.lucene.search.spans.SpanNearQuery],[Collection getTerms(), SpanQuery[] getClauses(), Spans getSpans(IndexReader reader), String getField(), String toString(String field), boolean isInOrder(), int getSlop(), void SpanNearQuery(SpanQuery[] clauses, int slop, boolean inOrder)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_19[...,...]
	->	->	->	->	->NODE_26[[org.apache.lucene.search.spans.SpanOrQuery],[Collection getTerms(), SpanQuery[] getClauses(), Spans getSpans(IndexReader reader), String getField(), String toString(String field), void SpanOrQuery(SpanQuery[] clauses)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_19[...,...]
	->	->	->	->NODE_27[[org.apache.lucene.search.spans.SpanTermQuery],[Collection getTerms(), Spans getSpans(IndexReader reader), String getField(), String toString(String field), Term getTerm(), void SpanTermQuery(Term term)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_19[...,...]
	->	->	->	->NODE_28[[org.apache.lucene.search.spans.SpanFirstQuery],[Collection getTerms(), SpanQuery getMatch(), Spans getSpans(IndexReader reader), String getField(), String toString(String field), int getEnd(), void SpanFirstQuery(SpanQuery match, int end)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_19[...,...]
	->	->NODE_29[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery],[Query rewrite(IndexReader reader), String toString(String field)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_16[...,...]
	->	->	->NODE_30[[org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery],[Query combine(Query[] queries), Query rewrite(IndexReader reader), String toString(String field)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_13[...,...]
	->	->	->	->NODE_21[...,...]
	->	->	->	->NODE_31[[org.apache.lucene.search.PrefixQuery],[Query combine(Query[] queries), Query rewrite(IndexReader reader), String toString(String field), Term getPrefix(), void PrefixQuery(Term prefix)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_14[...,...]
	->	->NODE_32[[org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanTermQuery],[String toString(String field), Term getTerm()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_13[...,...]
	->	->	->NODE_27[...,...]
	->	->	->NODE_17[...,...]
	->NODE_33[[org.apache.lucene.analysis.standard.ParseException, org.apache.lucene.queryParser.ParseException],[String add_escapes(String str), void ParseException(), void ParseException(String message), void ParseException(Token currentTokenVal, int[][] expectedTokenSequencesVal, String[] tokenImageVal)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_34[[org.apache.lucene.search.BooleanScorer.SubScorer],[void SubScorer(Scorer scorer, boolean required, boolean prohibited, HitCollector collector, SubScorer next)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_35[[org.apache.lucene.analysis.ru.RussianCharsets],[char toLowerCase(char letter, char[] charset)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_36[[org.apache.lucene.search.ExactPhraseScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.SloppyPhraseScorer],[float phraseFreq()]]
	->ITS CHILDREN:=================
	->	->NODE_37[[org.apache.lucene.search.SloppyPhraseScorer],[float phraseFreq(), void SloppyPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, int slop, byte[] norms)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_38[[org.apache.lucene.search.PhraseScorer],[Explanation explain(int doc), boolean doNext(), boolean next(), boolean skipTo(int target), float phraseFreq(), float score(), int doc(), void ExactPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void PhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void SloppyPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, int slop, byte[] norms), void firstToLast(), void init(), void pqToList(), void sort()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_39[[org.apache.lucene.search.Scorer],[Explanation explain(int doc), Scorer first(), Scorer last(), Similarity getSimilarity(), boolean doNext(), boolean next(), boolean skipTo(int target), float phraseFreq(), float score(), int doc(), void BooleanScorer(Similarity similarity), void ConjunctionScorer(Similarity similarity), void ExactPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void PhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms), void Scorer(Similarity similarity), void SloppyPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, int slop, byte[] norms), void SpanScorer(Spans spans, Weight weight, Similarity similarity, byte[] norms), void TermScorer(Weight weight, TermDocs td, Similarity similarity, byte[] norms), void add(Scorer scorer), void add(Scorer scorer, boolean required, boolean prohibited), void computeCoordFactors(), void firstToLast(), void init(), void pqToList(), void score(HitCollector hc), void sort(), void sortScorers()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->NODE_40[[org.apache.lucene.search.ExactPhraseScorer],[float phraseFreq(), void ExactPhraseScorer(Weight weight, TermPositions[] tps, Similarity similarity, byte[] norms)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_38[...,...]
	->NODE_41[[org.apache.lucene.queryParser.MultiFieldQueryParser],[Query parse(String query, String[] fields, Analyzer analyzer), Query parse(String query, String[] fields, int[] flags, Analyzer analyzer), void MultiFieldQueryParser(CharStream stream), void MultiFieldQueryParser(QueryParserTokenManager tm), void MultiFieldQueryParser(String f, Analyzer a)]]
	->ITS CHILDREN:=================
	->	->NODE_42[[org.apache.lucene.queryParser.QueryParser],[Locale getLocale(), ParseException generateParseException(), Query Clause(String field), Query Query(String field), Query Term(String field), Query getBooleanQuery(Vector clauses), Query getFieldQuery(String field, Analyzer analyzer, String queryText), Query getFieldQuery(String field, Analyzer analyzer, String queryText, int slop), Query getFuzzyQuery(String field, String termStr), Query getPrefixQuery(String field, String termStr), Query getRangeQuery(String field, Analyzer analyzer, String part1, String part2, boolean inclusive), Query getWildcardQuery(String field, String termStr), Query parse(String query), Query parse(String query, String field, Analyzer analyzer), Query parse(String query, String[] fields, Analyzer analyzer), Query parse(String query, String[] fields, int[] flags, Analyzer analyzer), String discardEscapeChar(String input), Token getNextToken(), Token getToken(int index), Token jj_consume_token(int kind), boolean getLowercaseWildcardTerms(), boolean jj_2_1(int xla), boolean jj_3_1(), boolean jj_scan_token(int kind), int Conjunction(), int Modifiers(), int getOperator(), int getPhraseSlop(), int jj_ntk(), void MultiFieldQueryParser(CharStream stream), void MultiFieldQueryParser(QueryParserTokenManager tm), void MultiFieldQueryParser(String f, Analyzer a), void QueryParser(CharStream stream), void QueryParser(QueryParserTokenManager tm), void QueryParser(String f, Analyzer a), void ReInit(CharStream stream), void ReInit(QueryParserTokenManager tm), void addClause(Vector clauses, int conj, int mods, Query q), void disable_tracing(), void enable_tracing(), void jj_add_error_token(int kind, int pos), void jj_la1_0(), void jj_la1_1(), void jj_rescan_token(), void jj_save(int index, int xla), void main(String[] args), void setLocale(Locale locale), void setLowercaseWildcardTerms(boolean lowercaseWildcardTerms), void setOperator(int operator), void setPhraseSlop(int phraseSlop)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_43[[org.apache.lucene.queryParser.QueryParserConstants],[Locale getLocale(), ParseException generateParseException(), Query Clause(String field), Query Query(String field), Query Term(String field), Query getBooleanQuery(Vector clauses), Query getFieldQuery(String field, Analyzer analyzer, String queryText), Query getFieldQuery(String field, Analyzer analyzer, String queryText, int slop), Query getFuzzyQuery(String field, String termStr), Query getPrefixQuery(String field, String termStr), Query getRangeQuery(String field, Analyzer analyzer, String part1, String part2, boolean inclusive), Query getWildcardQuery(String field, String termStr), Query parse(String query), Query parse(String query, String field, Analyzer analyzer), Query parse(String query, String[] fields, Analyzer analyzer), Query parse(String query, String[] fields, int[] flags, Analyzer analyzer), String discardEscapeChar(String input), Token getNextToken(), Token getToken(int index), Token jjFillToken(), Token jj_consume_token(int kind), boolean getLowercaseWildcardTerms(), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), boolean jj_2_1(int xla), boolean jj_3_1(), boolean jj_scan_token(int kind), int Conjunction(), int Modifiers(), int getOperator(), int getPhraseSlop(), int jjMoveNfa_0(int startState, int curPos), int jjMoveNfa_1(int startState, int curPos), int jjMoveNfa_2(int startState, int curPos), int jjMoveNfa_3(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), int jjMoveStringLiteralDfa0_1(), int jjMoveStringLiteralDfa0_2(), int jjMoveStringLiteralDfa0_3(), int jjMoveStringLiteralDfa1_1(long active0), int jjMoveStringLiteralDfa1_2(long active0), int jjStartNfaWithStates_1(int pos, int kind, int state), int jjStartNfaWithStates_2(int pos, int kind, int state), int jjStartNfaWithStates_3(int pos, int kind, int state), int jjStartNfa_1(int pos, long active0), int jjStartNfa_2(int pos, long active0), int jjStartNfa_3(int pos, long active0), int jjStopAtPos(int pos, int kind), int jjStopStringLiteralDfa_1(int pos, long active0), int jjStopStringLiteralDfa_2(int pos, long active0), int jjStopStringLiteralDfa_3(int pos, long active0), int jj_ntk(), void MultiFieldQueryParser(CharStream stream), void MultiFieldQueryParser(QueryParserTokenManager tm), void MultiFieldQueryParser(String f, Analyzer a), void QueryParser(CharStream stream), void QueryParser(QueryParserTokenManager tm), void QueryParser(String f, Analyzer a), void QueryParserTokenManager(CharStream stream), void QueryParserTokenManager(CharStream stream, int lexState), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInit(QueryParserTokenManager tm), void ReInitRounds(), void SwitchTo(int lexState), void addClause(Vector clauses, int conj, int mods, Query q), void disable_tracing(), void enable_tracing(), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void jj_add_error_token(int kind, int pos), void jj_la1_0(), void jj_la1_1(), void jj_rescan_token(), void jj_save(int index, int xla), void main(String[] args), void setDebugStream(java.io.PrintStream ds), void setLocale(Locale locale), void setLowercaseWildcardTerms(boolean lowercaseWildcardTerms), void setOperator(int operator), void setPhraseSlop(int phraseSlop)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->NODE_44[[org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer, org.apache.lucene.index.CompoundFileReader, org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.index.CompoundFileWriter, org.apache.lucene.index.FieldsReader, org.apache.lucene.index.FieldsWriter, org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.IndexReader, org.apache.lucene.index.IndexWriter, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.index.SegmentMergeQueue, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermEnum, org.apache.lucene.index.TermInfosReader, org.apache.lucene.index.TermInfosWriter, org.apache.lucene.index.TermVectorsReader, org.apache.lucene.index.TermVectorsWriter, org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.FuzzyTermEnum, org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable, org.apache.lucene.search.WildcardTermEnum, org.apache.lucene.store.Directory, org.apache.lucene.store.FSDirectory, org.apache.lucene.store.FSInputStream, org.apache.lucene.store.FSOutputStream, org.apache.lucene.store.InputStream, org.apache.lucene.store.OutputStream, org.apache.lucene.store.RAMDirectory, org.apache.lucene.store.RAMInputStream, org.apache.lucene.store.RAMOutputStream],[void close()]]
	->ITS CHILDREN:=================
	->	->NODE_45[[org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.store.FSInputStream],[void close(), void readInternal(byte[] b, int offset, int len)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_46[[org.apache.lucene.index.CompoundFileReader.CSInputStream],[void CSInputStream(InputStream base, long fileOffset, long length), void close(), void readInternal(byte[] b, int offset, int len), void seekInternal(long pos)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_47[[org.apache.lucene.store.InputStream],[String readString(), boolean isFDValid(), byte readByte(), int readInt(), int readVInt(), long getFilePointer(), long length(), long readLong(), long readVLong(), void CSInputStream(InputStream base, long fileOffset, long length), void FSInputStream(File path), void RAMInputStream(RAMFile f), void close(), void readBytes(byte[] b, int offset, int len), void readChars(char[] buffer, int start, int length), void readInternal(byte[] b, int offset, int len), void readInternal(byte[] b, int offset, int length), void readInternal(byte[] dest, int destOffset, int len), void refill(), void seek(long pos), void seekInternal(long pos), void seekInternal(long position)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_48[[org.apache.lucene.store.FSInputStream],[boolean isFDValid(), void FSInputStream(File path), void close(), void readInternal(byte[] b, int offset, int len), void seekInternal(long position)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_47[...,...]
	->	->NODE_49[[org.apache.lucene.index.FieldsReader, org.apache.lucene.index.TermVectorsReader, org.apache.lucene.util.PriorityQueue],[int size(), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->	->	->NODE_50[[org.apache.lucene.index.TermVectorsReader],[SegmentTermVector readTermVector(String field, long tvfPointer), SegmentTermVector[] readTermVectors(String[] fields, long[] tvfPointers), TermFreqVector get(int docNum, String field), TermFreqVector[] get(int docNum), int size(), void TermVectorsReader(Directory d, String segment, FieldInfos fieldInfos), void checkValidFormat(InputStream in), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_51[[org.apache.lucene.index.FieldsReader],[Document doc(int n), int size(), void FieldsReader(Directory d, String segment, FieldInfos fn), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_52[[org.apache.lucene.index.IndexReader, org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable],[int maxDoc(), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_53[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable],[Explanation explain(Query query, int doc), Query rewrite(Query original), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_54[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher],[Explanation explain(Query query, int doc), Query rewrite(Query original), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_55[[org.apache.lucene.search.MultiSearcher],[Document doc(int n), Explanation explain(Query query, int doc), Query rewrite(Query original), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), int maxDoc(), int searcherIndex(int n), int subDoc(int n), int subSearcher(int n), int[] getStarts(), void MultiSearcher(Searchable[] searchables), void ParallelMultiSearcher(Searchable[] searchables), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_56[[org.apache.lucene.search.Searcher],[Document doc(int i), Document doc(int n), Explanation explain(Query query, int doc), Hits search(Query query), Hits search(Query query, Filter filter), Hits search(Query query, Filter filter, Sort sort), Hits search(Query query, Sort sort), Query rewrite(Query original), Similarity getSimilarity(), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), int maxDoc(), int searcherIndex(int n), int subDoc(int n), int subSearcher(int n), int[] getStarts(), void IndexSearcher(Directory directory), void IndexSearcher(IndexReader r), void IndexSearcher(IndexReader r, boolean closeReader), void IndexSearcher(String path), void MultiSearcher(Searchable[] searchables), void ParallelMultiSearcher(Searchable[] searchables), void close(), void search(Query query, Filter filter, HitCollector results), void search(Query query, HitCollector results), void setSimilarity(Similarity similarity)]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_57[[org.apache.lucene.search.Searchable],[Document doc(int i), Document doc(int n), Explanation explain(Query query, int doc), Hits search(Query query), Hits search(Query query, Filter filter), Hits search(Query query, Filter filter, Sort sort), Hits search(Query query, Sort sort), Query rewrite(Query original), Query rewrite(Query query), Similarity getSimilarity(), TopDocs search(Query query, Filter filter, int n), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), int maxDoc(), int searcherIndex(int n), int subDoc(int n), int subSearcher(int n), int[] getStarts(), void IndexSearcher(Directory directory), void IndexSearcher(IndexReader r), void IndexSearcher(IndexReader r, boolean closeReader), void IndexSearcher(String path), void MultiSearcher(Searchable[] searchables), void ParallelMultiSearcher(Searchable[] searchables), void RemoteSearchable(Searchable local), void close(), void main(String[] args), void search(Query query, Filter filter, HitCollector results), void search(Query query, HitCollector results), void setSimilarity(Similarity similarity)]]
	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->NODE_2[...,...]
	->	->	->	->	->NODE_58[[org.apache.lucene.search.IndexSearcher],[Document doc(int i), Explanation explain(Query query, int doc), Query rewrite(Query original), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), int maxDoc(), void IndexSearcher(Directory directory), void IndexSearcher(IndexReader r), void IndexSearcher(IndexReader r, boolean closeReader), void IndexSearcher(String path), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_56[...,...]
	->	->	->	->NODE_59[[org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable],[Explanation explain(Query query, int doc), Query rewrite(Query original), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_55[...,...]
	->	->	->	->	->NODE_60[[org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searcher],[Document doc(int i), Explanation explain(Query query, int doc), Query rewrite(Query original), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_56[...,...]
	->	->	->	->	->	->NODE_61[[org.apache.lucene.search.RemoteSearchable],[Document doc(int i), Explanation explain(Query query, int doc), Query rewrite(Query original), TopDocs search(Query query, Filter filter, int n), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), int docFreq(Term term), int maxDoc(), void RemoteSearchable(Searchable local), void close(), void main(String[] args), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_57[...,...]
	->	->	->	->NODE_62[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.RemoteSearchable],[Document doc(int i), Explanation explain(Query query, int doc), Query rewrite(Query original), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_60[...,...]
	->	->	->	->	->NODE_58[...,...]
	->	->	->NODE_63[[org.apache.lucene.index.IndexReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Directory directory(), Document document(int n), IndexReader open(Directory directory), IndexReader open(Directory directory, boolean closeDirectory), IndexReader open(File path), IndexReader open(String path), TermDocs termDocs(), TermDocs termDocs(Term term), TermEnum terms(), TermEnum terms(Term t), TermEnum terms(Term term), TermFreqVector getTermFreqVector(int docNumber, String field), TermFreqVector getTermFreqVector(int n, String field), TermFreqVector[] getTermFreqVectors(int docNumber), TermFreqVector[] getTermFreqVectors(int n), TermPositions termPositions(), TermPositions termPositions(Term term), Vector files(), boolean hasDeletions(), boolean hasDeletions(SegmentInfo si), boolean hasSeparateNorms(SegmentInfo si), boolean indexExists(Directory directory), boolean indexExists(File directory), boolean indexExists(String directory), boolean isDeleted(int n), boolean isLocked(Directory directory), boolean isLocked(String directory), boolean usesCompoundFile(SegmentInfo si), byte[] norms(String f), byte[] norms(String field), int delete(Term term), int docFreq(Term t), int maxDoc(), int numDocs(), int readerIndex(int n), long getCurrentVersion(Directory directory), long getCurrentVersion(File directory), long getCurrentVersion(String directory), long lastModified(Directory directory), long lastModified(File directory), long lastModified(String directory), void FilterIndexReader(IndexReader in), void IndexReader(Directory directory), void IndexReader(Directory directory, SegmentInfos segmentInfos, boolean closeDirectory), void MultiReader(Directory directory, SegmentInfos sis, boolean closeDirectory, IndexReader[] subReaders), void MultiReader(IndexReader[] subReaders), void SegmentReader(SegmentInfo si), void SegmentReader(SegmentInfos sis, SegmentInfo si, boolean closeDir), void aquireWriteLock(), void close(), void closeNorms(), void commit(), void delete(int docNum), void doClose(), void doCommit(), void doDelete(int docNum), void doDelete(int n), void doSetNorm(int d, String f, byte b), void doSetNorm(int doc, String field, byte value), void doSetNorm(int n, String field, byte value), void doUndeleteAll(), void initialize(IndexReader[] subReaders), void initialize(SegmentInfo si), void norms(String f, byte[] bytes, int offset), void norms(String field, byte[] bytes, int offset), void norms(String field, byte[] result, int offset), void openNorms(Directory cfsDir), void setNorm(int doc, String field, byte value), void setNorm(int doc, String field, float value), void undeleteAll(), void unlock(Directory directory)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_64[[org.apache.lucene.index.TermVectorsWriter],[boolean isDocumentOpen(), boolean isFieldOpen(), void TermVectorsWriter(Directory directory, String segment, FieldInfos fieldInfos), void addTerm(String termText, int freq), void addTermFreqVector(TermFreqVector vector), void addTermFreqVectorInternal(TermFreqVector vector), void addTermInternal(String termText, int freq), void addVectors(TermFreqVector[] vectors), void close(), void closeDocument(), void closeField(), void openDocument(), void openField(String field), void writeDoc(), void writeField()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->	->NODE_65[[org.apache.lucene.store.FSOutputStream, org.apache.lucene.store.InputStream, org.apache.lucene.store.OutputStream, org.apache.lucene.store.RAMOutputStream],[long length(), void close(), void seek(long pos)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_66[[org.apache.lucene.store.InputStream, org.apache.lucene.store.OutputStream],[long getFilePointer(), long length(), void close(), void seek(long pos)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_47[...,...]
	->	->	->	->NODE_67[[org.apache.lucene.store.OutputStream],[long getFilePointer(), long length(), void FSOutputStream(File path), void RAMOutputStream(), void RAMOutputStream(RAMFile f), void close(), void flush(), void flushBuffer(byte[] b, int len), void flushBuffer(byte[] b, int size), void flushBuffer(byte[] src, int len), void reset(), void seek(long pos), void writeByte(byte b), void writeBytes(byte[] b, int length), void writeChars(String s, int start, int length), void writeInt(int i), void writeLong(long i), void writeString(String s), void writeTo(OutputStream out), void writeVInt(int i), void writeVLong(long i)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_68[[org.apache.lucene.store.FSOutputStream],[long length(), void FSOutputStream(File path), void close(), void flushBuffer(byte[] b, int size), void seek(long pos)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_67[...,...]
	->	->	->NODE_69[[org.apache.lucene.store.RAMOutputStream],[long length(), void RAMOutputStream(), void RAMOutputStream(RAMFile f), void close(), void flushBuffer(byte[] src, int len), void reset(), void seek(long pos), void writeTo(OutputStream out)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_67[...,...]
	->	->NODE_70[[org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.store.InputStream, org.apache.lucene.store.RAMInputStream],[void close(), void seekInternal(long pos)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_71[[org.apache.lucene.store.RAMInputStream],[void RAMInputStream(RAMFile f), void close(), void readInternal(byte[] dest, int destOffset, int len), void seekInternal(long pos)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_47[...,...]
	->	->	->NODE_46[...,...]
	->	->NODE_72[[org.apache.lucene.index.IndexWriter, org.apache.lucene.search.Searcher],[Similarity getSimilarity(), void close(), void setSimilarity(Similarity similarity)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_56[...,...]
	->	->	->NODE_73[[org.apache.lucene.index.IndexWriter],[Analyzer getAnalyzer(), Similarity getSimilarity(), String newSegmentName(), Vector readDeleteableFiles(), boolean getUseCompoundFile(), int docCount(), int getSegmentsCounter(), void IndexWriter(Directory d, Analyzer a, boolean create), void IndexWriter(Directory d, Analyzer a, boolean create, boolean closeDir), void IndexWriter(File path, Analyzer a, boolean create), void IndexWriter(String path, Analyzer a, boolean create), void addDocument(Document doc), void addDocument(Document doc, Analyzer analyzer), void addIndexes(Directory[] dirs), void addIndexes(IndexReader[] readers), void close(), void deleteFiles(Vector files, Directory directory), void deleteFiles(Vector files, Vector deletable), void deleteSegments(Vector segments), void flushRamSegments(), void maybeMergeSegments(), void mergeSegments(int minSegment), void optimize(), void setSimilarity(Similarity similarity), void setUseCompoundFile(boolean value), void writeDeleteableFiles(Vector files)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_74[[org.apache.lucene.index.CompoundFileReader, org.apache.lucene.index.CompoundFileWriter],[Directory getDirectory(), String getName(), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_75[[org.apache.lucene.index.CompoundFileReader],[Directory getDirectory(), InputStream openFile(String id), Lock makeLock(String name), OutputStream createFile(String name), String getName(), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(String name), void CompoundFileReader(Directory dir, String name), void close(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_76[[org.apache.lucene.store.Directory],[Directory getDirectory(), FSDirectory getDirectory(File file, boolean create), FSDirectory getDirectory(String path, boolean create), File getFile(), InputStream openFile(String id), InputStream openFile(String name), Lock makeLock(String name), OutputStream createFile(String name), String getName(), StringBuffer getLockPrefix(), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(File directory, String name), long fileModified(String name), void CompoundFileReader(Directory dir, String name), void FSDirectory(File path, boolean create), void RAMDirectory(), void RAMDirectory(Directory dir), void RAMDirectory(Directory dir, boolean closeDir), void RAMDirectory(File dir), void RAMDirectory(String dir), void close(), void create(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_77[[org.apache.lucene.index.CompoundFileWriter],[Directory getDirectory(), String getName(), void CompoundFileWriter(Directory dir, String name), void addFile(String file), void close(), void copyFile(FileEntry source, OutputStream os, byte[] buffer)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_78[[org.apache.lucene.index.TermInfosReader],[SegmentTermEnum getEnum(), SegmentTermEnum terms(), SegmentTermEnum terms(Term term), Term get(int position), Term scanEnum(int position), TermInfo get(Term term), TermInfo scanEnum(Term term), int getIndexOffset(Term term), int getSkipInterval(), long getPosition(Term term), long size(), void TermInfosReader(Directory dir, String seg, FieldInfos fis), void close(), void readIndex(), void seekEnum(int indexOffset)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->	->NODE_79[[org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.FuzzyTermEnum, org.apache.lucene.search.WildcardTermEnum],[boolean endEnum(), boolean termCompare(Term term), float difference(), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_80[[org.apache.lucene.search.FuzzyTermEnum],[boolean endEnum(), boolean termCompare(Term term), float difference(), int editDistance(String s, String t, int n, int m), int min(int a, int b, int c), void FuzzyTermEnum(IndexReader reader, Term term), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_81[[org.apache.lucene.search.FilteredTermEnum],[Term term(), boolean endEnum(), boolean next(), boolean termCompare(Term term), boolean wildcardEquals(String pattern, int patternIdx, String string, int stringIdx), float difference(), int docFreq(), int editDistance(String s, String t, int n, int m), int min(int a, int b, int c), void FilteredTermEnum(), void FuzzyTermEnum(IndexReader reader, Term term), void WildcardTermEnum(IndexReader reader, Term term), void close(), void setEnum(TermEnum actualEnum)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_82[[org.apache.lucene.index.TermEnum],[Term readTerm(), Term term(), TermInfo termInfo(), boolean endEnum(), boolean next(), boolean skipTo(Term target), boolean termCompare(Term term), boolean wildcardEquals(String pattern, int patternIdx, String string, int stringIdx), float difference(), int docFreq(), int editDistance(String s, String t, int n, int m), int min(int a, int b, int c), long freqPointer(), long proxPointer(), void FilterTermEnum(TermEnum in), void FilteredTermEnum(), void FuzzyTermEnum(IndexReader reader, Term term), void MultiTermEnum(IndexReader[] readers, int[] starts, Term t), void SegmentTermEnum(InputStream i, FieldInfos fis, boolean isi), void WildcardTermEnum(IndexReader reader, Term term), void close(), void growBuffer(int length), void seek(long pointer, int p, Term t, TermInfo ti), void setEnum(TermEnum actualEnum), void termInfo(TermInfo ti)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_83[[org.apache.lucene.search.WildcardTermEnum],[boolean endEnum(), boolean termCompare(Term term), boolean wildcardEquals(String pattern, int patternIdx, String string, int stringIdx), float difference(), void WildcardTermEnum(IndexReader reader, Term term), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_81[...,...]
	->	->NODE_84[[org.apache.lucene.index.TermInfosWriter],[void TermInfosWriter(Directory directory, String segment, FieldInfos fis), void TermInfosWriter(Directory directory, String segment, FieldInfos fis, boolean isIndex), void add(Term term, TermInfo ti), void close(), void initialize(Directory directory, String segment, FieldInfos fis, boolean isi), void writeTerm(Term term)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->	->NODE_85[[org.apache.lucene.index.FieldsReader, org.apache.lucene.search.MultiSearcher],[Document doc(int n), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_55[...,...]
	->	->	->NODE_51[...,...]
	->	->NODE_8[...,...]
	->	->NODE_86[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermEnum, org.apache.lucene.search.FilteredTermEnum],[boolean next(), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_87[[org.apache.lucene.index.SegmentMergeInfo],[boolean next(), void SegmentMergeInfo(int b, TermEnum te, IndexReader r), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_88[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermPositions],[boolean next(), int nextPosition(), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_89[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermPositions],[boolean next(), int nextPosition(), int read(int[] docs, int[] freqs), void close()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_90[[org.apache.lucene.index.SegmentTermPositions],[boolean next(), int nextPosition(), int read(int[] docs, int[] freqs), void SegmentTermPositions(SegmentReader p), void close(), void seek(TermInfo ti), void skipProx(long proxPointer), void skippingDoc()]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_91[[org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermPositions],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void SegmentTermPositions(SegmentReader p), void close(), void seek(TermEnum termEnum), void seek(TermInfo ti), void skipProx(long proxPointer), void skippingDoc()]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_92[[org.apache.lucene.index.SegmentTermDocs],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void SegmentTermDocs(SegmentReader parent), void SegmentTermPositions(SegmentReader p), void close(), void seek(Term term), void seek(TermEnum termEnum), void seek(TermInfo ti), void skipProx(long proxPointer), void skippingDoc()]]
	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->NODE_93[[org.apache.lucene.index.TermDocs],[TermDocs termDocs(IndexReader reader), TermDocs termDocs(int i), boolean next(), boolean skipTo(int i), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] arg0, int[] arg1), int read(int[] docs, int[] freqs), void FilterTermDocs(TermDocs in), void FilterTermPositions(TermPositions in), void MultiTermDocs(IndexReader[] r, int[] s), void MultiTermPositions(IndexReader[] r, int[] s), void MultipleTermPositions(IndexReader indexReader, Term[] terms), void SegmentTermDocs(SegmentReader parent), void SegmentTermPositions(SegmentReader p), void close(), void seek(Term arg0), void seek(Term term), void seek(TermEnum termEnum), void seek(TermInfo ti), void skipProx(long proxPointer), void skippingDoc()]]
	->	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->	->NODE_2[...,...]
	->	->	->	->	->	->	->NODE_94[[org.apache.lucene.index.TermPositions],[TermDocs termDocs(IndexReader reader), boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] arg0, int[] arg1), int read(int[] docs, int[] freqs), void FilterTermPositions(TermPositions in), void MultiTermPositions(IndexReader[] r, int[] s), void MultipleTermPositions(IndexReader indexReader, Term[] terms), void SegmentTermPositions(SegmentReader p), void close(), void seek(Term arg0), void seek(TermEnum termEnum), void seek(TermInfo ti), void skipProx(long proxPointer), void skippingDoc()]]
	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->NODE_93[...,...]
	->	->	->	->	->NODE_95[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermPositions],[boolean next(), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void close(), void seek(TermEnum termEnum)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_96[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.TermPositions],[boolean next(), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void FilterTermPositions(TermPositions in), void close(), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_97[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs],[boolean next(), boolean skipTo(int i), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void FilterTermDocs(TermDocs in), void FilterTermPositions(TermPositions in), void close(), void seek(Term term), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->NODE_93[...,...]
	->	->	->	->	->	->	->NODE_94[...,...]
	->	->	->	->	->	->NODE_98[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs],[boolean next(), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void close(), void seek(Term term), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_97[...,...]
	->	->	->	->	->	->	->NODE_99[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void close(), void seek(Term term), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->NODE_100[[org.apache.lucene.index.MultiTermDocs],[TermDocs termDocs(IndexReader reader), TermDocs termDocs(int i), boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void MultiTermDocs(IndexReader[] r, int[] s), void MultiTermPositions(IndexReader[] r, int[] s), void close(), void seek(Term term), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->	->NODE_93[...,...]
	->	->	->	->	->	->	->	->NODE_92[...,...]
	->	->	->	->	->	->NODE_101[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermPositions],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void close(), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_91[...,...]
	->	->	->	->	->	->	->NODE_102[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.TermPositions],[TermDocs termDocs(IndexReader reader), boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void MultiTermPositions(IndexReader[] r, int[] s), void close(), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->	->NODE_100[...,...]
	->	->	->	->	->	->	->	->NODE_94[...,...]
	->	->	->	->	->	->	->NODE_99[...,...]
	->	->	->	->NODE_103[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs],[boolean next(), int doc(), int freq(), int nextPosition(), void close(), void seek(TermEnum termEnum)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_104[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), void close(), void seek(TermEnum termEnum)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_105[[org.apache.lucene.index.MultipleTermPositions],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] arg0, int[] arg1), void MultipleTermPositions(IndexReader indexReader, Term[] terms), void close(), void seek(Term arg0), void seek(TermEnum termEnum)]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_94[...,...]
	->	->	->	->	->	->NODE_101[...,...]
	->	->	->	->	->NODE_95[...,...]
	->	->	->NODE_106[[org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.TermEnum, org.apache.lucene.search.FilteredTermEnum],[Term term(), boolean next(), int docFreq(), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_107[[org.apache.lucene.index.FilterIndexReader.FilterTermEnum],[Term term(), boolean next(), int docFreq(), void FilterTermEnum(TermEnum in), void close()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_82[...,...]
	->	->	->	->NODE_108[[org.apache.lucene.index.SegmentTermEnum],[Term readTerm(), Term term(), TermInfo termInfo(), boolean next(), int docFreq(), long freqPointer(), long proxPointer(), void SegmentTermEnum(InputStream i, FieldInfos fis, boolean isi), void close(), void growBuffer(int length), void seek(long pointer, int p, Term t, TermInfo ti), void termInfo(TermInfo ti)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_82[...,...]
	->	->	->	->NODE_81[...,...]
	->	->	->	->NODE_109[[org.apache.lucene.index.MultiTermEnum],[Term term(), boolean next(), int docFreq(), void MultiTermEnum(IndexReader[] readers, int[] starts, Term t), void close()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_82[...,...]
	->	->NODE_110[[org.apache.lucene.index.FieldsWriter, org.apache.lucene.index.IndexWriter],[void addDocument(Document doc), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_111[[org.apache.lucene.index.FieldsWriter],[void FieldsWriter(Directory d, String segment, FieldInfos fn), void addDocument(Document doc), void close()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_73[...,...]
	->	->NODE_112[[org.apache.lucene.index.CompoundFileReader, org.apache.lucene.store.Directory, org.apache.lucene.store.FSDirectory, org.apache.lucene.store.RAMDirectory],[Lock makeLock(String name), OutputStream createFile(String name), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(String name), void close(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_113[[org.apache.lucene.store.Directory, org.apache.lucene.store.FSDirectory, org.apache.lucene.store.RAMDirectory],[InputStream openFile(String name), Lock makeLock(String name), OutputStream createFile(String name), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(String name), void close(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_114[[org.apache.lucene.store.RAMDirectory],[InputStream openFile(String name), Lock makeLock(String name), OutputStream createFile(String name), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(String name), void RAMDirectory(), void RAMDirectory(Directory dir), void RAMDirectory(Directory dir, boolean closeDir), void RAMDirectory(File dir), void RAMDirectory(String dir), void close(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_76[...,...]
	->	->	->	->NODE_115[[org.apache.lucene.store.FSDirectory],[FSDirectory getDirectory(File file, boolean create), FSDirectory getDirectory(String path, boolean create), File getFile(), InputStream openFile(String name), Lock makeLock(String name), OutputStream createFile(String name), StringBuffer getLockPrefix(), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(File directory, String name), long fileModified(String name), void FSDirectory(File path, boolean create), void close(), void create(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_76[...,...]
	->	->	->NODE_75[...,...]
	->	->NODE_116[[org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.Tokenizer],[Token next(), org.apache.lucene.analysis.Token next(), void close()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_117[[org.apache.lucene.analysis.Tokenizer],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jj_consume_token(int kind), Token next(), boolean isTokenChar(char c), char normalize(char c), int jj_ntk(), org.apache.lucene.analysis.Token next(), void CharTokenizer(Reader input), void LetterTokenizer(Reader in), void LowerCaseTokenizer(Reader in), void ReInit(CharStream stream), void ReInit(StandardTokenizerTokenManager tm), void RussianLetterTokenizer(Reader in, char[] charset), void StandardTokenizer(CharStream stream), void StandardTokenizer(Reader reader), void StandardTokenizer(StandardTokenizerTokenManager tm), void Tokenizer(), void Tokenizer(Reader input), void WhitespaceTokenizer(Reader in), void close(), void disable_tracing(), void enable_tracing(), void jj_la1_0()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_118[[org.apache.lucene.analysis.TokenStream],[Hashtable makeStopTable(String[] stopWords), ParseException generateParseException(), Set makeStopSet(String[] stopWords), Token getNextToken(), Token getToken(int index), Token jj_consume_token(int kind), Token next(), boolean isTokenChar(char c), char normalize(char c), int jj_ntk(), org.apache.lucene.analysis.Token next(), void CharTokenizer(Reader input), void GermanStemFilter(TokenStream in), void GermanStemFilter(TokenStream in, Hashtable exclusiontable), void GermanStemFilter(TokenStream in, Set exclusionSet), void LetterTokenizer(Reader in), void LowerCaseFilter(TokenStream in), void LowerCaseTokenizer(Reader in), void PorterStemFilter(TokenStream in), void ReInit(CharStream stream), void ReInit(StandardTokenizerTokenManager tm), void RussianLetterTokenizer(Reader in, char[] charset), void RussianLowerCaseFilter(TokenStream in, char[] charset), void RussianStemFilter(TokenStream in, char[] charset), void StandardFilter(TokenStream in), void StandardTokenizer(CharStream stream), void StandardTokenizer(Reader reader), void StandardTokenizer(StandardTokenizerTokenManager tm), void StopFilter(TokenStream in, Hashtable stopTable), void StopFilter(TokenStream in, Set stopWords), void StopFilter(TokenStream in, String[] stopWords), void TokenFilter(), void TokenFilter(TokenStream input), void Tokenizer(), void Tokenizer(Reader input), void WhitespaceTokenizer(Reader in), void close(), void disable_tracing(), void enable_tracing(), void jj_la1_0(), void setExclusionSet(Set exclusionSet), void setExclusionTable(Hashtable exclusiontable), void setStemmer(GermanStemmer stemmer), void setStemmer(RussianStemmer stemmer)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_119[[org.apache.lucene.analysis.TokenFilter],[Hashtable makeStopTable(String[] stopWords), Set makeStopSet(String[] stopWords), Token next(), org.apache.lucene.analysis.Token next(), void GermanStemFilter(TokenStream in), void GermanStemFilter(TokenStream in, Hashtable exclusiontable), void GermanStemFilter(TokenStream in, Set exclusionSet), void LowerCaseFilter(TokenStream in), void PorterStemFilter(TokenStream in), void RussianLowerCaseFilter(TokenStream in, char[] charset), void RussianStemFilter(TokenStream in, char[] charset), void StandardFilter(TokenStream in), void StopFilter(TokenStream in, Hashtable stopTable), void StopFilter(TokenStream in, Set stopWords), void StopFilter(TokenStream in, String[] stopWords), void TokenFilter(), void TokenFilter(TokenStream input), void close(), void setExclusionSet(Set exclusionSet), void setExclusionTable(Hashtable exclusiontable), void setStemmer(GermanStemmer stemmer), void setStemmer(RussianStemmer stemmer)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_118[...,...]
	->NODE_120[[org.apache.lucene.analysis.CharTokenizer, org.apache.lucene.analysis.LowerCaseFilter, org.apache.lucene.analysis.PorterStemFilter, org.apache.lucene.analysis.StopFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.de.GermanStemFilter, org.apache.lucene.analysis.ru.RussianLowerCaseFilter, org.apache.lucene.analysis.ru.RussianStemFilter],[Token next()]]
	->ITS CHILDREN:=================
	->	->NODE_121[[org.apache.lucene.analysis.ru.RussianStemFilter],[Token next(), void RussianStemFilter(TokenStream in, char[] charset), void setStemmer(RussianStemmer stemmer)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_119[...,...]
	->	->NODE_122[[org.apache.lucene.analysis.LowerCaseFilter],[Token next(), void LowerCaseFilter(TokenStream in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_119[...,...]
	->	->NODE_123[[org.apache.lucene.analysis.de.GermanStemFilter],[Token next(), void GermanStemFilter(TokenStream in), void GermanStemFilter(TokenStream in, Hashtable exclusiontable), void GermanStemFilter(TokenStream in, Set exclusionSet), void setExclusionSet(Set exclusionSet), void setExclusionTable(Hashtable exclusiontable), void setStemmer(GermanStemmer stemmer)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_119[...,...]
	->	->NODE_124[[org.apache.lucene.analysis.ru.RussianLowerCaseFilter],[Token next(), void RussianLowerCaseFilter(TokenStream in, char[] charset)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_119[...,...]
	->	->NODE_116[...,...]
	->	->NODE_125[[org.apache.lucene.analysis.CharTokenizer],[Token next(), boolean isTokenChar(char c), char normalize(char c), void CharTokenizer(Reader input), void LetterTokenizer(Reader in), void LowerCaseTokenizer(Reader in), void RussianLetterTokenizer(Reader in, char[] charset), void WhitespaceTokenizer(Reader in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_117[...,...]
	->	->NODE_126[[org.apache.lucene.analysis.StopFilter],[Hashtable makeStopTable(String[] stopWords), Set makeStopSet(String[] stopWords), Token next(), void StopFilter(TokenStream in, Hashtable stopTable), void StopFilter(TokenStream in, Set stopWords), void StopFilter(TokenStream in, String[] stopWords)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_119[...,...]
	->	->NODE_127[[org.apache.lucene.analysis.PorterStemFilter],[Token next(), void PorterStemFilter(TokenStream in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_119[...,...]
	->NODE_128[[org.apache.lucene.analysis.standard.Token, org.apache.lucene.queryParser.Token],[Token newToken(int ofKind)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_129[[org.apache.lucene.index.FilterIndexReader.FilterTermPositions, org.apache.lucene.index.MultiTermPositions, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermPositions],[int nextPosition()]]
	->ITS CHILDREN:=================
	->	->NODE_88[...,...]
	->	->NODE_130[[org.apache.lucene.index.MultiTermPositions],[TermDocs termDocs(IndexReader reader), int nextPosition(), void MultiTermPositions(IndexReader[] r, int[] s)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_102[...,...]
	->	->NODE_131[[org.apache.lucene.index.FilterIndexReader.FilterTermPositions],[int nextPosition(), void FilterTermPositions(TermPositions in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_96[...,...]
	->NODE_132[[org.apache.lucene.analysis.standard.StandardTokenizer, org.apache.lucene.analysis.standard.StandardTokenizerTokenManager, org.apache.lucene.queryParser.QueryParser, org.apache.lucene.queryParser.QueryParserTokenManager],[Token getNextToken(), void ReInit(CharStream stream)]]
	->ITS CHILDREN:=================
	->	->NODE_133[[org.apache.lucene.analysis.standard.StandardTokenizer, org.apache.lucene.queryParser.QueryParser],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jj_consume_token(int kind), int jj_ntk(), void ReInit(CharStream stream), void disable_tracing(), void enable_tracing(), void jj_la1_0()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_134[[org.apache.lucene.analysis.standard.StandardTokenizerConstants, org.apache.lucene.queryParser.QueryParserConstants],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jjFillToken(), Token jj_consume_token(int kind), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), int jjMoveNfa_0(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), int jj_ntk(), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInitRounds(), void SwitchTo(int lexState), void disable_tracing(), void enable_tracing(), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void jj_la1_0(), void setDebugStream(java.io.PrintStream ds)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_135[[org.apache.lucene.analysis.standard.StandardTokenizerConstants],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jjFillToken(), Token jj_consume_token(int kind), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), boolean jjCanMove_1(int hiByte, int i1, int i2, long l1, long l2), boolean jjCanMove_2(int hiByte, int i1, int i2, long l1, long l2), int jjMoveNfa_0(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), int jj_ntk(), org.apache.lucene.analysis.Token next(), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInit(StandardTokenizerTokenManager tm), void ReInitRounds(), void StandardFilter(TokenStream in), void StandardTokenizer(CharStream stream), void StandardTokenizer(Reader reader), void StandardTokenizer(StandardTokenizerTokenManager tm), void StandardTokenizerTokenManager(CharStream stream), void StandardTokenizerTokenManager(CharStream stream, int lexState), void SwitchTo(int lexState), void disable_tracing(), void enable_tracing(), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void jj_la1_0(), void setDebugStream(java.io.PrintStream ds)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->	->NODE_43[...,...]
	->	->	->NODE_42[...,...]
	->	->	->NODE_136[[org.apache.lucene.analysis.standard.StandardTokenizer],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jj_consume_token(int kind), int jj_ntk(), org.apache.lucene.analysis.Token next(), void ReInit(CharStream stream), void ReInit(StandardTokenizerTokenManager tm), void StandardTokenizer(CharStream stream), void StandardTokenizer(Reader reader), void StandardTokenizer(StandardTokenizerTokenManager tm), void disable_tracing(), void enable_tracing(), void jj_la1_0()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_117[...,...]
	->	->	->	->NODE_137[[org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.standard.StandardTokenizerConstants],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jj_consume_token(int kind), int jj_ntk(), org.apache.lucene.analysis.Token next(), void ReInit(CharStream stream), void ReInit(StandardTokenizerTokenManager tm), void StandardFilter(TokenStream in), void StandardTokenizer(CharStream stream), void StandardTokenizer(Reader reader), void StandardTokenizer(StandardTokenizerTokenManager tm), void disable_tracing(), void enable_tracing(), void jj_la1_0()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_135[...,...]
	->	->	->	->	->NODE_118[...,...]
	->	->NODE_138[[org.apache.lucene.analysis.standard.StandardTokenizerTokenManager, org.apache.lucene.queryParser.QueryParserTokenManager],[Token getNextToken(), Token jjFillToken(), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), int jjMoveNfa_0(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInitRounds(), void SwitchTo(int lexState), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void setDebugStream(java.io.PrintStream ds)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_139[[org.apache.lucene.analysis.standard.StandardTokenizerTokenManager],[Token getNextToken(), Token jjFillToken(), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), boolean jjCanMove_1(int hiByte, int i1, int i2, long l1, long l2), boolean jjCanMove_2(int hiByte, int i1, int i2, long l1, long l2), int jjMoveNfa_0(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInitRounds(), void StandardTokenizerTokenManager(CharStream stream), void StandardTokenizerTokenManager(CharStream stream, int lexState), void SwitchTo(int lexState), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void setDebugStream(java.io.PrintStream ds)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_135[...,...]
	->	->	->NODE_134[...,...]
	->	->	->NODE_140[[org.apache.lucene.queryParser.QueryParserTokenManager],[Token getNextToken(), Token jjFillToken(), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), int jjMoveNfa_0(int startState, int curPos), int jjMoveNfa_1(int startState, int curPos), int jjMoveNfa_2(int startState, int curPos), int jjMoveNfa_3(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), int jjMoveStringLiteralDfa0_1(), int jjMoveStringLiteralDfa0_2(), int jjMoveStringLiteralDfa0_3(), int jjMoveStringLiteralDfa1_1(long active0), int jjMoveStringLiteralDfa1_2(long active0), int jjStartNfaWithStates_1(int pos, int kind, int state), int jjStartNfaWithStates_2(int pos, int kind, int state), int jjStartNfaWithStates_3(int pos, int kind, int state), int jjStartNfa_1(int pos, long active0), int jjStartNfa_2(int pos, long active0), int jjStartNfa_3(int pos, long active0), int jjStopAtPos(int pos, int kind), int jjStopStringLiteralDfa_1(int pos, long active0), int jjStopStringLiteralDfa_2(int pos, long active0), int jjStopStringLiteralDfa_3(int pos, long active0), void QueryParserTokenManager(CharStream stream), void QueryParserTokenManager(CharStream stream, int lexState), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInitRounds(), void SwitchTo(int lexState), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void setDebugStream(java.io.PrintStream ds)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_43[...,...]
	->NODE_141[[org.apache.lucene.document.DateField],[Date stringToDate(String s), String MAX_DATE_STRING(), String MIN_DATE_STRING(), String dateToString(Date date), String timeToString(long time), long stringToTime(String s), void DateField()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_142[[org.apache.lucene.analysis.Analyzer, org.apache.lucene.analysis.PerFieldAnalyzerWrapper, org.apache.lucene.analysis.SimpleAnalyzer, org.apache.lucene.analysis.StopAnalyzer, org.apache.lucene.analysis.WhitespaceAnalyzer, org.apache.lucene.analysis.de.GermanAnalyzer, org.apache.lucene.analysis.ru.RussianAnalyzer, org.apache.lucene.analysis.standard.StandardAnalyzer],[TokenStream tokenStream(String fieldName, Reader reader)]]
	->ITS CHILDREN:=================
	->	->NODE_143[[org.apache.lucene.analysis.ru.RussianAnalyzer],[String[] makeStopWords(char[] charset), TokenStream tokenStream(String fieldName, Reader reader), void RussianAnalyzer(), void RussianAnalyzer(char[] charset), void RussianAnalyzer(char[] charset, Hashtable stopwords), void RussianAnalyzer(char[] charset, String[] stopwords)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_144[[org.apache.lucene.analysis.Analyzer],[String[] makeStopWords(char[] charset), TokenStream tokenStream(Reader reader), TokenStream tokenStream(String fieldName, Reader reader), void GermanAnalyzer(), void GermanAnalyzer(File stopwords), void GermanAnalyzer(Hashtable stopwords), void GermanAnalyzer(String[] stopwords), void PerFieldAnalyzerWrapper(Analyzer defaultAnalyzer), void RussianAnalyzer(), void RussianAnalyzer(char[] charset), void RussianAnalyzer(char[] charset, Hashtable stopwords), void RussianAnalyzer(char[] charset, String[] stopwords), void StandardAnalyzer(), void StandardAnalyzer(String[] stopWords), void StopAnalyzer(), void StopAnalyzer(String[] stopWords), void addAnalyzer(String fieldName, Analyzer analyzer), void setStemExclusionTable(File exclusionlist), void setStemExclusionTable(Hashtable exclusionlist), void setStemExclusionTable(String[] exclusionlist)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_145[[org.apache.lucene.analysis.PerFieldAnalyzerWrapper],[TokenStream tokenStream(String fieldName, Reader reader), void PerFieldAnalyzerWrapper(Analyzer defaultAnalyzer), void addAnalyzer(String fieldName, Analyzer analyzer)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_144[...,...]
	->	->NODE_146[[org.apache.lucene.analysis.de.GermanAnalyzer],[TokenStream tokenStream(String fieldName, Reader reader), void GermanAnalyzer(), void GermanAnalyzer(File stopwords), void GermanAnalyzer(Hashtable stopwords), void GermanAnalyzer(String[] stopwords), void setStemExclusionTable(File exclusionlist), void setStemExclusionTable(Hashtable exclusionlist), void setStemExclusionTable(String[] exclusionlist)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_144[...,...]
	->	->NODE_147[[org.apache.lucene.analysis.StopAnalyzer],[TokenStream tokenStream(String fieldName, Reader reader), void StopAnalyzer(), void StopAnalyzer(String[] stopWords)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_144[...,...]
	->	->NODE_148[[org.apache.lucene.analysis.standard.StandardAnalyzer],[TokenStream tokenStream(String fieldName, Reader reader), void StandardAnalyzer(), void StandardAnalyzer(String[] stopWords)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_144[...,...]
	->NODE_149[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.PhraseQuery, org.apache.lucene.search.Query, org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanQuery],[Weight createWeight(Searcher searcher)]]
	->ITS CHILDREN:=================
	->	->NODE_150[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.Query],[Query rewrite(IndexReader reader), Weight createWeight(Searcher searcher)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_151[[org.apache.lucene.search.FilteredQuery],[Query getQuery(), Query rewrite(IndexReader reader), String toString(String s), Weight createWeight(Searcher searcher), void FilteredQuery(Query query, Filter filter)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_14[...,...]
	->	->	->NODE_16[...,...]
	->	->NODE_15[...,...]
	->	->NODE_152[[org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.PhraseQuery, org.apache.lucene.search.spans.SpanQuery],[Weight createWeight(Searcher searcher), int getSlop()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_19[...,...]
	->	->	->NODE_153[[org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.PhraseQuery],[String toString(String f), Weight createWeight(Searcher searcher), int getSlop(), void add(Term term), void setSlop(int s)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_154[[org.apache.lucene.search.PhraseQuery],[String toString(String f), Term[] getTerms(), Weight createWeight(Searcher searcher), int getSlop(), void PhraseQuery(), void add(Term term), void setSlop(int s)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_14[...,...]
	->	->	->	->NODE_155[[org.apache.lucene.search.PhrasePrefixQuery],[String toString(String f), Weight createWeight(Searcher searcher), int getSlop(), void add(Term term), void add(Term[] terms), void setSlop(int s)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_14[...,...]
	->NODE_156[[org.apache.lucene.analysis.standard.TokenMgrError, org.apache.lucene.queryParser.TokenMgrError],[String LexicalError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar), String addEscapes(String str), void TokenMgrError(), void TokenMgrError(String message, int reason), void TokenMgrError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar, int reason)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_157[[org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.Weight, org.apache.lucene.search.spans.SpanWeight],[Query getQuery()]]
	->ITS CHILDREN:=================
	->	->NODE_151[...,...]
	->	->NODE_158[[org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.Weight, org.apache.lucene.search.spans.SpanWeight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_159[[org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.spans.SpanWeight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void normalize(float queryNorm)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_160[[org.apache.lucene.search.spans.SpanWeight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void SpanWeight(SpanQuery query, Searcher searcher), void normalize(float queryNorm)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_161[[org.apache.lucene.search.Weight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void BooleanWeight(Searcher searcher), void PhrasePrefixWeight(Searcher searcher), void PhraseWeight(Searcher searcher), void SpanWeight(SpanQuery query, Searcher searcher), void TermWeight(Searcher searcher), void normalize(float norm), void normalize(float queryNorm)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_2[...,...]
	->	->	->	->NODE_162[[org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void PhrasePrefixWeight(Searcher searcher), void normalize(float queryNorm)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_161[...,...]
	->	->	->	->NODE_163[[org.apache.lucene.search.PhraseQuery.PhraseWeight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void PhraseWeight(Searcher searcher), void normalize(float queryNorm)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_161[...,...]
	->	->	->	->NODE_164[[org.apache.lucene.search.TermQuery.TermWeight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void TermWeight(Searcher searcher), void normalize(float queryNorm)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_161[...,...]
	->	->	->NODE_165[[org.apache.lucene.search.BooleanQuery.BooleanWeight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void BooleanWeight(Searcher searcher), void normalize(float norm)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_161[...,...]
	->NODE_166[[org.apache.lucene.index.SegmentInfo],[void SegmentInfo(String name, int docCount, Directory dir)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_167[[org.apache.lucene.store.Lock],[boolean isLocked(), boolean obtain(), boolean obtain(long lockWaitTimeout), void release()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_168[[org.apache.lucene.index.FieldsReader, org.apache.lucene.search.Hits, org.apache.lucene.search.MultiSearcher],[Document doc(int n)]]
	->ITS CHILDREN:=================
	->	->NODE_85[...,...]
	->	->NODE_169[[org.apache.lucene.search.Hits],[Document doc(int n), HitDoc hitDoc(int n), float score(int n), int id(int n), int length(), void Hits(Searcher s, Query q, Filter f), void Hits(Searcher s, Query q, Filter f, Sort o), void addToFront(HitDoc hitDoc), void getMoreDocs(int min), void remove(HitDoc hitDoc)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_170[[org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.IndexReader, org.apache.lucene.index.MultiReader, org.apache.lucene.index.SegmentReader, org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable],[int maxDoc()]]
	->ITS CHILDREN:=================
	->	->NODE_52[...,...]
	->	->NODE_171[[org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.IndexReader, org.apache.lucene.index.MultiReader, org.apache.lucene.index.SegmentReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), int docFreq(Term t), int maxDoc(), int numDocs(), void doClose(), void doCommit(), void doUndeleteAll()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_172[[org.apache.lucene.index.IndexReader, org.apache.lucene.index.MultiReader, org.apache.lucene.index.SegmentReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), byte[] norms(String field), int docFreq(Term t), int maxDoc(), int numDocs(), void doClose(), void doCommit(), void doUndeleteAll()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_173[[org.apache.lucene.index.MultiReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermEnum terms(Term term), TermFreqVector getTermFreqVector(int n, String field), TermFreqVector[] getTermFreqVectors(int n), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), byte[] norms(String field), int docFreq(Term t), int maxDoc(), int numDocs(), int readerIndex(int n), void MultiReader(Directory directory, SegmentInfos sis, boolean closeDirectory, IndexReader[] subReaders), void MultiReader(IndexReader[] subReaders), void doClose(), void doCommit(), void doDelete(int n), void doSetNorm(int n, String field, byte value), void doUndeleteAll(), void initialize(IndexReader[] subReaders), void norms(String field, byte[] result, int offset)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_63[...,...]
	->	->	->	->NODE_174[[org.apache.lucene.index.SegmentReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermEnum terms(Term t), TermFreqVector getTermFreqVector(int docNumber, String field), TermFreqVector[] getTermFreqVectors(int docNumber), TermPositions termPositions(), Vector files(), boolean hasDeletions(), boolean hasDeletions(SegmentInfo si), boolean hasSeparateNorms(SegmentInfo si), boolean isDeleted(int n), boolean usesCompoundFile(SegmentInfo si), byte[] norms(String field), int docFreq(Term t), int maxDoc(), int numDocs(), void SegmentReader(SegmentInfo si), void SegmentReader(SegmentInfos sis, SegmentInfo si, boolean closeDir), void closeNorms(), void doClose(), void doCommit(), void doDelete(int docNum), void doSetNorm(int doc, String field, byte value), void doUndeleteAll(), void initialize(SegmentInfo si), void norms(String field, byte[] bytes, int offset), void openNorms(Directory cfsDir)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_63[...,...]
	->	->	->NODE_175[[org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.MultiReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), int docFreq(Term t), int maxDoc(), int numDocs(), void doClose(), void doCommit(), void doDelete(int n), void doUndeleteAll()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_173[...,...]
	->	->	->	->NODE_176[[org.apache.lucene.index.FilterIndexReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermEnum terms(Term t), TermFreqVector getTermFreqVector(int docNumber, String field), TermFreqVector[] getTermFreqVectors(int docNumber), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), byte[] norms(String f), int docFreq(Term t), int maxDoc(), int numDocs(), void FilterIndexReader(IndexReader in), void doClose(), void doCommit(), void doDelete(int n), void doSetNorm(int d, String f, byte b), void doUndeleteAll(), void norms(String f, byte[] bytes, int offset)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_63[...,...]
	->	->	->NODE_177[[org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.IndexReader, org.apache.lucene.index.SegmentReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermEnum terms(Term t), TermFreqVector getTermFreqVector(int docNumber, String field), TermFreqVector[] getTermFreqVectors(int docNumber), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), int docFreq(Term t), int maxDoc(), int numDocs(), void doClose(), void doCommit(), void doUndeleteAll()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_176[...,...]
	->	->	->	->NODE_174[...,...]
	->NODE_178[[org.apache.lucene.search.MultiSearcherThread],[IOException getIOException(), int hits(), void MultiSearcherThread(Searchable searchable, Query query, Filter filter, int nDocs, FieldDocSortedHitQueue hq, Sort sort, int i, int[] starts, String name), void MultiSearcherThread(Searchable searchable, Query query, Filter filter, int nDocs, HitQueue hq, int i, int[] starts, String name)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_179[[org.apache.lucene.analysis.Token],[String termText(), String type(), int endOffset(), int getPositionIncrement(), int startOffset(), void Token(String text, int start, int end), void Token(String text, int start, int end, String typ), void setPositionIncrement(int positionIncrement)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_180[[org.apache.lucene.search.FieldCache.StringIndex],[void StringIndex(int[] values, String[] lookup)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_181[[org.apache.lucene.index.TermVectorsWriter.TVField],[void TVField(int number)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_182[[org.apache.lucene.analysis.CharTokenizer, org.apache.lucene.analysis.LetterTokenizer, org.apache.lucene.analysis.WhitespaceTokenizer, org.apache.lucene.analysis.ru.RussianLetterTokenizer],[boolean isTokenChar(char c)]]
	->ITS CHILDREN:=================
	->	->NODE_183[[org.apache.lucene.analysis.LetterTokenizer],[boolean isTokenChar(char c), char normalize(char c), void LetterTokenizer(Reader in), void LowerCaseTokenizer(Reader in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_125[...,...]
	->	->NODE_184[[org.apache.lucene.analysis.ru.RussianLetterTokenizer],[boolean isTokenChar(char c), void RussianLetterTokenizer(Reader in, char[] charset)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_125[...,...]
	->	->NODE_185[[org.apache.lucene.analysis.WhitespaceTokenizer],[boolean isTokenChar(char c), void WhitespaceTokenizer(Reader in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_125[...,...]
	->NODE_186[[org.apache.lucene.index.Posting],[void Posting(Term t, int position)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_187[[org.apache.lucene.search.BooleanClause],[void BooleanClause(Query q, boolean r, boolean p)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_188[[org.apache.lucene.search.Sort],[void Sort(), void Sort(SortField field), void Sort(SortField[] fields), void Sort(String field), void Sort(String field, boolean reverse), void Sort(String[] fields), void setSort(SortField field), void setSort(SortField[] fields), void setSort(String field), void setSort(String field, boolean reverse), void setSort(String[] fieldnames)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_189[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermEnum, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.PhrasePositions, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.Spans],[boolean next()]]
	->ITS CHILDREN:=================
	->	->NODE_190[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhrasePositions, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.Spans],[boolean next(), boolean skipTo(int target)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_191[[org.apache.lucene.search.PhrasePositions],[boolean next(), boolean nextPosition(), boolean skipTo(int target), void PhrasePositions(TermPositions t, int o), void firstPosition()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_192[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.Spans],[boolean next(), boolean skipTo(int target), int doc()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_193[[org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.SpanScorer],[Explanation explain(int doc), boolean next(), boolean skipTo(int target), float score(), int doc()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_194[[org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer],[Explanation explain(int doc), boolean doNext(), boolean next(), boolean skipTo(int target), float score(), int doc(), void init()]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_195[[org.apache.lucene.search.ConjunctionScorer],[Explanation explain(int doc), Scorer first(), Scorer last(), boolean doNext(), boolean next(), boolean skipTo(int target), float score(), int doc(), void ConjunctionScorer(Similarity similarity), void add(Scorer scorer), void init(), void sortScorers()]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_39[...,...]
	->	->	->	->	->	->NODE_38[...,...]
	->	->	->	->	->NODE_196[[org.apache.lucene.search.spans.SpanScorer],[Explanation explain(int doc), boolean next(), boolean skipTo(int target), float score(), int doc(), void SpanScorer(Spans spans, Weight weight, Similarity similarity, byte[] norms)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_39[...,...]
	->	->	->	->	->NODE_197[[org.apache.lucene.search.TermScorer],[Explanation explain(int doc), boolean next(), boolean skipTo(int target), float score(), int doc(), void TermScorer(Weight weight, TermDocs td, Similarity similarity, byte[] norms)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_39[...,...]
	->	->	->	->	->NODE_198[[org.apache.lucene.search.BooleanScorer],[Explanation explain(int doc), boolean next(), boolean skipTo(int target), float score(), int doc(), void BooleanScorer(Similarity similarity), void add(Scorer scorer, boolean required, boolean prohibited), void computeCoordFactors()]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_39[...,...]
	->	->	->	->NODE_199[[org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.Spans],[boolean next(), boolean skipTo(int target), int doc(), int end(), int start()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_200[[org.apache.lucene.search.spans.NearSpans],[SpansCell min(), boolean atMatch(), boolean checkSlop(), boolean firstNonOrderedNextToPartialList(), boolean matchIsOrdered(), boolean next(), boolean skipTo(int target), int doc(), int end(), int start(), void NearSpans(SpanNearQuery query, IndexReader reader), void addToList(SpansCell cell), void firstToLast(), void initList(boolean next), void listToQueue(), void partialListToQueue(), void queueToList()]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_201[[org.apache.lucene.search.spans.Spans],[SpansCell min(), boolean atMatch(), boolean checkSlop(), boolean firstNonOrderedNextToPartialList(), boolean matchIsOrdered(), boolean next(), boolean skipTo(int target), int doc(), int end(), int start(), void NearSpans(SpanNearQuery query, IndexReader reader), void SpansCell(Spans spans, int index), void addToList(SpansCell cell), void firstToLast(), void initList(boolean next), void listToQueue(), void partialListToQueue(), void queueToList()]]
	->	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->	->NODE_2[...,...]
	->	->	->	->	->NODE_202[[org.apache.lucene.search.spans.NearSpans.SpansCell],[boolean next(), boolean skipTo(int target), int doc(), int end(), int start(), void SpansCell(Spans spans, int index)]]
	->	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->	->NODE_201[...,...]
	->	->	->	->NODE_203[[org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.spans.NearSpans],[boolean next(), boolean skipTo(int target), int doc(), void firstToLast()]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_200[...,...]
	->	->	->	->	->NODE_38[...,...]
	->	->	->	->NODE_104[...,...]
	->	->NODE_204[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.Spans],[boolean next(), int doc()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_103[...,...]
	->	->	->NODE_192[...,...]
	->	->NODE_86[...,...]
	->NODE_205[[org.apache.lucene.analysis.LowerCaseTokenizer],[char normalize(char c), void LowerCaseTokenizer(Reader in)]]
	->ITS CHILDREN:=================
	->	->NODE_183[...,...]
	->NODE_206[[org.apache.lucene.analysis.de.WordlistLoader],[HashSet getWordSet(File wordfile), Hashtable getWordtable(File wordfile), Hashtable getWordtable(String path, String wordfile), Hashtable getWordtable(String wordfile), Hashtable makeWordTable(HashSet wordSet)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_207[[org.apache.lucene.search.FieldCacheImpl],[Comparable[] getCustom(IndexReader reader, String field, SortComparator comparator), Object getAuto(IndexReader reader, String field), Object lookup(IndexReader reader, String field, Object comparer), Object lookup(IndexReader reader, String field, int type), Object store(IndexReader reader, String field, Object comparer, Object value), Object store(IndexReader reader, String field, int type, Object value), StringIndex getStringIndex(IndexReader reader, String field), String[] getStrings(IndexReader reader, String field), float[] getFloats(IndexReader reader, String field), int[] getInts(IndexReader reader, String field)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_208[[org.apache.lucene.analysis.ru.RussianStemmer],[String stem(String input), String stem(String theWord, char[] charset), boolean adjectival(StringBuffer stemmingZone), boolean derivational(StringBuffer stemmingZone), boolean findAndRemoveEnding(StringBuffer stemmingZone, char[][] theEndingClass), boolean findAndRemoveEnding(StringBuffer stemmingZone, char[][] theEndingClass, char[][] thePredessors), boolean isVowel(char letter), boolean noun(StringBuffer stemmingZone), boolean perfectiveGerund(StringBuffer stemmingZone), boolean reflexive(StringBuffer stemmingZone), boolean removeI(StringBuffer stemmingZone), boolean removeSoft(StringBuffer stemmingZone), boolean superlative(StringBuffer stemmingZone), boolean undoubleN(StringBuffer stemmingZone), boolean verb(StringBuffer stemmingZone), int findEnding(StringBuffer stemmingZone, char[][] theEndingClass), int findEnding(StringBuffer stemmingZone, int startIndex, char[][] theEndingClass), void RussianStemmer(), void RussianStemmer(char[] charset), void markPositions(String word), void setCharset(char[] newCharset), void setEndings()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_209[[org.apache.lucene.search.FuzzyQuery, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.WildcardQuery],[FilteredTermEnum getEnum(IndexReader reader)]]
	->ITS CHILDREN:=================
	->	->NODE_210[[org.apache.lucene.search.WildcardQuery],[FilteredTermEnum getEnum(IndexReader reader), void WildcardQuery(Term term)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_13[...,...]
	->	->NODE_12[...,...]
	->NODE_211[[org.apache.lucene.search.PhraseQueue, org.apache.lucene.search.spans.NearSpans.CellQueue, org.apache.lucene.search.spans.SpanOrQuery.SpanQueue],[boolean lessThan(Object o1, Object o2)]]
	->ITS CHILDREN:=================
	->	->NODE_212[[org.apache.lucene.search.spans.SpanOrQuery.SpanQueue],[boolean lessThan(Object o1, Object o2), void SpanQueue(int size)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->	->NODE_213[[org.apache.lucene.search.PhraseQueue],[boolean lessThan(Object o1, Object o2), void PhraseQueue(int size)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->	->NODE_214[[org.apache.lucene.search.spans.NearSpans.CellQueue],[boolean lessThan(Object o1, Object o2), void CellQueue(int size)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_6[...,...]
	->NODE_215[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery],[Query rewrite(IndexReader reader)]]
	->ITS CHILDREN:=================
	->	->NODE_150[...,...]
	->	->NODE_29[...,...]
	->NODE_216[[org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.Explanation, org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.Weight, org.apache.lucene.search.spans.SpanWeight],[float getValue()]]
	->ITS CHILDREN:=================
	->	->NODE_217[[org.apache.lucene.search.Explanation],[Explanation[] getDetails(), String getDescription(), String toHtml(), String toString(int depth), float getValue(), void Explanation(), void Explanation(float value, String description), void addDetail(Explanation detail), void setDescription(String description), void setValue(float value)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->	->NODE_158[...,...]
	->NODE_218[[org.apache.lucene.index.SegmentInfos],[SegmentInfo info(int i), long getVersion(), long readCurrentVersion(Directory directory), void read(Directory directory), void write(Directory directory)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_219[[org.apache.lucene.search.BooleanScorer.Collector],[void Collector(int mask, BucketTable bucketTable), void collect(int doc, float score)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_220[[org.apache.lucene.document.Document, org.apache.lucene.document.Field, org.apache.lucene.search.Query],[float getBoost()]]
	->ITS CHILDREN:=================
	->	->NODE_221[[org.apache.lucene.document.Document, org.apache.lucene.document.Field],[float getBoost(), void setBoost(float boost)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_222[[org.apache.lucene.document.Document],[Enumeration fields(), Field getField(String name), Field[] getFields(String name), String get(String name), String[] getValues(String name), float getBoost(), void Document(), void add(Field field), void removeField(String name), void removeFields(String name), void setBoost(float boost)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_223[[org.apache.lucene.document.Field],[Field Keyword(String name, Date value), Field Keyword(String name, String value), Field Text(String name, Reader value), Field Text(String name, Reader value, boolean storeTermVector), Field Text(String name, String value), Field Text(String name, String value, boolean storeTermVector), Field UnIndexed(String name, String value), Field UnStored(String name, String value), Field UnStored(String name, String value, boolean storeTermVector), Reader readerValue(), String name(), String stringValue(), boolean isIndexed(), boolean isStored(), boolean isTermVectorStored(), boolean isTokenized(), float getBoost(), void Field(String name, Reader reader), void Field(String name, String string, boolean store, boolean index, boolean token), void Field(String name, String string, boolean store, boolean index, boolean token, boolean storeTermVector), void setBoost(float boost)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_14[...,...]
	->NODE_224[[org.apache.lucene.index.TermInfo],[void TermInfo(), void TermInfo(TermInfo ti), void TermInfo(int df, long fp, long pp), void set(TermInfo ti), void set(int docFreq, long freqPointer, long proxPointer, int skipOffset)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_225[[org.apache.lucene.search.HitDoc],[void HitDoc(float s, int i)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_226[[org.apache.lucene.index.SegmentReader.Norm],[void Norm(InputStream in, int number), void reWrite()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_227[[org.apache.lucene.analysis.standard.FastCharStream, org.apache.lucene.queryParser.FastCharStream, org.apache.lucene.store.InputStream],[void refill()]]
	->ITS CHILDREN:=================
	->	->NODE_47[...,...]
	->	->NODE_228[[org.apache.lucene.analysis.standard.FastCharStream, org.apache.lucene.queryParser.FastCharStream],[String GetImage(), char BeginToken(), char readChar(), char[] GetSuffix(int len), int getBeginColumn(), int getBeginLine(), int getColumn(), int getEndColumn(), int getEndLine(), int getLine(), void Done(), void FastCharStream(Reader r), void backup(int amount), void refill()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_229[[org.apache.lucene.analysis.standard.StandardFilter, org.apache.lucene.analysis.standard.StandardTokenizer],[org.apache.lucene.analysis.Token next()]]
	->ITS CHILDREN:=================
	->	->NODE_230[[org.apache.lucene.analysis.standard.StandardFilter],[org.apache.lucene.analysis.Token next(), void StandardFilter(TokenStream in)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_137[...,...]
	->	->	->NODE_119[...,...]
	->	->NODE_136[...,...]
	->	->NODE_116[...,...]
	->NODE_231[[org.apache.lucene.index.IndexWriter, org.apache.lucene.search.Scorer, org.apache.lucene.search.Searcher],[Similarity getSimilarity()]]
	->ITS CHILDREN:=================
	->	->NODE_39[...,...]
	->	->NODE_72[...,...]
	->NODE_232[[org.apache.lucene.search.SortComparator],[Comparable getComparable(String termtext), ScoreDocComparator newComparator(IndexReader reader, String fieldname)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_233[[org.apache.lucene.index.FieldInfos, org.apache.lucene.index.FieldsReader, org.apache.lucene.index.MultipleTermPositions.IntQueue, org.apache.lucene.index.SegmentTermVector, org.apache.lucene.index.TermFreqVector, org.apache.lucene.index.TermVectorsReader, org.apache.lucene.search.BooleanScorer.BucketTable, org.apache.lucene.search.QueryTermVector, org.apache.lucene.util.BitVector, org.apache.lucene.util.PriorityQueue],[int size()]]
	->ITS CHILDREN:=================
	->	->NODE_234[[org.apache.lucene.search.BooleanScorer.BucketTable],[HitCollector newCollector(int mask), int size(), void BucketTable(BooleanScorer scorer)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->	->NODE_49[...,...]
	->	->NODE_235[[org.apache.lucene.index.SegmentTermVector, org.apache.lucene.index.TermFreqVector, org.apache.lucene.search.QueryTermVector],[String getField(), String[] getTerms(), int size(), int[] getTermFrequencies()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_236[[org.apache.lucene.search.QueryTermVector],[String getField(), String[] getTerms(), int indexOf(String term), int size(), int[] getTermFrequencies(), int[] indexesOf(String[] terms, int start, int len), void QueryTermVector(String queryString, Analyzer analyzer), void QueryTermVector(String[] queryTerms), void processTerms(String[] queryTerms)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_237[[org.apache.lucene.index.TermFreqVector],[String getField(), String[] getTerms(), int indexOf(String term), int indexOf(String termText), int size(), int[] getTermFrequencies(), int[] getTermPositions(int index), int[] indexesOf(String[] termNumbers, int start, int len), int[] indexesOf(String[] terms, int start, int len), void QueryTermVector(String queryString, Analyzer analyzer), void QueryTermVector(String[] queryTerms), void SegmentTermVector(String field, String[] terms, int[] termFreqs), void processTerms(String[] queryTerms)]]
	->	->	->	->ITS CHILDREN:=================
	->	->	->	->	->NODE_2[...,...]
	->	->	->NODE_238[[org.apache.lucene.index.SegmentTermVector],[String getField(), String[] getTerms(), int indexOf(String termText), int size(), int[] getTermFrequencies(), int[] indexesOf(String[] termNumbers, int start, int len), void SegmentTermVector(String field, String[] terms, int[] termFreqs)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_237[...,...]
	->	->NODE_239[[org.apache.lucene.index.FieldInfos, org.apache.lucene.util.BitVector],[int size(), void write(Directory d, String name)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_240[[org.apache.lucene.util.BitVector],[boolean get(int bit), int count(), int size(), void BitVector(Directory d, String name), void BitVector(int n), void clear(int bit), void set(int bit), void write(Directory d, String name)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_241[[org.apache.lucene.index.FieldInfos],[FieldInfo fieldInfo(String fieldName), FieldInfo fieldInfo(int fieldNumber), String fieldName(int fieldNumber), boolean hasVectors(), int fieldNumber(String fieldName), int size(), void FieldInfos(), void FieldInfos(Directory d, String name), void add(Collection names, boolean isIndexed), void add(Document doc), void add(String name, boolean isIndexed), void add(String name, boolean isIndexed, boolean storeTermVector), void addIndexed(Collection names, boolean storeTermVectors), void addInternal(String name, boolean isIndexed, boolean storeTermVector), void read(InputStream input), void write(Directory d, String name), void write(OutputStream output)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_242[[org.apache.lucene.index.MultipleTermPositions.IntQueue, org.apache.lucene.util.PriorityQueue],[int size(), void clear()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_243[[org.apache.lucene.index.MultipleTermPositions.IntQueue],[int next(), int size(), void add(int i), void clear(), void growArray(), void sort()]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->	->NODE_6[...,...]
	->NODE_244[[org.apache.lucene.search.ScoreDocComparator],[Comparable sortValue(ScoreDoc i), int compare(ScoreDoc i, ScoreDoc j), int sortType()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_245[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.ParallelMultiSearcher, org.apache.lucene.search.RemoteSearchable],[Query rewrite(Query original), int docFreq(Term term), void search(Query query, Filter filter, HitCollector results)]]
	->ITS CHILDREN:=================
	->	->NODE_53[...,...]
	->	->NODE_246[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.ParallelMultiSearcher],[Query rewrite(Query original), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), void search(Query query, Filter filter, HitCollector results)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_247[[org.apache.lucene.search.ParallelMultiSearcher],[Query rewrite(Query original), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), void ParallelMultiSearcher(Searchable[] searchables), void search(Query query, Filter filter, HitCollector results)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_55[...,...]
	->	->	->NODE_54[...,...]
	->NODE_248[[org.apache.lucene.index.TermPositionVector],[int[] getTermPositions(int index)]]
	->ITS CHILDREN:=================
	->	->NODE_237[...,...]
	->NODE_249[[org.apache.lucene.index.SegmentTermVector, org.apache.lucene.index.TermFreqVector, org.apache.lucene.search.QueryTermVector, org.apache.lucene.search.RangeQuery, org.apache.lucene.search.SortField, org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanQuery, org.apache.lucene.search.spans.SpanTermQuery],[String getField()]]
	->ITS CHILDREN:=================
	->	->NODE_235[...,...]
	->	->NODE_20[...,...]
	->	->NODE_250[[org.apache.lucene.search.SortField],[Locale getLocale(), SortComparatorSource getFactory(), String getField(), boolean getReverse(), int getType(), void SortField(String field), void SortField(String field, Locale locale), void SortField(String field, Locale locale, boolean reverse), void SortField(String field, SortComparatorSource comparator), void SortField(String field, SortComparatorSource comparator, boolean reverse), void SortField(String field, boolean reverse), void SortField(String field, int type), void SortField(String field, int type, boolean reverse)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_251[[org.apache.lucene.analysis.PorterStemmer, org.apache.lucene.queryParser.QueryParser, org.apache.lucene.search.RemoteSearchable],[void main(String[] args)]]
	->ITS CHILDREN:=================
	->	->NODE_42[...,...]
	->	->NODE_61[...,...]
	->	->NODE_252[[org.apache.lucene.analysis.PorterStemmer],[String stem(String s), boolean cons(int i), boolean cvc(int i), boolean doublec(int j), boolean ends(String s), boolean stem(), boolean stem(char[] word), boolean stem(char[] word, int wordLen), boolean stem(char[] wordBuffer, int offset, int wordLen), boolean stem(int i0), boolean vowelinstem(), char[] getResultBuffer(), int getResultLength(), int m(), void PorterStemmer(), void add(char ch), void main(String[] args), void r(String s), void reset(), void setto(String s), void step1(), void step2(), void step3(), void step4(), void step5(), void step6()]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_253[[org.apache.lucene.search.FieldDoc],[void FieldDoc(int doc, float score), void FieldDoc(int doc, float score, Comparable[] fields)]]
	->ITS CHILDREN:=================
	->	->NODE_254[[org.apache.lucene.search.ScoreDoc],[void FieldDoc(int doc, float score), void FieldDoc(int doc, float score, Comparable[] fields), void ScoreDoc(int doc, float score)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_255[[org.apache.lucene.search.DefaultSimilarity],[float coord(int overlap, int maxOverlap), float idf(int docFreq, int numDocs), float lengthNorm(String fieldName, int numTerms), float queryNorm(float sumOfSquaredWeights), float sloppyFreq(int distance), float tf(float freq)]]
	->ITS CHILDREN:=================
	->	->NODE_256[[org.apache.lucene.search.Similarity],[Similarity getDefault(), byte encodeNorm(float f), byte floatToByte(float f), float byteToFloat(byte b), float coord(int overlap, int maxOverlap), float decodeNorm(byte b), float idf(Collection terms, Searcher searcher), float idf(Term term, Searcher searcher), float idf(int docFreq, int numDocs), float lengthNorm(String fieldName, int numTerms), float lengthNorm(String fieldName, int numTokens), float queryNorm(float sumOfSquaredWeights), float sloppyFreq(int distance), float tf(float freq), float tf(int freq), void setDefault(Similarity similarity)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_257[[org.apache.lucene.queryParser.QueryParser, org.apache.lucene.search.SortField],[Locale getLocale()]]
	->ITS CHILDREN:=================
	->	->NODE_250[...,...]
	->	->NODE_42[...,...]
	->NODE_258[[org.apache.lucene.index.DocumentWriter],[Posting[] sortPostingTable(), void DocumentWriter(Directory directory, Analyzer analyzer, Similarity similarity, int maxFieldLength), void addDocument(String segment, Document doc), void addPosition(String field, String text, int position), void invertDocument(Document doc), void quickSort(Posting[] postings, int lo, int hi), void writeNorms(Document doc, String segment), void writePostings(Posting[] postings, String segment)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_259[[org.apache.lucene.store.FSInputStream.Descriptor],[void Descriptor(File file, String mode)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_260[[org.apache.lucene.index.FieldInfo],[void FieldInfo(String na, boolean tk, int nu, boolean storeTermVector)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_261[[org.apache.lucene.store.Lock.With],[Object doBody(), Object run(), void With(Lock lock), void With(Lock lock, long lockWaitTimeout)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_262[[org.apache.lucene.index.Term],[String field(), String text(), int compareTo(Object other), int compareTo(Term other), void Term(String fld, String txt), void Term(String fld, String txt, boolean intern), void readObject(java.io.ObjectInputStream in), void set(String fld, String txt)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_263[[org.apache.lucene.util.Constants],[void Constants()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_264[[org.apache.lucene.search.CachingWrapperFilter, org.apache.lucene.search.DateFilter, org.apache.lucene.search.Filter, org.apache.lucene.search.QueryFilter],[BitSet bits(IndexReader reader)]]
	->ITS CHILDREN:=================
	->	->NODE_265[[org.apache.lucene.search.QueryFilter],[BitSet bits(IndexReader reader), void QueryFilter(Query query)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_266[[org.apache.lucene.search.Filter],[BitSet bits(IndexReader reader), DateFilter After(String field, Date date), DateFilter After(String field, long time), DateFilter Before(String field, Date date), DateFilter Before(String field, long time), void CachingWrapperFilter(Filter filter), void DateFilter(String f), void DateFilter(String f, Date from, Date to), void DateFilter(String f, long from, long to), void QueryFilter(Query query)]]
	->	->	->ITS CHILDREN:=================
	->	->	->	->NODE_2[...,...]
	->	->NODE_267[[org.apache.lucene.search.CachingWrapperFilter],[BitSet bits(IndexReader reader), void CachingWrapperFilter(Filter filter)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_266[...,...]
	->	->NODE_268[[org.apache.lucene.search.DateFilter],[BitSet bits(IndexReader reader), DateFilter After(String field, Date date), DateFilter After(String field, long time), DateFilter Before(String field, Date date), DateFilter Before(String field, long time), void DateFilter(String f), void DateFilter(String f, Date from, Date to), void DateFilter(String f, long from, long to)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_266[...,...]
	->NODE_269[[org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.PhraseQuery, org.apache.lucene.search.spans.SpanNearQuery],[int getSlop()]]
	->ITS CHILDREN:=================
	->	->NODE_25[...,...]
	->	->NODE_152[...,...]
	->NODE_270[[org.apache.lucene.search.TopFieldDocs],[void TopFieldDocs(int totalHits, ScoreDoc[] scoreDocs, SortField[] fields)]]
	->ITS CHILDREN:=================
	->	->NODE_271[[org.apache.lucene.search.TopDocs],[void TopDocs(int totalHits, ScoreDoc[] scoreDocs), void TopFieldDocs(int totalHits, ScoreDoc[] scoreDocs, SortField[] fields)]]
	->	->ITS CHILDREN:=================
	->	->	->NODE_2[...,...]
	->NODE_272[[org.apache.lucene.util.StringHelper],[int stringDifference(String s1, String s2), void StringHelper()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_273[[org.apache.lucene.index.SegmentMerger],[IndexReader segmentReader(int i), int appendPostings(SegmentMergeInfo[] smis, int n), int merge(), int mergeFields(), long writeSkip(), void SegmentMerger(Directory dir, String name, boolean compoundFile), void add(IndexReader reader), void bufferSkip(int doc), void closeReaders(), void createCompoundFile(), void mergeNorms(), void mergeTermInfo(SegmentMergeInfo[] smis, int n), void mergeTermInfos(), void mergeTerms(), void mergeVectors(), void resetSkip()]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_274[[org.apache.lucene.analysis.PorterStemmer, org.apache.lucene.store.RAMOutputStream],[void reset()]]
	->ITS CHILDREN:=================
	->	->NODE_69[...,...]
	->	->NODE_252[...,...]
	->NODE_275[[org.apache.lucene.search.FieldCacheImpl.Entry],[void Entry(IndexReader reader, String field, Object custom), void Entry(IndexReader reader, String field, int type)]]
	->ITS CHILDREN:=================
	->	->NODE_2[...,...]
	->NODE_276[[org.apache.lucene.index.MultipleTermPositions.IntQueue, org.apache.lucene.search.PhraseScorer],[void sort()]]
	->ITS CHILDREN:=================
	->	->NODE_243[...,...]
	->	->NODE_38[...,...]
Done printing lattice!
Printing candidate nodes
	->NODE_0[[org.apache.lucene.index.MultipleTermPositions.TermPositionsQueue, org.apache.lucene.index.SegmentMergeQueue, org.apache.lucene.search.FieldDocSortedHitQueue, org.apache.lucene.search.FieldSortedHitQueue, org.apache.lucene.search.HitQueue, org.apache.lucene.util.PriorityQueue],[boolean lessThan(Object a, Object b)]]
	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.util.PriorityQueue]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.09090909 ]##
	  	->NODE_1[[org.apache.lucene.search.FieldDocSortedHitQueue, org.apache.lucene.search.FieldSortedHitQueue],[SortField[] getFields(), boolean lessThan(Object a, Object b)]]
	  	  FEATURE TYPE:  ## ADHOC
	->NODE_2[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.FuzzyQuery, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery, org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanTermQuery],[String toString(String field)]]
	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.Query]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.11111111 ]## ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.MultiTermQuery]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.16666667 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.5 ]; RELATED TYPES: [org.apache.lucene.search.FuzzyQuery]
	  	->NODE_3[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.Query, org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanQuery],[String toString(String field), Weight createWeight(Searcher searcher)]]
	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.Query]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.22222222 ]##
	  	  	->NODE_4[[org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanQuery],[String toString(String field), Term getTerm(), Weight createWeight(Searcher searcher)]]
	  	  	  FEATURE TYPE:  ## ADHOC
	  	->NODE_5[[org.apache.lucene.search.RangeQuery, org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanTermQuery],[String getField(), String toString(String field)]]
	  	  FEATURE TYPE:  ## ADHOC
	  	  	->NODE_6[[org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanTermQuery],[Collection getTerms(), Spans getSpans(IndexReader reader), String getField(), String toString(String field)]]
	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	  	->NODE_7[[org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanOrQuery],[Collection getTerms(), SpanQuery[] getClauses(), Spans getSpans(IndexReader reader), String getField(), String toString(String field)]]
	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	->NODE_8[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery],[Query rewrite(IndexReader reader), String toString(String field)]]
	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.Query]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.22222222 ]##
	  	  	->NODE_9[[org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery],[Query combine(Query[] queries), Query rewrite(IndexReader reader), String toString(String field)]]
	  	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.Query]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.33333334 ]##
	  	->NODE_10[[org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanTermQuery],[String toString(String field), Term getTerm()]]
	  	  FEATURE TYPE:  ## ADHOC
	  	  	->NODE_4[...,...]
	->NODE_11[[org.apache.lucene.analysis.standard.ParseException, org.apache.lucene.queryParser.ParseException],[String add_escapes(String str), void ParseException(), void ParseException(String message), void ParseException(Token currentTokenVal, int[][] expectedTokenSequencesVal, String[] tokenImageVal)]]
	  FEATURE TYPE:  ## ADHOC
	->NODE_12[[org.apache.lucene.search.ExactPhraseScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.SloppyPhraseScorer],[float phraseFreq()]]
	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.PhraseScorer]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.083333336 ]##
	->NODE_13[[org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.Tokenizer, org.apache.lucene.index.CompoundFileReader, org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.index.CompoundFileWriter, org.apache.lucene.index.FieldsReader, org.apache.lucene.index.FieldsWriter, org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.IndexReader, org.apache.lucene.index.IndexWriter, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.index.SegmentMergeQueue, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermEnum, org.apache.lucene.index.TermInfosReader, org.apache.lucene.index.TermInfosWriter, org.apache.lucene.index.TermVectorsReader, org.apache.lucene.index.TermVectorsWriter, org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.FuzzyTermEnum, org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable, org.apache.lucene.search.WildcardTermEnum, org.apache.lucene.store.Directory, org.apache.lucene.store.FSDirectory, org.apache.lucene.store.FSInputStream, org.apache.lucene.store.FSOutputStream, org.apache.lucene.store.InputStream, org.apache.lucene.store.OutputStream, org.apache.lucene.store.RAMDirectory, org.apache.lucene.store.RAMInputStream, org.apache.lucene.store.RAMOutputStream],[void close()]]
	  FEATURE TYPE:  ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.search.Searchable]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.11111111 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.2 ]; RELATED TYPES: [org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.index.TermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.125 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.33333334 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermPositions] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.store.InputStream]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.06666667 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.store.FSInputStream, org.apache.lucene.store.RAMInputStream] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.index.SegmentTermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.083333336 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.16666667 ]; RELATED TYPES: [org.apache.lucene.index.SegmentTermPositions] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.store.OutputStream]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.071428575 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.33333334 ]; RELATED TYPES: [org.apache.lucene.store.FSOutputStream, org.apache.lucene.store.RAMOutputStream] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.FilteredTermEnum]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.11111111 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.25 ]; RELATED TYPES: [org.apache.lucene.search.FuzzyTermEnum, org.apache.lucene.search.WildcardTermEnum] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.analysis.TokenStream]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.5 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.5 ]; RELATED TYPES: [org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.Tokenizer] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.index.TermEnum]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.2 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.FuzzyTermEnum, org.apache.lucene.search.WildcardTermEnum] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.store.Directory]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.09090909 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.1 ]; RELATED TYPES: [org.apache.lucene.index.CompoundFileReader, org.apache.lucene.store.FSDirectory, org.apache.lucene.store.RAMDirectory] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.SegmentTermEnum]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.083333336 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.TermInfosReader] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.TermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.125 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.14285715 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.IndexReader]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.019607844 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.search.IndexSearcher] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.Searchable]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.11111111 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.125 ]; RELATED TYPES: [org.apache.lucene.search.RemoteSearchable] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.store.OutputStream]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.071428575 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.FieldsWriter, org.apache.lucene.index.TermInfosWriter, org.apache.lucene.index.TermVectorsWriter] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.store.InputStream]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.06666667 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.CompoundFileReader, org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.index.FieldsReader, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermVectorsReader] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.store.Directory]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.09090909 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.CompoundFileReader, org.apache.lucene.index.CompoundFileWriter, org.apache.lucene.index.IndexReader, org.apache.lucene.index.IndexWriter, org.apache.lucene.index.TermInfosReader] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.TermInfosWriter]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.16666667 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.16666667 ]; RELATED TYPES: [org.apache.lucene.index.TermInfosWriter] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.SegmentMergeQueue]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.33333334 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.MultiTermEnum] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.analysis.TokenStream]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.5 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.5 ]; RELATED TYPES: [org.apache.lucene.analysis.TokenFilter] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.TermEnum]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.2 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.5 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.search.FilteredTermEnum]
	  	->NODE_14[[org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.store.FSInputStream],[void close(), void readInternal(byte[] b, int offset, int len)]]
	  	  FEATURE TYPE:  ## ADHOC
	  	->NODE_15[[org.apache.lucene.index.FieldsReader, org.apache.lucene.index.TermVectorsReader, org.apache.lucene.util.PriorityQueue],[int size(), void close()]]
	  	  FEATURE TYPE:  ## ADHOC
	  	->NODE_16[[org.apache.lucene.index.IndexReader, org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable],[int maxDoc(), void close()]]
	  	  FEATURE TYPE:  ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.search.Searchable]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.22222222 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.4 ]; RELATED TYPES: [org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.IndexReader]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.039215688 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.search.IndexSearcher] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.Searchable]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.22222222 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.25 ]; RELATED TYPES: [org.apache.lucene.search.RemoteSearchable]
	  	  	->NODE_17[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable],[Explanation explain(Query query, int doc), Query rewrite(Query original), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results)]]
	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	  	->NODE_18[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher],[Explanation explain(Query query, int doc), Query rewrite(Query original), TopDocs search(Query query, Filter filter, int nDocs), TopFieldDocs search(Query query, Filter filter, int nDocs, Sort sort), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results)]]
	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	  	->	->NODE_19[[org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searcher],[Document doc(int i), Explanation explain(Query query, int doc), Query rewrite(Query original), TopFieldDocs search(Query query, Filter filter, int n, Sort sort), int docFreq(Term term), int maxDoc(), void close(), void search(Query query, Filter filter, HitCollector results)]]
	  	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	  	->	->NODE_19[...,...]
	  	->NODE_20[[org.apache.lucene.store.FSOutputStream, org.apache.lucene.store.InputStream, org.apache.lucene.store.OutputStream, org.apache.lucene.store.RAMOutputStream],[long length(), void close(), void seek(long pos)]]
	  	  FEATURE TYPE:  ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.store.OutputStream]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.21428572 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.store.FSOutputStream, org.apache.lucene.store.RAMOutputStream]
	  	  	->NODE_21[[org.apache.lucene.store.InputStream, org.apache.lucene.store.OutputStream],[long getFilePointer(), long length(), void close(), void seek(long pos)]]
	  	  	  FEATURE TYPE:  ## ADHOC
	  	->NODE_22[[org.apache.lucene.index.CompoundFileReader.CSInputStream, org.apache.lucene.store.InputStream, org.apache.lucene.store.RAMInputStream],[void close(), void seekInternal(long pos)]]
	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.store.InputStream]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.13333334 ]## ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.store.InputStream]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.13333334 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.CompoundFileReader.CSInputStream]
	  	->NODE_23[[org.apache.lucene.index.IndexWriter, org.apache.lucene.search.Searcher],[Similarity getSimilarity(), void close(), void setSimilarity(Similarity similarity)]]
	  	  FEATURE TYPE:  ## ADHOC
	  	->NODE_24[[org.apache.lucene.index.CompoundFileReader, org.apache.lucene.index.CompoundFileWriter],[Directory getDirectory(), String getName(), void close()]]
	  	  FEATURE TYPE:  ## ADHOC
	  	->NODE_25[[org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.FuzzyTermEnum, org.apache.lucene.search.WildcardTermEnum],[boolean endEnum(), boolean termCompare(Term term), float difference(), void close()]]
	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.FilteredTermEnum]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.44444445 ]##
	  	->NODE_26[[org.apache.lucene.index.FieldsReader, org.apache.lucene.search.MultiSearcher],[Document doc(int n), void close()]]
	  	  FEATURE TYPE:  ## ADHOC
	  	->NODE_27[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermEnum, org.apache.lucene.search.FilteredTermEnum],[boolean next(), void close()]]
	  	  FEATURE TYPE:  ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.index.TermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.25 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.6666667 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermPositions] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.index.SegmentTermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.16666667 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.33333334 ]; RELATED TYPES: [org.apache.lucene.index.SegmentTermPositions] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.index.TermEnum]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.4 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.5 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.search.FilteredTermEnum] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.TermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.25 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.2857143 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.TermEnum]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.4 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.search.FilteredTermEnum]
	  	  	->	->NODE_28[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermPositions],[boolean next(), int nextPosition(), int read(int[] docs, int[] freqs), void close()]]
	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	  	  	->	->NODE_29[[org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermPositions],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void SegmentTermPositions(SegmentReader p), void close(), void seek(TermEnum termEnum), void seek(TermInfo ti), void skipProx(long proxPointer), void skippingDoc()]]
	  	  	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	  	  	->NODE_30[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermPositions],[boolean next(), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void close(), void seek(TermEnum termEnum)]]
	  	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	  	  	  	->NODE_31[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.TermPositions],[boolean next(), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void FilterTermPositions(TermPositions in), void close(), void seek(TermEnum termEnum)]]
	  	  	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	  	  	  	->NODE_32[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs],[boolean next(), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void close(), void seek(Term term), void seek(TermEnum termEnum)]]
	  	  	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	  	  	  	  	->NODE_33[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void close(), void seek(Term term), void seek(TermEnum termEnum)]]
	  	  	  	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	  	  	  	->NODE_34[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermPositions],[boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void close(), void seek(TermEnum termEnum)]]
	  	  	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	  	  	  	  	->NODE_29[...,...]
	  	  	  	  	  	  	->NODE_35[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.TermPositions],[TermDocs termDocs(IndexReader reader), boolean next(), boolean skipTo(int target), int doc(), int freq(), int nextPosition(), int read(int[] docs, int[] freqs), void MultiTermPositions(IndexReader[] r, int[] s), void close(), void seek(TermEnum termEnum)]]
	  	  	  	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	  	  	  	  	->NODE_33[...,...]
	  	  	->	->	->	->NODE_34[...,...]
	  	  	->	->	->NODE_30[...,...]
	  	  	->NODE_36[[org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.TermEnum, org.apache.lucene.search.FilteredTermEnum],[Term term(), boolean next(), int docFreq(), void close()]]
	  	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.index.TermEnum]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.8 ]## ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.TermEnum]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.8 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.search.FilteredTermEnum]
	  	->NODE_37[[org.apache.lucene.index.FieldsWriter, org.apache.lucene.index.IndexWriter],[void addDocument(Document doc), void close()]]
	  	  FEATURE TYPE:  ## ADHOC
	  	->NODE_38[[org.apache.lucene.index.CompoundFileReader, org.apache.lucene.store.Directory, org.apache.lucene.store.FSDirectory, org.apache.lucene.store.RAMDirectory],[Lock makeLock(String name), OutputStream createFile(String name), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(String name), void close(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.store.Directory]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.90909094 ]## ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.store.Directory]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.90909094 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.CompoundFileReader]
	  	  	->NODE_39[[org.apache.lucene.store.Directory, org.apache.lucene.store.FSDirectory, org.apache.lucene.store.RAMDirectory],[InputStream openFile(String name), Lock makeLock(String name), OutputStream createFile(String name), String[] list(), boolean fileExists(String name), long fileLength(String name), long fileModified(String name), void close(), void deleteFile(String name), void renameFile(String from, String to), void touchFile(String name)]]
	  	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.store.Directory]; ANCHOR TYPE BEHAVIOR COVERAGE: [1.0 ]##
	  	->NODE_40[[org.apache.lucene.analysis.TokenFilter, org.apache.lucene.analysis.Tokenizer],[Token next(), org.apache.lucene.analysis.Token next(), void close()]]
	  	  FEATURE TYPE:  ## ADHOC
	->NODE_41[[org.apache.lucene.analysis.CharTokenizer, org.apache.lucene.analysis.LowerCaseFilter, org.apache.lucene.analysis.PorterStemFilter, org.apache.lucene.analysis.StopFilter, org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.de.GermanStemFilter, org.apache.lucene.analysis.ru.RussianLowerCaseFilter, org.apache.lucene.analysis.ru.RussianStemFilter],[Token next()]]
	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.analysis.TokenStream]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.5 ]##
	  	->NODE_40[...,...]
	->NODE_42[[org.apache.lucene.analysis.standard.Token, org.apache.lucene.queryParser.Token],[Token newToken(int ofKind)]]
	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.queryParser.Token]; ANCHOR TYPE BEHAVIOR COVERAGE: [1.0 ]##FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.analysis.standard.Token]; ANCHOR TYPE BEHAVIOR COVERAGE: [1.0 ]##
	->NODE_43[[org.apache.lucene.index.FilterIndexReader.FilterTermPositions, org.apache.lucene.index.MultiTermPositions, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermPositions],[int nextPosition()]]
	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.index.TermPositions]; ANCHOR TYPE BEHAVIOR COVERAGE: [1.0 ]##
	  	->	->NODE_35[...,...]
	  	->	->NODE_31[...,...]
	->NODE_44[[org.apache.lucene.analysis.standard.StandardTokenizer, org.apache.lucene.analysis.standard.StandardTokenizerTokenManager, org.apache.lucene.queryParser.QueryParser, org.apache.lucene.queryParser.QueryParserTokenManager],[Token getNextToken(), void ReInit(CharStream stream)]]
	  FEATURE TYPE:  ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.analysis.standard.StandardTokenizerTokenManager]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.10526316 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.analysis.standard.StandardTokenizer] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.queryParser.QueryParserTokenManager]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.057142857 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.queryParser.QueryParser]
	  	->	->NODE_45[[org.apache.lucene.analysis.standard.StandardTokenizerConstants, org.apache.lucene.queryParser.QueryParserConstants],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jjFillToken(), Token jj_consume_token(int kind), boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2), int jjMoveNfa_0(int startState, int curPos), int jjMoveStringLiteralDfa0_0(), int jj_ntk(), void ReInit(CharStream stream), void ReInit(CharStream stream, int lexState), void ReInitRounds(), void SwitchTo(int lexState), void disable_tracing(), void enable_tracing(), void jjAddStates(int start, int end), void jjCheckNAdd(int state), void jjCheckNAddStates(int start), void jjCheckNAddStates(int start, int end), void jjCheckNAddTwoStates(int state1, int state2), void jj_la1_0(), void setDebugStream(java.io.PrintStream ds)]]
	  	  	  FEATURE TYPE:  ## ADHOC
	  	->	->	->NODE_46[[org.apache.lucene.analysis.TokenStream, org.apache.lucene.analysis.standard.StandardTokenizerConstants],[ParseException generateParseException(), Token getNextToken(), Token getToken(int index), Token jj_consume_token(int kind), int jj_ntk(), org.apache.lucene.analysis.Token next(), void ReInit(CharStream stream), void ReInit(StandardTokenizerTokenManager tm), void StandardFilter(TokenStream in), void StandardTokenizer(CharStream stream), void StandardTokenizer(Reader reader), void StandardTokenizer(StandardTokenizerTokenManager tm), void disable_tracing(), void enable_tracing(), void jj_la1_0()]]
	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	->	->NODE_45[...,...]
	->NODE_47[[org.apache.lucene.analysis.Analyzer, org.apache.lucene.analysis.PerFieldAnalyzerWrapper, org.apache.lucene.analysis.SimpleAnalyzer, org.apache.lucene.analysis.StopAnalyzer, org.apache.lucene.analysis.WhitespaceAnalyzer, org.apache.lucene.analysis.de.GermanAnalyzer, org.apache.lucene.analysis.ru.RussianAnalyzer, org.apache.lucene.analysis.standard.StandardAnalyzer],[TokenStream tokenStream(String fieldName, Reader reader)]]
	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.analysis.Analyzer]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.5 ]## ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.analysis.Analyzer]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.5 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.analysis.PerFieldAnalyzerWrapper]
	->NODE_48[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.PhraseQuery, org.apache.lucene.search.Query, org.apache.lucene.search.TermQuery, org.apache.lucene.search.spans.SpanQuery],[Weight createWeight(Searcher searcher)]]
	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.Query]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.11111111 ]## ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.Query]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.11111111 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.5 ]; RELATED TYPES: [org.apache.lucene.search.FilteredQuery]
	  	->NODE_49[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.Query],[Query rewrite(IndexReader reader), Weight createWeight(Searcher searcher)]]
	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.Query]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.22222222 ]## ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.Query]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.22222222 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.search.FilteredQuery]
	  	->NODE_3[...,...]
	  	->NODE_50[[org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.PhraseQuery, org.apache.lucene.search.spans.SpanQuery],[Weight createWeight(Searcher searcher), int getSlop()]]
	  	  FEATURE TYPE:  ## ADHOC
	  	  	->NODE_51[[org.apache.lucene.search.PhrasePrefixQuery, org.apache.lucene.search.PhraseQuery],[String toString(String f), Weight createWeight(Searcher searcher), int getSlop(), void add(Term term), void setSlop(int s)]]
	  	  	  FEATURE TYPE:  ## ADHOC
	->NODE_52[[org.apache.lucene.analysis.standard.TokenMgrError, org.apache.lucene.queryParser.TokenMgrError],[String LexicalError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar), String addEscapes(String str), void TokenMgrError(), void TokenMgrError(String message, int reason), void TokenMgrError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar, int reason)]]
	  FEATURE TYPE:  ## ADHOC
	->NODE_53[[org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.Weight, org.apache.lucene.search.spans.SpanWeight],[Query getQuery()]]
	  FEATURE TYPE:  ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.search.Weight]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.16666667 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.2 ]; RELATED TYPES: [org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.spans.SpanWeight]
	  	->NODE_54[[org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.Weight, org.apache.lucene.search.spans.SpanWeight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights()]]
	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.search.Weight]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.8333333 ]##
	  	  	->NODE_55[[org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.spans.SpanWeight],[Explanation explain(IndexReader reader, int doc), Query getQuery(), Scorer scorer(IndexReader reader), float getValue(), float sumOfSquaredWeights(), void normalize(float queryNorm)]]
	  	  	  FEATURE TYPE:  ## ADHOC
	->NODE_56[[org.apache.lucene.index.FieldsReader, org.apache.lucene.search.Hits, org.apache.lucene.search.MultiSearcher],[Document doc(int n)]]
	  FEATURE TYPE:  ## ADHOC
	  	->NODE_26[...,...]
	->NODE_57[[org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.IndexReader, org.apache.lucene.index.MultiReader, org.apache.lucene.index.SegmentReader, org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable, org.apache.lucene.search.Searchable],[int maxDoc()]]
	  FEATURE TYPE:  ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.search.Searchable]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.11111111 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.2 ]; RELATED TYPES: [org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.RemoteSearchable] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.index.IndexReader]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.019607844 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.06666667 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.MultiReader, org.apache.lucene.index.SegmentReader] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.IndexReader]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.019607844 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader, org.apache.lucene.search.IndexSearcher] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.Searchable]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.11111111 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.125 ]; RELATED TYPES: [org.apache.lucene.search.RemoteSearchable]
	  	->NODE_16[...,...]
	  	->NODE_58[[org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.IndexReader, org.apache.lucene.index.MultiReader, org.apache.lucene.index.SegmentReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), int docFreq(Term t), int maxDoc(), int numDocs(), void doClose(), void doCommit(), void doUndeleteAll()]]
	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.index.IndexReader]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.29411766 ]## ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.IndexReader]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.29411766 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.8333333 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader]
	  	  	->NODE_59[[org.apache.lucene.index.IndexReader, org.apache.lucene.index.MultiReader, org.apache.lucene.index.SegmentReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), byte[] norms(String field), int docFreq(Term t), int maxDoc(), int numDocs(), void doClose(), void doCommit(), void doUndeleteAll()]]
	  	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.index.IndexReader]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.3137255 ]##
	  	  	->NODE_60[[org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.MultiReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), int docFreq(Term t), int maxDoc(), int numDocs(), void doClose(), void doCommit(), void doDelete(int n), void doUndeleteAll()]]
	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	->NODE_61[[org.apache.lucene.index.FilterIndexReader, org.apache.lucene.index.IndexReader, org.apache.lucene.index.SegmentReader],[Collection getFieldNames(), Collection getFieldNames(boolean indexed), Collection getIndexedFieldNames(boolean storedTermVector), Document document(int n), TermDocs termDocs(), TermEnum terms(), TermEnum terms(Term t), TermFreqVector getTermFreqVector(int docNumber, String field), TermFreqVector[] getTermFreqVectors(int docNumber), TermPositions termPositions(), boolean hasDeletions(), boolean isDeleted(int n), int docFreq(Term t), int maxDoc(), int numDocs(), void doClose(), void doCommit(), void doUndeleteAll()]]
	  	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.index.IndexReader]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.3529412 ]## ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.IndexReader]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.3529412 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader]
	->NODE_62[[org.apache.lucene.analysis.CharTokenizer, org.apache.lucene.analysis.LetterTokenizer, org.apache.lucene.analysis.WhitespaceTokenizer, org.apache.lucene.analysis.ru.RussianLetterTokenizer],[boolean isTokenChar(char c)]]
	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.analysis.CharTokenizer]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.25 ]##
	->NODE_63[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.index.SegmentTermPositions, org.apache.lucene.index.TermDocs, org.apache.lucene.index.TermEnum, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.FilteredTermEnum, org.apache.lucene.search.PhrasePositions, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.Spans],[boolean next()]]
	  FEATURE TYPE:  ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.index.TermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.125 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.33333334 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.SegmentTermPositions] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.search.spans.Spans]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.2 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.2 ]; RELATED TYPES: [org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.index.SegmentTermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.083333336 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.16666667 ]; RELATED TYPES: [org.apache.lucene.index.SegmentTermPositions] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.Scorer]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.125 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.2 ]; RELATED TYPES: [org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.SpanScorer] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.index.TermEnum]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.2 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.25 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.MultiTermEnum, org.apache.lucene.index.SegmentTermEnum, org.apache.lucene.search.FilteredTermEnum] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.TermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.125 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.5 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.search.TermScorer] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.spans.NearSpans.SpansCell]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.16666667 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.2 ]; RELATED TYPES: [org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.spans.Spans]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.2 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.33333334 ]; RELATED TYPES: [org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.PhrasePositions]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.2 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.5 ]; RELATED TYPES: [org.apache.lucene.search.PhrasePositions, org.apache.lucene.search.PhraseScorer] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.TermEnum]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.2 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.5 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermEnum, org.apache.lucene.index.SegmentMergeInfo, org.apache.lucene.search.FilteredTermEnum]
	  	->NODE_64[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhrasePositions, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.Spans],[boolean next(), boolean skipTo(int target)]]
	  	  FEATURE TYPE:  ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.index.TermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.25 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.25 ]; RELATED TYPES: [org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.search.spans.Spans]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.4 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.4 ]; RELATED TYPES: [org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.Scorer]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.25 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.4 ]; RELATED TYPES: [org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.SpanScorer] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.TermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.25 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.6666667 ]; RELATED TYPES: [org.apache.lucene.index.MultiTermDocs, org.apache.lucene.search.TermScorer] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.spans.NearSpans.SpansCell]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.33333334 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.4 ]; RELATED TYPES: [org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.spans.Spans]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.4 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.6666667 ]; RELATED TYPES: [org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.PhrasePositions]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.4 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.search.PhrasePositions, org.apache.lucene.search.PhraseScorer]
	  	  	->NODE_65[[org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.Spans],[boolean next(), boolean skipTo(int target), int doc()]]
	  	  	  FEATURE TYPE:  ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.index.TermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.375 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.375 ]; RELATED TYPES: [org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.search.spans.Spans]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.6 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.6 ]; RELATED TYPES: [org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.Scorer]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.375 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.6 ]; RELATED TYPES: [org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.SpanScorer] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.TermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.375 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.MultiTermDocs, org.apache.lucene.search.TermScorer] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.spans.NearSpans.SpansCell]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.5 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.6 ]; RELATED TYPES: [org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.spans.Spans]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.6 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer]
	  	  	  	->NODE_66[[org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.SpanScorer],[Explanation explain(int doc), boolean next(), boolean skipTo(int target), float score(), int doc()]]
	  	  	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.Scorer]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.625 ]##
	  	  	  	  	->NODE_67[[org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer],[Explanation explain(int doc), boolean doNext(), boolean next(), boolean skipTo(int target), float score(), int doc(), void init()]]
	  	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	  	  	->NODE_68[[org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.Spans],[boolean next(), boolean skipTo(int target), int doc(), int end(), int start()]]
	  	  	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.spans.NearSpans.SpansCell]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.8333333 ]##FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.search.spans.Spans]; ANCHOR TYPE BEHAVIOR COVERAGE: [1.0 ]## ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.spans.Spans]; ANCHOR TYPE BEHAVIOR COVERAGE: [1.0 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.search.spans.NearSpans.SpansCell]
	  	  	  	->NODE_69[[org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.spans.NearSpans],[boolean next(), boolean skipTo(int target), int doc(), void firstToLast()]]
	  	  	  	  FEATURE TYPE:  ## ADHOC
	  	->NODE_70[[org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.MultipleTermPositions, org.apache.lucene.index.SegmentTermDocs, org.apache.lucene.index.TermDocs, org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.Scorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer, org.apache.lucene.search.spans.Spans],[boolean next(), int doc()]]
	  	  FEATURE TYPE:  ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.index.TermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.25 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.2857143 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.index.SegmentTermDocs] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.search.spans.Spans]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.4 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.4 ]; RELATED TYPES: [org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.Scorer]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.25 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.4 ]; RELATED TYPES: [org.apache.lucene.search.BooleanScorer, org.apache.lucene.search.ConjunctionScorer, org.apache.lucene.search.PhraseScorer, org.apache.lucene.search.TermScorer, org.apache.lucene.search.spans.SpanScorer] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.TermDocs]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.25 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.FilterIndexReader.FilterTermDocs, org.apache.lucene.index.MultiTermDocs, org.apache.lucene.search.TermScorer] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.spans.NearSpans.SpansCell]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.33333334 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.4 ]; RELATED TYPES: [org.apache.lucene.search.spans.NearSpans, org.apache.lucene.search.spans.NearSpans.SpansCell] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.spans.Spans]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.4 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.6666667 ]; RELATED TYPES: [org.apache.lucene.search.spans.NearSpans.SpansCell, org.apache.lucene.search.spans.SpanScorer]
	  	  	->NODE_65[...,...]
	  	->NODE_27[...,...]
	->NODE_71[[org.apache.lucene.search.FuzzyQuery, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.WildcardQuery],[FilteredTermEnum getEnum(IndexReader reader)]]
	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.MultiTermQuery]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.16666667 ]##
	->NODE_72[[org.apache.lucene.search.PhraseQueue, org.apache.lucene.search.spans.NearSpans.CellQueue, org.apache.lucene.search.spans.SpanOrQuery.SpanQueue],[boolean lessThan(Object o1, Object o2)]]
	  FEATURE TYPE:  ## ADHOC
	->NODE_73[[org.apache.lucene.search.BooleanQuery, org.apache.lucene.search.FilteredQuery, org.apache.lucene.search.MultiTermQuery, org.apache.lucene.search.PrefixQuery, org.apache.lucene.search.Query, org.apache.lucene.search.RangeQuery],[Query rewrite(IndexReader reader)]]
	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.Query]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.11111111 ]## ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.Query]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.11111111 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.5 ]; RELATED TYPES: [org.apache.lucene.search.FilteredQuery]
	  	->NODE_49[...,...]
	  	->NODE_8[...,...]
	->NODE_74[[org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.Explanation, org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.Weight, org.apache.lucene.search.spans.SpanWeight],[float getValue()]]
	  FEATURE TYPE:  ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.search.Weight]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.16666667 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.2 ]; RELATED TYPES: [org.apache.lucene.search.BooleanQuery.BooleanWeight, org.apache.lucene.search.PhrasePrefixQuery.PhrasePrefixWeight, org.apache.lucene.search.PhraseQuery.PhraseWeight, org.apache.lucene.search.TermQuery.TermWeight, org.apache.lucene.search.spans.SpanWeight]
	  	->NODE_54[...,...]
	->NODE_75[[org.apache.lucene.document.Document, org.apache.lucene.document.Field, org.apache.lucene.search.Query],[float getBoost()]]
	  FEATURE TYPE:  ## ADHOC
	  	->NODE_76[[org.apache.lucene.document.Document, org.apache.lucene.document.Field],[float getBoost(), void setBoost(float boost)]]
	  	  FEATURE TYPE:  ## ADHOC
	->NODE_77[[org.apache.lucene.analysis.standard.FastCharStream, org.apache.lucene.queryParser.FastCharStream, org.apache.lucene.store.InputStream],[void refill()]]
	  FEATURE TYPE:  ## ADHOC
	  	->NODE_78[[org.apache.lucene.analysis.standard.FastCharStream, org.apache.lucene.queryParser.FastCharStream],[String GetImage(), char BeginToken(), char readChar(), char[] GetSuffix(int len), int getBeginColumn(), int getBeginLine(), int getColumn(), int getEndColumn(), int getEndLine(), int getLine(), void Done(), void FastCharStream(Reader r), void backup(int amount), void refill()]]
	  	  FEATURE TYPE:  ## ADHOC
	->	->	->NODE_46[...,...]
	->	->NODE_40[...,...]
	->NODE_79[[org.apache.lucene.index.IndexWriter, org.apache.lucene.search.Scorer, org.apache.lucene.search.Searcher],[Similarity getSimilarity()]]
	  FEATURE TYPE:  ## ADHOC
	  	->NODE_23[...,...]
	->NODE_80[[org.apache.lucene.index.FieldInfos, org.apache.lucene.index.FieldsReader, org.apache.lucene.index.MultipleTermPositions.IntQueue, org.apache.lucene.index.SegmentTermVector, org.apache.lucene.index.TermFreqVector, org.apache.lucene.index.TermVectorsReader, org.apache.lucene.search.BooleanScorer.BucketTable, org.apache.lucene.search.QueryTermVector, org.apache.lucene.util.BitVector, org.apache.lucene.util.PriorityQueue],[int size()]]
	  FEATURE TYPE:  ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.index.TermFreqVector]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.16666667 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.25 ]; RELATED TYPES: [org.apache.lucene.index.SegmentTermVector, org.apache.lucene.search.QueryTermVector] ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.index.FieldInfos]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.05882353 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.index.FieldsReader, org.apache.lucene.index.TermVectorsReader]
	  	->NODE_15[...,...]
	  	->NODE_81[[org.apache.lucene.index.SegmentTermVector, org.apache.lucene.index.TermFreqVector, org.apache.lucene.search.QueryTermVector],[String getField(), String[] getTerms(), int size(), int[] getTermFrequencies()]]
	  	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.index.TermFreqVector]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.6666667 ]##
	  	->NODE_82[[org.apache.lucene.index.FieldInfos, org.apache.lucene.util.BitVector],[int size(), void write(Directory d, String name)]]
	  	  FEATURE TYPE:  ## ADHOC
	  	->NODE_83[[org.apache.lucene.index.MultipleTermPositions.IntQueue, org.apache.lucene.util.PriorityQueue],[int size(), void clear()]]
	  	  FEATURE TYPE:  ## ADHOC
	->NODE_84[[org.apache.lucene.search.IndexSearcher, org.apache.lucene.search.MultiSearcher, org.apache.lucene.search.ParallelMultiSearcher, org.apache.lucene.search.RemoteSearchable],[Query rewrite(Query original), int docFreq(Term term), void search(Query query, Filter filter, HitCollector results)]]
	  FEATURE TYPE:  ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.MultiSearcher]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.21428572 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.75 ]; RELATED TYPES: [org.apache.lucene.search.ParallelMultiSearcher]
	  	->NODE_17[...,...]
	  	->	->NODE_18[...,...]
	->NODE_85[[org.apache.lucene.index.SegmentTermVector, org.apache.lucene.index.TermFreqVector, org.apache.lucene.search.QueryTermVector, org.apache.lucene.search.RangeQuery, org.apache.lucene.search.SortField, org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanQuery, org.apache.lucene.search.spans.SpanTermQuery],[String getField()]]
	  FEATURE TYPE:  ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_INTERFACE_IMPLEMENTATIONS; ANCHOR: [org.apache.lucene.index.TermFreqVector]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.16666667 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.25 ]; RELATED TYPES: [org.apache.lucene.index.SegmentTermVector, org.apache.lucene.search.QueryTermVector] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.spans.SpanQuery]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.25 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.33333334 ]; RELATED TYPES: [org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNearQuery, org.apache.lucene.search.spans.SpanNotQuery, org.apache.lucene.search.spans.SpanOrQuery, org.apache.lucene.search.spans.SpanTermQuery] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.SortField]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.07692308 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.07692308 ]; RELATED TYPES: [org.apache.lucene.search.SortField] ## PARTIAL_EXTENT_PARTIAL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.spans.SpanQuery]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.25 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 0.33333334 ]; RELATED TYPES: [org.apache.lucene.search.spans.SpanFirstQuery, org.apache.lucene.search.spans.SpanNotQuery]
	  	->NODE_81[...,...]
	  	->NODE_5[...,...]
	->NODE_86[[org.apache.lucene.analysis.PorterStemmer, org.apache.lucene.queryParser.QueryParser, org.apache.lucene.search.RemoteSearchable],[void main(String[] args)]]
	  FEATURE TYPE:  ## ADHOC
	->NODE_87[[org.apache.lucene.queryParser.QueryParser, org.apache.lucene.search.SortField],[Locale getLocale()]]
	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.SortField]; ANCHOR TYPE BEHAVIOR COVERAGE: [0.07692308 ]##
	->NODE_88[[org.apache.lucene.search.CachingWrapperFilter, org.apache.lucene.search.DateFilter, org.apache.lucene.search.Filter, org.apache.lucene.search.QueryFilter],[BitSet bits(IndexReader reader)]]
	  FEATURE TYPE: FULL_EXTENT_FULL_BEHAVIOR_EXPLICIT_CLASS_SUBCLASS_REDEFINITIONS; ANCHOR: [org.apache.lucene.search.Filter]; ANCHOR TYPE BEHAVIOR COVERAGE: [1.0 ]## ## PARTIAL_EXTENT_FULL_BEHAVIOR_EXPLICIT_AGGREGATIONS; ANCHOR: [org.apache.lucene.search.Filter]; ANCHOR TYPE BEHAVIOR COVERAGE: [1.0 ]; CONFIGURATION BEHAVIOR COVERAGE: [ 1.0 ]; RELATED TYPES: [org.apache.lucene.search.CachingWrapperFilter]
	->	->NODE_50[...,...]
	->NODE_89[[org.apache.lucene.analysis.PorterStemmer, org.apache.lucene.store.RAMOutputStream],[void reset()]]
	  FEATURE TYPE:  ## ADHOC
	->NODE_90[[org.apache.lucene.index.MultipleTermPositions.IntQueue, org.apache.lucene.search.PhraseScorer],[void sort()]]
	  FEATURE TYPE:  ## ADHOC
Done printing candidate nodes!
true
